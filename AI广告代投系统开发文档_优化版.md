# AIå¹¿å‘Šä»£æŠ•ç³»ç»Ÿå¼€å‘æ–‡æ¡£ v1.2 å®Œæ•´ç‰ˆ

> æœ¬æ–‡æ¡£åœ¨ v1.1 åŸºç¡€ä¸Šå…¨é¢ä¼˜åŒ–ï¼Œå¢åŠ äº†å®Œæ•´çš„æŠ€æœ¯å®ç°ç»†èŠ‚ã€ä»£ç ç¤ºä¾‹ã€é…ç½®æ–‡ä»¶å’Œæœ€ä½³å®è·µï¼Œä¸ºå¼€å‘å›¢é˜Ÿæä¾›å¯ç›´æ¥ä½¿ç”¨çš„å®æ–½æŒ‡å—ã€‚

---

## ğŸ“‹ ç›®å½•

1. [ç³»ç»Ÿæ¦‚è¿°](#ä¸€ã€ç³»ç»Ÿæ¦‚è¿°)
2. [æŠ€æœ¯æ¶æ„è®¾è®¡](#äºŒã€æŠ€æœ¯æ¶æ„è®¾è®¡)
3. [æ•°æ®åº“è®¾è®¡](#ä¸‰ã€æ•°æ®åº“è®¾è®¡)
4. [APIæ¥å£è®¾è®¡](#å››ã€APIæ¥å£è®¾è®¡)
5. [çŠ¶æ€æœºå®ç°](#äº”ã€çŠ¶æ€æœºå®ç°)
6. [æƒé™æ§åˆ¶ç³»ç»Ÿ](#å…­ã€æƒé™æ§åˆ¶ç³»ç»Ÿ)
7. [AIé¢„æµ‹æ¨¡å—](#ä¸ƒã€AIé¢„æµ‹æ¨¡å—)
8. [å‰ç«¯å¼€å‘æŒ‡å—](#å…«ã€å‰ç«¯å¼€å‘æŒ‡å—)
9. [æµ‹è¯•ç­–ç•¥](#ä¹ã€æµ‹è¯•ç­–ç•¥)
10. [éƒ¨ç½²ä¸è¿ç»´](#åã€éƒ¨ç½²ä¸è¿ç»´)
11. [æ€§èƒ½ä¼˜åŒ–](#åä¸€ã€æ€§èƒ½ä¼˜åŒ–)
12. [å®‰å…¨é…ç½®](#åäºŒã€å®‰å…¨é…ç½®)
13. [æ•…éšœæ’æŸ¥](#åä¸‰ã€æ•…éšœæ’æŸ¥)
14. [å¼€å‘è§„èŒƒ](#åå››ã€å¼€å‘è§„èŒƒ)

---

## ä¸€ã€ç³»ç»Ÿæ¦‚è¿°

### 1.1 é¡¹ç›®èƒŒæ™¯
AIå¹¿å‘Šä»£æŠ•ç³»ç»Ÿæ˜¯ä¸€ä¸ªä¸“ä¸ºFacebookå¹¿å‘Šä»£æŠ•ä¸šåŠ¡è®¾è®¡çš„ç»¼åˆæ€§ç®¡ç†å¹³å°ï¼Œè§£å†³æŠ•æ‰‹æ•ˆç‡ç®¡ç†ã€è´¢åŠ¡å¯¹è´¦ã€æ¸ é“è¯„ä¼°å’Œç›ˆåˆ©åˆ†æç­‰æ ¸å¿ƒä¸šåŠ¡æŒ‘æˆ˜ã€‚

### 1.2 æ ¸å¿ƒä¸šåŠ¡æµç¨‹
```mermaid
graph TD
    A[ç”²æ–¹ç­¾çº¦ä»˜æ¬¾] --> B[åˆ›å»ºé¡¹ç›®]
    B --> C[ç”³è¯·æ¸ é“è´¦æˆ·]
    C --> D[åˆ†é…è´¦æˆ·ç»™æŠ•æ‰‹]
    D --> E[æŠ•æ‰‹æŠ•æ”¾å¹¿å‘Š]
    E --> F[æ¯æ—¥æäº¤æ—¥æŠ¥]
    F --> G[æ•°æ®å‘˜å®¡æ ¸ç”²æ–¹ç²‰æ•°]
    E --> H[æäº¤å……å€¼ç”³è¯·]
    H --> I[æ•°æ®å‘˜å®¡æ ¸éœ€æ±‚]
    I --> J[è´¢åŠ¡å®¡æ‰¹]
    J --> K[è´¢åŠ¡æ‰“æ¬¾ç»™ä»£ç†å•†]
    K --> L[ä»£ç†å•†å……å€¼]
    L --> M[æœˆåº•è´¢åŠ¡å¯¹è´¦]
    M --> N[é¡¹ç›®ç›ˆåˆ©åˆ†æ]
```

### 1.3 æŠ€æœ¯æ ˆé€‰æ‹©
| å±‚çº§ | æŠ€æœ¯é€‰æ‹© | ç†ç”± |
|------|----------|------|
| å‰ç«¯ | Next.js 14 + TypeScript | SSRæ”¯æŒã€ç±»å‹å®‰å…¨ã€SEOå‹å¥½ |
| åç«¯ | FastAPI + SQLAlchemy | é«˜æ€§èƒ½ã€è‡ªåŠ¨æ–‡æ¡£ç”Ÿæˆã€ç±»å‹éªŒè¯ |
| æ•°æ®åº“ | PostgreSQL + Supabase | å¼ºä¸€è‡´æ€§ã€RLSå®‰å…¨ã€æ‰˜ç®¡æœåŠ¡ |
| ç¼“å­˜ | Redis | é«˜æ€§èƒ½ã€æ•°æ®ç»“æ„ä¸°å¯Œ |
| ç›‘æ§ | Prometheus + Grafana | äº‘åŸç”Ÿæ ‡å‡†ã€ç”Ÿæ€å®Œå–„ |

---

## äºŒã€æŠ€æœ¯æ¶æ„è®¾è®¡

### 2.1 æ•´ä½“æ¶æ„
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å‰ç«¯å±‚ (Next.js)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   é¡µé¢ç»„ä»¶   â”‚ â”‚   çŠ¶æ€ç®¡ç†   â”‚ â”‚   è·¯ç”±æ§åˆ¶   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                APIç½‘å…³å±‚ (FastAPI)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   è®¤è¯ä¸­é—´ä»¶ â”‚ â”‚   æƒé™æ§åˆ¶   â”‚ â”‚   è¯·æ±‚æ—¥å¿—   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                ä¸šåŠ¡é€»è¾‘å±‚ (Services)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   é¡¹ç›®ç®¡ç†   â”‚ â”‚   è´¢åŠ¡ç®¡ç†   â”‚ â”‚   AIé¢„æµ‹     â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                æ•°æ®è®¿é—®å±‚ (SQLAlchemy)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   æ¨¡å‹å®šä¹‰   â”‚ â”‚   æŸ¥è¯¢æ„å»º   â”‚ â”‚   è¿æ¥æ±      â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  æ•°æ®å±‚ (PostgreSQL)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   æ ¸å¿ƒæ•°æ®   â”‚ â”‚   å®¡è®¡æ—¥å¿—   â”‚ â”‚   RLSç­–ç•¥    â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ ¸å¿ƒæ¨¡å—è®¾è®¡

#### 2.2.1 é¡¹ç›®ç®¡ç†æ¨¡å—
```python
# services/project_service.py
class ProjectService:
    def __init__(self, db: Session):
        self.db = db

    async def create_project(self, project_data: ProjectCreate, user_id: str) -> Project:
        """åˆ›å»ºé¡¹ç›®"""
        # éªŒè¯æ•°æ®
        await self._validate_project_data(project_data)

        # åˆ›å»ºé¡¹ç›®
        project = Project(
            **project_data.dict(),
            created_by=user_id,
            status=ProjectStatus.PLANNING
        )

        self.db.add(project)
        self.db.commit()
        self.db.refresh(project)

        # è®°å½•å®¡è®¡æ—¥å¿—
        await audit_logger.log_create(
            table_name="projects",
            record_id=project.id,
            new_values=project_data.dict(),
            user_id=user_id
        )

        return project

    async def _validate_project_data(self, data: ProjectCreate):
        """éªŒè¯é¡¹ç›®æ•°æ®"""
        if data.lead_price <= 0:
            raise ValueError("å•ç²‰ä»·æ ¼å¿…é¡»å¤§äº0")

        if data.pricing_model not in ["per_lead", "fixed_fee", "hybrid"]:
            raise ValueError("æ— æ•ˆçš„æ”¶è´¹æ¨¡å¼")
```

#### 2.2.2 å……å€¼ç®¡ç†æ¨¡å—
```python
# services/topup_service.py
class TopupService:
    def __init__(self, db: Session):
        self.db = db

    async def create_topup_request(self, request: TopupCreate, user_id: str) -> Topup:
        """åˆ›å»ºå……å€¼ç”³è¯·"""
        # éªŒè¯è´¦æˆ·æƒé™
        account = await self._verify_account_permission(
            request.ad_account_id, user_id
        )

        # è®¡ç®—è´¹ç”¨
        fee_rate = await self._get_channel_fee_rate(account.channel_id)
        fee_amount = request.amount * fee_rate
        total_amount = request.amount + fee_amount

        # åˆ›å»ºå……å€¼ç”³è¯·
        topup = Topup(
            project_id=account.project_id,
            ad_account_id=request.ad_account_id,
            user_id=user_id,
            amount=request.amount,
            fee_rate=fee_rate,
            fee_amount=fee_amount,
            total_amount=total_amount,
            status=TopupStatus.DRAFT,
            purpose=request.purpose
        )

        self.db.add(topup)
        self.db.commit()

        # å‘é€é€šçŸ¥
        await notification_service.notify_data_clerk(topup)

        return topup
```

### 2.3 é”™è¯¯å¤„ç†è®¾è®¡
```python
# core/exceptions.py
class BaseAPIException(Exception):
    """APIå¼‚å¸¸åŸºç±»"""
    def __init__(self, message: str, error_code: str = None):
        self.message = message
        self.error_code = error_code
        super().__init__(message)

class ValidationError(BaseAPIException):
    """æ•°æ®éªŒè¯é”™è¯¯"""
    def __init__(self, message: str, field: str = None):
        super().__init__(message, "VALIDATION_ERROR")
        self.field = field

class PermissionError(BaseAPIException):
    """æƒé™é”™è¯¯"""
    def __init__(self, message: str = "æƒé™ä¸è¶³"):
        super().__init__(message, "PERMISSION_DENIED")

class BusinessLogicError(BaseAPIException):
    """ä¸šåŠ¡é€»è¾‘é”™è¯¯"""
    def __init__(self, message: str, business_code: str = None):
        super().__init__(message, "BUSINESS_ERROR")
        self.business_code = business_code

# handlers/exception_handler.py
from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse

async def api_exception_handler(request: Request, exc: BaseAPIException):
    """ç»Ÿä¸€å¼‚å¸¸å¤„ç†"""
    return JSONResponse(
        status_code=400,
        content={
            "success": False,
            "error": {
                "code": exc.error_code,
                "message": exc.message,
                "field": getattr(exc, 'field', None),
                "business_code": getattr(exc, 'business_code', None)
            },
            "timestamp": datetime.utcnow().isoformat(),
            "request_id": getattr(request.state, 'request_id', None)
        }
    )
```

---

## ä¸‰ã€æ•°æ®åº“è®¾è®¡

### 3.1 æ ¸å¿ƒè¡¨ç»“æ„

#### 3.1.1 ç”¨æˆ·è¡¨ (users)
```sql
CREATE TABLE public.users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    hashed_password VARCHAR(255) NOT NULL,
    full_name VARCHAR(255),
    role VARCHAR(50) NOT NULL CHECK (role IN ('admin', 'manager', 'data_clerk', 'finance', 'media_buyer')),
    is_active BOOLEAN DEFAULT true,
    last_login TIMESTAMP,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- ç´¢å¼•
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_role ON users(role);
CREATE INDEX idx_users_active ON users(is_active);
```

#### 3.1.2 é¡¹ç›®è¡¨ (projects)
```sql
CREATE TABLE public.projects (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    code VARCHAR(50) UNIQUE NOT NULL,
    description TEXT,
    client_name VARCHAR(255) NOT NULL,
    client_contact VARCHAR(255),
    client_email VARCHAR(255),
    client_phone VARCHAR(50),

    -- æ”¶è´¹æ¨¡å¼
    pricing_model VARCHAR(50) DEFAULT 'per_lead' CHECK (pricing_model IN ('per_lead', 'fixed_fee', 'hybrid')),
    lead_price NUMERIC(10,2) NOT NULL CHECK (lead_price > 0),
    setup_fee NUMERIC(10,2) DEFAULT 0 CHECK (setup_fee >= 0),
    currency VARCHAR(3) DEFAULT 'USD',

    -- é¡¹ç›®çŠ¶æ€
    status VARCHAR(20) DEFAULT 'planning' CHECK (status IN ('planning', 'active', 'paused', 'completed', 'cancelled')),
    start_date TIMESTAMP,
    end_date TIMESTAMP,

    -- é¢„ç®—å’Œç›®æ ‡
    monthly_budget NUMERIC(12,2),
    total_budget NUMERIC(15,2),
    monthly_target_leads INTEGER DEFAULT 0,
    target_cpl NUMERIC(10,2),

    -- ç®¡ç†ä¿¡æ¯
    manager_id UUID REFERENCES users(id) ON DELETE SET NULL,
    created_by UUID NOT NULL REFERENCES users(id),
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- ç´¢å¼•
CREATE INDEX idx_projects_status ON projects(status);
CREATE INDEX idx_projects_client ON projects(client_name);
CREATE INDEX idx_projects_manager ON projects(manager_id);
CREATE INDEX idx_projects_created_by ON projects(created_by);
```

#### 3.1.3 æ¸ é“è¡¨ (channels)
```sql
CREATE TABLE public.channels (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    code VARCHAR(50) UNIQUE NOT NULL,
    company_name VARCHAR(255) NOT NULL,

    -- è”ç³»ä¿¡æ¯
    contact_person VARCHAR(255),
    contact_email VARCHAR(255),
    contact_phone VARCHAR(50),
    contact_wechat VARCHAR(100),

    -- è´¹ç”¨ç»“æ„
    service_fee_rate NUMERIC(5,4) NOT NULL CHECK (service_fee_rate >= 0 AND service_fee_rate <= 1),
    account_setup_fee NUMERIC(10,2) DEFAULT 0,
    minimum_topup NUMERIC(10,2) DEFAULT 0,

    -- æ¸ é“çŠ¶æ€å’Œè´¨é‡
    status VARCHAR(20) DEFAULT 'active' CHECK (status IN ('active', 'inactive', 'suspended')),
    priority INTEGER DEFAULT 1,
    quality_score NUMERIC(3,2) CHECK (quality_score >= 0 AND quality_score <= 10),
    reliability_score NUMERIC(3,2) CHECK (reliability_score >= 0 AND reliability_score <= 10),

    -- ç»Ÿè®¡æ•°æ®
    total_accounts INTEGER DEFAULT 0,
    active_accounts INTEGER DEFAULT 0,
    dead_accounts INTEGER DEFAULT 0,
    total_spend NUMERIC(15,2) DEFAULT 0,

    -- ç®¡ç†ä¿¡æ¯
    notes TEXT,
    created_by UUID NOT NULL REFERENCES users(id),
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- ç´¢å¼•
CREATE INDEX idx_channels_status ON channels(status);
CREATE INDEX idx_channels_quality ON channels(quality_score);
CREATE INDEX idx_channels_code ON channels(code);
```

#### 3.1.4 å¹¿å‘Šè´¦æˆ·è¡¨ (ad_accounts)
```sql
CREATE TABLE public.ad_accounts (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    account_id VARCHAR(255) UNIQUE NOT NULL,
    name VARCHAR(255) NOT NULL,

    -- å¹³å°ä¿¡æ¯
    platform VARCHAR(50) DEFAULT 'facebook',
    platform_account_id VARCHAR(255),
    platform_business_id VARCHAR(255),

    -- å…³è”ä¿¡æ¯
    project_id UUID NOT NULL REFERENCES projects(id) ON DELETE CASCADE,
    channel_id UUID NOT NULL REFERENCES channels(id) ON DELETE RESTRICT,
    assigned_user_id UUID NOT NULL REFERENCES users(id) ON DELETE SET NULL,

    -- è´¦æˆ·çŠ¶æ€
    status VARCHAR(20) DEFAULT 'new' CHECK (status IN ('new', 'testing', 'active', 'suspended', 'dead', 'archived')),
    status_reason TEXT,
    last_status_change TIMESTAMP,

    -- ç”Ÿå‘½å‘¨æœŸæ—¶é—´æˆ³
    created_date TIMESTAMP,
    activated_date TIMESTAMP,
    suspended_date TIMESTAMP,
    dead_date TIMESTAMP,
    archived_date TIMESTAMP,

    -- é¢„ç®—ä¿¡æ¯
    daily_budget NUMERIC(10,2),
    total_budget NUMERIC(12,2),
    remaining_budget NUMERIC(12,2),

    -- è´¦æˆ·é…ç½®
    currency VARCHAR(3) DEFAULT 'USD',
    timezone VARCHAR(50),
    country VARCHAR(2),

    -- æ€§èƒ½æ•°æ®
    total_spend NUMERIC(15,2) DEFAULT 0,
    total_leads INTEGER DEFAULT 0,
    avg_cpl NUMERIC(10,2),
    best_cpl NUMERIC(10,2),

    -- å¼€æˆ·è´¹ç”¨
    setup_fee NUMERIC(10,2) DEFAULT 0,
    setup_fee_paid BOOLEAN DEFAULT false,

    -- ç®¡ç†ä¿¡æ¯
    notes TEXT,
    tags JSONB,
    metadata JSONB,
    created_by UUID NOT NULL REFERENCES users(id),
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- ç´¢å¼•
CREATE INDEX idx_ad_accounts_project ON ad_accounts(project_id);
CREATE INDEX idx_ad_accounts_channel ON ad_accounts(channel_id);
CREATE INDEX idx_ad_accounts_user ON ad_accounts(assigned_user_id);
CREATE INDEX idx_ad_accounts_status ON ad_accounts(status);
CREATE INDEX idx_ad_accounts_platform ON ad_accounts(platform);
CREATE UNIQUE INDEX idx_ad_accounts_account_id ON ad_accounts(account_id);
```

#### 3.1.5 å……å€¼è¡¨ (topups)
```sql
CREATE TABLE public.topups (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    project_id UUID NOT NULL REFERENCES projects(id) ON DELETE CASCADE,
    ad_account_id UUID NOT NULL REFERENCES ad_accounts(id) ON DELETE CASCADE,
    requested_by UUID NOT NULL REFERENCES users(id),

    -- ç”³è¯·ä¿¡æ¯
    amount NUMERIC(15,2) NOT NULL CHECK (amount > 0),
    purpose TEXT,
    urgency_level VARCHAR(20) DEFAULT 'normal' CHECK (urgency_level IN ('normal', 'urgent')),

    -- å®¡æ‰¹æµç¨‹
    status VARCHAR(20) DEFAULT 'draft' CHECK (status IN ('draft', 'pending', 'clerk_approved', 'finance_approved', 'paid', 'posted', 'rejected')),

    -- å®¡æ‰¹ä¿¡æ¯
    clerk_approval JSONB,
    finance_approval JSONB,

    -- è´¹ç”¨è®¡ç®—
    fee_rate NUMERIC(5,4) NOT NULL CHECK (fee_rate >= 0 AND fee_rate <= 1),
    fee_amount NUMERIC(15,2) NOT NULL,
    total_amount NUMERIC(15,2) NOT NULL,

    -- æ‰§è¡Œä¿¡æ¯
    payment_method VARCHAR(50),
    transaction_id VARCHAR(255),
    paid_at TIMESTAMP,
    posted_at TIMESTAMP,

    -- æ‹’ç»ä¿¡æ¯
    rejection_reason TEXT,
    rejected_by UUID REFERENCES users(id),
    rejected_at TIMESTAMP,

    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- ç´¢å¼•
CREATE INDEX idx_topups_project ON topups(project_id);
CREATE INDEX idx_topups_account ON topups(ad_account_id);
CREATE INDEX idx_topups_user ON topups(requested_by);
CREATE INDEX idx_topups_status ON topups(status);
CREATE INDEX idx_topups_created ON topups(created_at);
```

#### 3.1.6 æ—¥æŠ¥è¡¨ (ad_spend_daily)
```sql
CREATE TABLE public.ad_spend_daily (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    project_id UUID NOT NULL REFERENCES projects(id) ON DELETE CASCADE,
    ad_account_id UUID NOT NULL REFERENCES ad_accounts(id) ON DELETE CASCADE,
    user_id UUID NOT NULL REFERENCES users(id),
    date DATE NOT NULL,

    -- æŠ•æ‰‹æäº¤æ•°æ®
    leads_submitted INTEGER DEFAULT 0 CHECK (leads_submitted >= 0),
    spend NUMERIC(15,2) NOT NULL CHECK (spend >= 0),
    impressions INTEGER DEFAULT 0,
    clicks INTEGER DEFAULT 0,

    -- ç”²æ–¹ç¡®è®¤æ•°æ®
    leads_confirmed INTEGER,
    confirmed_by UUID REFERENCES users(id),
    confirmed_at TIMESTAMP,

    -- å·®å¼‚åˆ†æ
    leads_diff INTEGER GENERATED ALWAYS AS (
        CASE
            WHEN leads_confirmed IS NOT NULL THEN leads_confirmed - leads_submitted
            ELSE NULL
        END
    ) STORED,
    diff_reason TEXT,

    -- è´¨é‡è¯„ä¼°
    lead_quality_score NUMERIC(3,2) CHECK (lead_quality_score >= 0 AND lead_quality_score <= 10),

    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),

    -- çº¦æŸ
    UNIQUE(ad_account_id, date)
);

-- ç´¢å¼•
CREATE INDEX idx_ad_spend_daily_project ON ad_spend_daily(project_id);
CREATE INDEX idx_ad_spend_daily_account ON ad_spend_daily(ad_account_id);
CREATE INDEX idx_ad_spend_daily_user ON ad_spend_daily(user_id);
CREATE INDEX idx_ad_spend_daily_date ON ad_spend_daily(date);
CREATE INDEX idx_ad_spend_daily_status ON ad_spend_daily(leads_confirmed) WHERE leads_confirmed IS NOT NULL;
```

### 3.2 RLSå®‰å…¨ç­–ç•¥

#### 3.2.1 å¯ç”¨RLS
```sql
-- ä¸ºæ ¸å¿ƒè¡¨å¯ç”¨è¡Œçº§å®‰å…¨
ALTER TABLE projects ENABLE ROW LEVEL SECURITY;
ALTER TABLE ad_accounts ENABLE ROW LEVEL SECURITY;
ALTER TABLE topups ENABLE ROW LEVEL SECURITY;
ALTER TABLE ad_spend_daily ENABLE ROW LEVEL SECURITY;
```

#### 3.2.2 é¡¹ç›®è®¿é—®ç­–ç•¥
```sql
-- é¡¹ç›®è®¿é—®ç­–ç•¥
CREATE POLICY "é¡¹ç›®è®¿é—®ç­–ç•¥" ON projects
    USING (
        -- ç®¡ç†å‘˜å¯ä»¥è®¿é—®æ‰€æœ‰é¡¹ç›®
        current_setting('app.current_role') = 'admin'
        OR
        -- é¡¹ç›®ç»ç†å¯ä»¥è®¿é—®è‡ªå·±ç®¡ç†çš„é¡¹ç›®
        manager_id = current_setting('app.current_user_id')::uuid
        OR
        -- æˆ·ç®¡å¯ä»¥è®¿é—®æ‰€æœ‰é¡¹ç›®ï¼ˆå®¡æ ¸éœ€è¦ï¼‰
        current_setting('app.current_role') = 'data_clerk'
        OR
        -- è´¢åŠ¡å¯ä»¥è®¿é—®æ‰€æœ‰é¡¹ç›®ï¼ˆå¯¹è´¦éœ€è¦ï¼‰
        current_setting('app.current_role') = 'finance'
        OR
        -- æŠ•æ‰‹åªèƒ½è®¿é—®åˆ†é…ç»™è‡ªå·±çš„é¡¹ç›®
        EXISTS (
            SELECT 1 FROM ad_accounts
            WHERE ad_accounts.project_id = projects.id
            AND ad_accounts.assigned_user_id = current_setting('app.current_user_id')::uuid
        )
    );

-- é¡¹ç›®ä¿®æ”¹ç­–ç•¥
CREATE POLICY "é¡¹ç›®ä¿®æ”¹ç­–ç•¥" ON projects
    FOR ALL
    USING (
        current_setting('app.current_role') = 'admin'
        OR
        manager_id = current_setting('app.current_user_id')::uuid
    )
    WITH CHECK (
        current_setting('app.current_role') = 'admin'
        OR
        manager_id = current_setting('app.current_user_id')::uuid
    );
```

#### 3.2.3 å¹¿å‘Šè´¦æˆ·è®¿é—®ç­–ç•¥
```sql
-- å¹¿å‘Šè´¦æˆ·è®¿é—®ç­–ç•¥
CREATE POLICY "å¹¿å‘Šè´¦æˆ·è®¿é—®ç­–ç•¥" ON ad_accounts
    USING (
        -- ç®¡ç†å‘˜å¯ä»¥è®¿é—®æ‰€æœ‰è´¦æˆ·
        current_setting('app.current_role') = 'admin'
        OR
        -- æˆ·ç®¡å¯ä»¥è®¿é—®æ‰€æœ‰è´¦æˆ·
        current_setting('app.current_role') = 'data_clerk'
        OR
        -- è´¢åŠ¡å¯ä»¥è®¿é—®æ‰€æœ‰è´¦æˆ·
        current_setting('app.current_role') = 'finance'
        OR
        -- é¡¹ç›®ç»ç†å¯ä»¥è®¿é—®é¡¹ç›®ä¸‹çš„æ‰€æœ‰è´¦æˆ·
        EXISTS (
            SELECT 1 FROM projects
            WHERE projects.id = ad_accounts.project_id
            AND projects.manager_id = current_setting('app.current_user_id')::uuid
        )
        OR
        -- æŠ•æ‰‹åªèƒ½è®¿é—®åˆ†é…ç»™è‡ªå·±çš„è´¦æˆ·
        assigned_user_id = current_setting('app.current_user_id')::uuid
    );

-- å¹¿å‘Šè´¦æˆ·ä¿®æ”¹ç­–ç•¥
CREATE POLICY "å¹¿å‘Šè´¦æˆ·ä¿®æ”¹ç­–ç•¥" ON ad_accounts
    FOR ALL
    USING (
        current_setting('app.current_role') IN ('admin', 'data_clerk')
        OR
        EXISTS (
            SELECT 1 FROM projects
            WHERE projects.id = ad_accounts.project_id
            AND projects.manager_id = current_setting('app.current_user_id')::uuid
        )
    );
```

### 3.3 è§¦å‘å™¨å’Œå‡½æ•°

#### 3.3.1 æ›´æ–°æ—¶é—´æˆ³è§¦å‘å™¨
```sql
-- åˆ›å»ºæ›´æ–°æ—¶é—´æˆ³å‡½æ•°
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ language 'plpgsql';

-- ä¸ºæ‰€æœ‰è¡¨æ·»åŠ è§¦å‘å™¨
CREATE TRIGGER update_projects_updated_at BEFORE UPDATE ON projects
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_channels_updated_at BEFORE UPDATE ON channels
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_ad_accounts_updated_at BEFORE UPDATE ON ad_accounts
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_topups_updated_at BEFORE UPDATE ON topups
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_ad_spend_daily_updated_at BEFORE UPDATE ON ad_spend_daily
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
```

#### 3.3.2 è´¦æˆ·çŠ¶æ€å˜æ›´è§¦å‘å™¨
```sql
-- è´¦æˆ·çŠ¶æ€å˜æ›´å†å²å‡½æ•°
CREATE OR REPLACE FUNCTION log_account_status_change()
RETURNS TRIGGER AS $$
BEGIN
    -- è®°å½•çŠ¶æ€å˜æ›´å†å²
    INSERT INTO account_status_history (
        account_id,
        old_status,
        new_status,
        change_reason,
        changed_at,
        changed_by,
        change_source
    ) VALUES (
        NEW.id,
        OLD.status,
        NEW.status,
        NEW.status_reason,
        NOW(),
        NEW.updated_by,
        'manual'
    );

    -- æ›´æ–°çŠ¶æ€æ—¶é—´æˆ³
    IF NEW.status != OLD.status THEN
        NEW.last_status_change = NOW();

        CASE NEW.status
            WHEN 'active' THEN NEW.activated_date = NOW();
            WHEN 'suspended' THEN NEW.suspended_date = NOW();
            WHEN 'dead' THEN NEW.dead_date = NOW();
            WHEN 'archived' THEN NEW.archived_date = NOW();
        END CASE;
    END IF;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- åˆ›å»ºè§¦å‘å™¨
CREATE TRIGGER account_status_change_trigger
    BEFORE UPDATE ON ad_accounts
    FOR EACH ROW
    WHEN (OLD.status IS DISTINCT FROM NEW.status)
    EXECUTE FUNCTION log_account_status_change();
```

---

## å››ã€APIæ¥å£è®¾è®¡

### 4.1 æ¥å£è§„èŒƒ

#### 4.1.1 å‘½åè§„èŒƒ
- è·¯ç”±ä½¿ç”¨ kebab-caseï¼š`/api/topups/request`
- HTTPåŠ¨è¯è¯­ä¹‰ï¼šGETæŸ¥è¯¢ã€POSTåˆ›å»ºã€PUTæ›´æ–°ã€DELETEåˆ é™¤
- èµ„æºåè¯å¤æ•°ï¼š`/api/projects`ã€`/api/accounts`
- åµŒå¥—èµ„æºï¼š`/api/projects/{project_id}/accounts`

#### 4.1.2 è¯·æ±‚å“åº”æ ¼å¼
```python
# schemas/common.py
from pydantic import BaseModel
from typing import Generic, TypeVar, Optional, List
from datetime import datetime

T = TypeVar('T')

class APIResponse(BaseModel, Generic[T]):
    """ç»Ÿä¸€APIå“åº”æ ¼å¼"""
    success: bool
    data: Optional[T] = None
    error: Optional[dict] = None
    message: str
    timestamp: datetime
    request_id: Optional[str] = None

class PaginatedResponse(BaseModel, Generic[T]):
    """åˆ†é¡µå“åº”æ ¼å¼"""
    items: List[T]
    pagination: dict
    total: int
    page: int
    size: int
    pages: int

class ErrorResponse(BaseModel):
    """é”™è¯¯å“åº”æ ¼å¼"""
    success: bool = False
    error: dict
    message: str
    timestamp: datetime
    request_id: Optional[str] = None
```

#### 4.1.3 ä¸­é—´ä»¶é…ç½®
```python
# middleware/request_id.py
import uuid
from fastapi import Request, Response
from starlette.middleware.base import BaseHTTPMiddleware

class RequestIDMiddleware(BaseHTTPMiddleware):
    """è¯·æ±‚IDä¸­é—´ä»¶"""
    async def dispatch(self, request: Request, call_next):
        request_id = str(uuid.uuid4())
        request.state.request_id = request_id

        response = await call_next(request)
        response.headers["X-Request-ID"] = request_id

        return response

# middleware/context.py
from fastapi import Request, HTTPException
from starlette.middleware.base import BaseHTTPMiddleware

class ContextMiddleware(BaseHTTPMiddleware):
    """ç”¨æˆ·ä¸Šä¸‹æ–‡ä¸­é—´ä»¶"""
    async def dispatch(self, request: Request, call_next):
        # ä»JWT tokenä¸­æå–ç”¨æˆ·ä¿¡æ¯
        token = request.headers.get("Authorization")
        if token:
            user = await verify_token(token.replace("Bearer ", ""))
            if user:
                # è®¾ç½®æ•°æ®åº“ä¼šè¯å˜é‡
                async with get_db_session() as session:
                    await session.execute(
                        "SET LOCAL app.current_user_id = :user_id",
                        {"user_id": user.id}
                    )
                    await session.execute(
                        "SET LOCAL app.current_role = :role",
                        {"role": user.role}
                    )

        response = await call_next(request)
        return response
```

### 4.2 é¡¹ç›®ç®¡ç†API

#### 4.2.1 é¡¹ç›®CRUDæ¥å£
```python
# routers/projects.py
from fastapi import APIRouter, Depends, HTTPException, Query
from typing import List, Optional
from datetime import datetime

router = APIRouter(prefix="/api/projects", tags=["projects"])

@router.post("/", response_model=APIResponse[ProjectResponse])
async def create_project(
    project: ProjectCreate,
    current_user: User = Depends(get_current_user),
    request_id: str = Depends(get_request_id)
):
    """åˆ›å»ºé¡¹ç›®"""
    try:
        # æƒé™éªŒè¯
        if not permission_checker.can_create_project(current_user.role):
            raise PermissionError("æ— åˆ›å»ºé¡¹ç›®æƒé™")

        # ä¸šåŠ¡é€»è¾‘
        project_service = ProjectService(db)
        result = await project_service.create_project(project, current_user.id)

        return APIResponse(
            success=True,
            data=result,
            message="é¡¹ç›®åˆ›å»ºæˆåŠŸ",
            timestamp=datetime.utcnow(),
            request_id=request_id
        )

    except ValidationError as e:
        raise HTTPException(status_code=400, detail=e.message)
    except Exception as e:
        logger.error(f"åˆ›å»ºé¡¹ç›®å¤±è´¥: {e}", extra={"request_id": request_id})
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")

@router.get("/", response_model=APIResponse[PaginatedResponse[ProjectResponse]])
async def list_projects(
    skip: int = Query(0, ge=0),
    limit: int = Query(20, ge=1, le=100),
    status: Optional[str] = Query(None),
    client_name: Optional[str] = Query(None),
    current_user: User = Depends(get_current_user),
    request_id: str = Depends(get_request_id)
):
    """è·å–é¡¹ç›®åˆ—è¡¨"""
    try:
        project_service = ProjectService(db)
        filters = {}
        if status:
            filters["status"] = status
        if client_name:
            filters["client_name"] = client_name

        # æ ¹æ®ç”¨æˆ·è§’è‰²åº”ç”¨æƒé™è¿‡æ»¤
        projects = await project_service.get_projects(
            user_id=current_user.id,
            user_role=current_user.role,
            filters=filters,
            skip=skip,
            limit=limit
        )

        total = await project_service.count_projects(
            user_id=current_user.id,
            user_role=current_user.role,
            filters=filters
        )

        paginated_response = PaginatedResponse(
            items=projects,
            pagination={
                "total": total,
                "page": skip // limit + 1,
                "size": limit,
                "pages": (total + limit - 1) // limit
            }
        )

        return APIResponse(
            success=True,
            data=paginated_response,
            message="è·å–é¡¹ç›®åˆ—è¡¨æˆåŠŸ",
            timestamp=datetime.utcnow(),
            request_id=request_id
        )

    except Exception as e:
        logger.error(f"è·å–é¡¹ç›®åˆ—è¡¨å¤±è´¥: {e}", extra={"request_id": request_id})
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")

@router.get("/{project_id}", response_model=APIResponse[ProjectDetailResponse])
async def get_project(
    project_id: str,
    current_user: User = Depends(get_current_user),
    request_id: str = Depends(get_request_id)
):
    """è·å–é¡¹ç›®è¯¦æƒ…"""
    try:
        # æƒé™éªŒè¯
        if not permission_checker.can_access_project(current_user, project_id, "read"):
            raise PermissionError("æ— è®¿é—®é¡¹ç›®æƒé™")

        project_service = ProjectService(db)
        project = await project_service.get_project_by_id(project_id)

        if not project:
            raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨")

        # è·å–é¡¹ç›®ç»Ÿè®¡ä¿¡æ¯
        stats = await project_service.get_project_stats(project_id)

        project_detail = ProjectDetailResponse(
            **project.__dict__,
            stats=stats
        )

        return APIResponse(
            success=True,
            data=project_detail,
            message="è·å–é¡¹ç›®è¯¦æƒ…æˆåŠŸ",
            timestamp=datetime.utcnow(),
            request_id=request_id
        )

    except PermissionError as e:
        raise HTTPException(status_code=403, detail=e.message)
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–é¡¹ç›®è¯¦æƒ…å¤±è´¥: {e}", extra={"request_id": request_id})
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")
```

#### 4.2.2 é¡¹ç›®çŠ¶æ€ç®¡ç†æ¥å£
```python
@router.put("/{project_id}/status")
async def update_project_status(
    project_id: str,
    status_update: ProjectStatusUpdate,
    current_user: User = Depends(get_current_user),
    request_id: str = Depends(get_request_id)
):
    """æ›´æ–°é¡¹ç›®çŠ¶æ€"""
    try:
        # æƒé™éªŒè¯
        if not permission_checker.can_update_project_status(current_user, project_id):
            raise PermissionError("æ— ä¿®æ”¹é¡¹ç›®çŠ¶æ€æƒé™")

        # çŠ¶æ€è½¬æ¢éªŒè¯
        if not is_valid_status_transition(
            current_status=await get_project_current_status(project_id),
            new_status=status_update.status,
            user_role=current_user.role
        ):
            raise BusinessLogicError(f"æ— æ³•ä»å½“å‰çŠ¶æ€è½¬æ¢åˆ° {status_update.status}")

        project_service = ProjectService(db)
        result = await project_service.update_project_status(
            project_id=project_id,
            new_status=status_update.status,
            reason=status_update.reason,
            user_id=current_user.id
        )

        return APIResponse(
            success=True,
            data=result,
            message="é¡¹ç›®çŠ¶æ€æ›´æ–°æˆåŠŸ",
            timestamp=datetime.utcnow(),
            request_id=request_id
        )

    except PermissionError as e:
        raise HTTPException(status_code=403, detail=e.message)
    except BusinessLogicError as e:
        raise HTTPException(status_code=400, detail=e.message)
    except Exception as e:
        logger.error(f"æ›´æ–°é¡¹ç›®çŠ¶æ€å¤±è´¥: {e}", extra={"request_id": request_id})
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")
```

### 4.3 å……å€¼ç®¡ç†API

#### 4.3.1 å……å€¼ç”³è¯·æ¥å£
```python
# routers/topups.py
@router.post("/request", response_model=APIResponse[TopupResponse])
async def create_topup_request(
    request: TopupCreate,
    current_user: User = Depends(get_current_user),
    request_id: str = Depends(get_request_id)
):
    """æäº¤å……å€¼ç”³è¯·"""
    try:
        # æƒé™éªŒè¯
        if not permission_checker.can_create_topup(current_user.role):
            raise PermissionError("æ— æäº¤å……å€¼ç”³è¯·æƒé™")

        # ä¸šåŠ¡éªŒè¯
        validation_result = await validate_topup_request(request, current_user.id)
        if not validation_result.is_valid:
            raise ValidationError(validation_result.errors)

        # åˆ›å»ºå……å€¼ç”³è¯·
        topup_service = TopupService(db)
        result = await topup_service.create_topup_request(request, current_user.id)

        # å‘é€é€šçŸ¥
        await notification_service.send_topup_request_notification(result)

        return APIResponse(
            success=True,
            data=result,
            message="å……å€¼ç”³è¯·æäº¤æˆåŠŸ",
            timestamp=datetime.utcnow(),
            request_id=request_id
        )

    except ValidationError as e:
        raise HTTPException(status_code=400, detail=e.message)
    except PermissionError as e:
        raise HTTPException(status_code=403, detail=e.message)
    except Exception as e:
        logger.error(f"æäº¤å……å€¼ç”³è¯·å¤±è´¥: {e}", extra={"request_id": request_id})
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")

@router.put("/{topup_id}/clerk-approval")
async def clerk_approval(
    topup_id: str,
    approval: ClerkApprovalSchema,
    current_user: User = Depends(get_current_user),
    request_id: str = Depends(get_request_id)
):
    """æ•°æ®å‘˜å®¡æ‰¹å……å€¼ç”³è¯·"""
    try:
        # æƒé™éªŒè¯
        if not permission_checker.can_approve_topup_as_clerk(current_user.role):
            raise PermissionError("æ— æ•°æ®å‘˜å®¡æ‰¹æƒé™")

        topup_service = TopupService(db)
        result = await topup_service.clerk_approval(
            topup_id=topup_id,
            approval=approval,
            user_id=current_user.id
        )

        # å¦‚æœæ‰¹å‡†ï¼Œé€šçŸ¥è´¢åŠ¡
        if approval.approved:
            await notification_service.send_finance_approval_notification(result)

        return APIResponse(
            success=True,
            data=result,
            message="æ•°æ®å‘˜å®¡æ‰¹å®Œæˆ",
            timestamp=datetime.utcnow(),
            request_id=request_id
        )

    except BusinessLogicError as e:
        raise HTTPException(status_code=400, detail=e.message)
    except Exception as e:
        logger.error(f"æ•°æ®å‘˜å®¡æ‰¹å¤±è´¥: {e}", extra={"request_id": request_id})
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")

@router.put("/{topup_id}/finance-approval")
async def finance_approval(
    topup_id: str,
    approval: FinanceApprovalSchema,
    current_user: User = Depends(get_current_user),
    request_id: str = Depends(get_request_id)
):
    """è´¢åŠ¡å®¡æ‰¹å¹¶æ‰§è¡Œå……å€¼"""
    try:
        # æƒé™éªŒè¯
        if not permission_checker.can_approve_topup_as_finance(current_user.role):
            raise PermissionError("æ— è´¢åŠ¡å®¡æ‰¹æƒé™")

        topup_service = TopupService(db)
        result = await topup_service.finance_approval(
            topup_id=topup_id,
            approval=approval,
            user_id=current_user.id
        )

        # å¦‚æœæ‰¹å‡†æ‰§è¡Œå……å€¼ï¼Œæ›´æ–°è´¦æˆ·ä½™é¢
        if approval.approved and approval.execute_payment:
            await account_service.update_account_balance(
                account_id=result.ad_account_id,
                amount=result.amount,
                transaction_id=approval.transaction_id
            )

            # è®°å½•è´¢åŠ¡æµæ°´
            await ledger_service.create_transaction(
                topup_id=result.id,
                amount=result.total_amount,
                transaction_type="topup",
                user_id=current_user.id
            )

        return APIResponse(
            success=True,
            data=result,
            message="è´¢åŠ¡å®¡æ‰¹å®Œæˆ",
            timestamp=datetime.utcnow(),
            request_id=request_id
        )

    except BusinessLogicError as e:
        raise HTTPException(status_code=400, detail=e.message)
    except Exception as e:
        logger.error(f"è´¢åŠ¡å®¡æ‰¹å¤±è´¥: {e}", extra={"request_id": request_id})
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")
```

### 4.4 æ—¥æŠ¥ç®¡ç†API

#### 4.4.1 æ—¥æŠ¥æäº¤æ¥å£
```python
# routers/daily_reports.py
@router.post("/", response_model=APIResponse[DailyReportResponse])
async def submit_daily_report(
    report: DailyReportCreate,
    current_user: User = Depends(get_current_user),
    request_id: str = Depends(get_request_id)
):
    """æäº¤æ—¥æŠ¥"""
    try:
        # æƒé™éªŒè¯
        if not permission_checker.can_submit_daily_report(current_user.role):
            raise PermissionError("æ— æäº¤æ—¥æŠ¥æƒé™")

        # ä¸šåŠ¡éªŒè¯
        validation_result = await validate_daily_report(report, current_user.id)
        if not validation_result.is_valid:
            raise ValidationError(validation_result.errors)

        # åˆ›å»ºæ—¥æŠ¥
        daily_report_service = DailyReportService(db)
        result = await daily_report_service.create_daily_report(report, current_user.id)

        # è®¡ç®—CPLç­‰æŒ‡æ ‡
        await daily_report_service.calculate_metrics(result.id)

        # é€šçŸ¥æ•°æ®å‘˜å®¡æ ¸
        await notification_service.send_daily_report_notification(result)

        return APIResponse(
            success=True,
            data=result,
            message="æ—¥æŠ¥æäº¤æˆåŠŸ",
            timestamp=datetime.utcnow(),
            request_id=request_id
        )

    except ValidationError as e:
        raise HTTPException(status_code=400, detail=e.message)
    except Exception as e:
        logger.error(f"æäº¤æ—¥æŠ¥å¤±è´¥: {e}", extra={"request_id": request_id})
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")

@router.put("/{report_id}/confirm")
async def confirm_daily_report(
    report_id: str,
    confirmation: DailyReportConfirmation,
    current_user: User = Depends(get_current_user),
    request_id: str = Depends(get_request_id)
):
    """ç¡®è®¤æ—¥æŠ¥ç²‰æ•°"""
    try:
        # æƒé™éªŒè¯
        if not permission_checker.can_confirm_daily_report(current_user.role):
            raise PermissionError("æ— ç¡®è®¤æ—¥æŠ¥æƒé™")

        daily_report_service = DailyReportService(db)
        result = await daily_report_service.confirm_daily_report(
            report_id=report_id,
            confirmation=confirmation,
            user_id=current_user.id
        )

        # æ£€æŸ¥å¼‚å¸¸å¹¶æ ‡è®°
        anomalies = await anomaly_detector.detect_daily_report_anomalies(result)
        if anomalies:
            await daily_report_service.mark_anomalies(result.id, anomalies)

        return APIResponse(
            success=True,
            data=result,
            message="æ—¥æŠ¥ç¡®è®¤æˆåŠŸ",
            timestamp=datetime.utcnow(),
            request_id=request_id
        )

    except BusinessLogicError as e:
        raise HTTPException(status_code=400, detail=e.message)
    except Exception as e:
        logger.error(f"ç¡®è®¤æ—¥æŠ¥å¤±è´¥: {e}", extra={"request_id": request_id})
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯")
```

---

## äº”ã€çŠ¶æ€æœºå®ç°

### 5.1 çŠ¶æ€æœºåŸºç±»
```python
# core/state_machine.py
from enum import Enum
from typing import Dict, List, Optional, Callable, Any
from abc import ABC, abstractmethod

class State(Enum):
    """çŠ¶æ€æšä¸¾åŸºç±»"""
    pass

class StateTransition:
    """çŠ¶æ€è½¬æ¢å®šä¹‰"""
    def __init__(
        self,
        from_state: State,
        to_state: State,
        allowed_roles: List[str],
        validator: Optional[Callable] = None,
        action: Optional[Callable] = None
    ):
        self.from_state = from_state
        self.to_state = to_state
        self.allowed_roles = allowed_roles
        self.validator = validator
        self.action = action

class StateMachine(ABC):
    """çŠ¶æ€æœºåŸºç±»"""

    def __init__(self, initial_state: State):
        self.current_state = initial_state
        self.transitions: Dict[State, List[StateTransition]] = {}
        self.history: List[Dict] = []

    def add_transition(self, transition: StateTransition):
        """æ·»åŠ çŠ¶æ€è½¬æ¢"""
        if transition.from_state not in self.transitions:
            self.transitions[transition.from_state] = []
        self.transitions[transition.from_state].append(transition)

    def can_transition(self, to_state: State, user_role: str, context: Dict = None) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥è½¬æ¢åˆ°ç›®æ ‡çŠ¶æ€"""
        if self.current_state not in self.transitions:
            return False

        for transition in self.transitions[self.current_state]:
            if transition.to_state == to_state and user_role in transition.allowed_roles:
                if transition.validator:
                    try:
                        return transition.validator(context or {})
                    except:
                        return False
                return True

        return False

    async def transition(
        self,
        to_state: State,
        user_id: str,
        user_role: str,
        reason: str = None,
        context: Dict = None
    ) -> bool:
        """æ‰§è¡ŒçŠ¶æ€è½¬æ¢"""
        if not self.can_transition(to_state, user_role, context):
            raise ValueError(f"æ— æ³•ä» {self.current_state} è½¬æ¢åˆ° {to_state}")

        # æ‰§è¡Œè½¬æ¢
        transition = self._find_transition(to_state, user_role)
        old_state = self.current_state

        # æ‰§è¡ŒéªŒè¯
        if transition.validator:
            transition.validator(context or {})

        # æ‰§è¡ŒåŠ¨ä½œ
        if transition.action:
            await transition.action(context or {})

        # æ›´æ–°çŠ¶æ€
        self.current_state = to_state

        # è®°å½•å†å²
        self.history.append({
            "from_state": old_state,
            "to_state": to_state,
            "user_id": user_id,
            "user_role": user_role,
            "reason": reason,
            "timestamp": datetime.utcnow(),
            "context": context
        })

        return True

    def _find_transition(self, to_state: State, user_role: str) -> StateTransition:
        """æŸ¥æ‰¾çŠ¶æ€è½¬æ¢"""
        for transition in self.transitions[self.current_state]:
            if transition.to_state == to_state and user_role in transition.allowed_roles:
                return transition
        raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„çŠ¶æ€è½¬æ¢")

    def get_available_transitions(self, user_role: str) -> List[State]:
        """è·å–ç”¨æˆ·è§’è‰²å¯ç”¨çš„çŠ¶æ€è½¬æ¢"""
        if self.current_state not in self.transitions:
            return []

        available_states = []
        for transition in self.transitions[self.current_state]:
            if user_role in transition.allowed_roles:
                available_states.append(transition.to_state)

        return available_states
```

### 5.2 å……å€¼çŠ¶æ€æœºå®ç°
```python
# models/topup_states.py
from enum import Enum

class TopupStatus(Enum):
    DRAFT = "draft"
    PENDING = "pending"
    CLERK_APPROVED = "clerk_approved"
    FINANCE_APPROVED = "finance_approved"
    PAID = "paid"
    POSTED = "posted"
    REJECTED = "rejected"

# services/topup_state_machine.py
class TopupStateMachine(StateMachine):

    def __init__(self, initial_state: TopupStatus = TopupStatus.DRAFT):
        super().__init__(initial_state)
        self._setup_transitions()

    def _setup_transitions(self):
        """è®¾ç½®çŠ¶æ€è½¬æ¢è§„åˆ™"""

        # æŠ•æ‰‹æäº¤ç”³è¯·
        self.add_transition(StateTransition(
            from_state=TopupStatus.DRAFT,
            to_state=TopupStatus.PENDING,
            allowed_roles=["media_buyer", "admin", "manager"],
            validator=self._validate_submission,
            action=self._on_submit
        ))

        # æ•°æ®å‘˜å®¡æ‰¹
        self.add_transition(StateTransition(
            from_state=TopupStatus.PENDING,
            to_state=TopupStatus.CLERK_APPROVED,
            allowed_roles=["data_clerk", "admin"],
            validator=self._validate_clerk_approval,
            action=self._on_clerk_approve
        ))

        # æ•°æ®å‘˜æ‹’ç»
        self.add_transition(StateTransition(
            from_state=TopupStatus.PENDING,
            to_state=TopupStatus.REJECTED,
            allowed_roles=["data_clerk", "admin"],
            validator=self._validate_rejection,
            action=self._on_reject
        ))

        # è´¢åŠ¡å®¡æ‰¹
        self.add_transition(StateTransition(
            from_state=TopupStatus.CLERK_APPROVED,
            to_state=TopupStatus.FINANCE_APPROVED,
            allowed_roles=["finance", "admin"],
            validator=self._validate_finance_approval,
            action=self._on_finance_approve
        ))

        # è´¢åŠ¡æ‹’ç»
        self.add_transition(StateTransition(
            from_state=TopupStatus.CLERK_APPROVED,
            to_state=TopupStatus.REJECTED,
            allowed_roles=["finance", "admin"],
            validator=self._validate_rejection,
            action=self._on_reject
        ))

        # è´¢åŠ¡ä»˜æ¬¾
        self.add_transition(StateTransition(
            from_state=TopupStatus.FINANCE_APPROVED,
            to_state=TopupStatus.PAID,
            allowed_roles=["finance", "admin"],
            validator=self._validate_payment,
            action=self._on_pay
        ))

        # ç³»ç»Ÿè®°è´¦
        self.add_transition(StateTransition(
            from_state=TopupStatus.PAID,
            to_state=TopupStatus.POSTED,
            allowed_roles=["system"],
            action=self._on_post
        ))

        # é‡æ–°æäº¤ï¼ˆè¢«æ‹’ç»åï¼‰
        self.add_transition(StateTransition(
            from_state=TopupStatus.REJECTED,
            to_state=TopupStatus.DRAFT,
            allowed_roles=["media_buyer", "admin", "manager"],
            validator=self._validate_resubmission,
            action=self._on_resubmit
        ))

    def _validate_submission(self, context: Dict) -> bool:
        """éªŒè¯æäº¤ç”³è¯·"""
        required_fields = ["amount", "ad_account_id", "purpose"]
        for field in required_fields:
            if field not in context or not context[field]:
                raise ValueError(f"ç¼ºå°‘å¿…å¡«å­—æ®µ: {field}")

        if context["amount"] <= 0:
            raise ValueError("å……å€¼é‡‘é¢å¿…é¡»å¤§äº0")

        return True

    def _validate_clerk_approval(self, context: Dict) -> bool:
        """éªŒè¯æ•°æ®å‘˜å®¡æ‰¹"""
        if "account_balance" in context and context["account_balance"] > 1000:
            raise ValueError("è´¦æˆ·ä½™é¢å……è¶³ï¼Œæš‚ä¸éœ€è¦å……å€¼")

        return True

    def _validate_finance_approval(self, context: Dict) -> bool:
        """éªŒè¯è´¢åŠ¡å®¡æ‰¹"""
        if "payment_method" not in context:
            raise ValueError("å¿…é¡»æŒ‡å®šä»˜æ¬¾æ–¹å¼")

        return True

    def _validate_payment(self, context: Dict) -> bool:
        """éªŒè¯ä»˜æ¬¾"""
        if "transaction_id" not in context:
            raise ValueError("ç¼ºå°‘äº¤æ˜“ID")

        return True

    def _validate_rejection(self, context: Dict) -> bool:
        """éªŒè¯æ‹’ç»"""
        if "reason" not in context or not context["reason"]:
            raise ValueError("æ‹’ç»æ—¶å¿…é¡»æä¾›åŸå› ")

        return True

    def _validate_resubmission(self, context: Dict) -> bool:
        """éªŒè¯é‡æ–°æäº¤"""
        # æ£€æŸ¥æ˜¯å¦ä¿®æ”¹äº†é—®é¢˜
        return True

    async def _on_submit(self, context: Dict):
        """æäº¤ç”³è¯·æ—¶çš„åŠ¨ä½œ"""
        # å‘é€é€šçŸ¥ç»™æ•°æ®å‘˜
        await notification_service.notify_data_clerk(context["topup_id"])

    async def _on_clerk_approve(self, context: Dict):
        """æ•°æ®å‘˜æ‰¹å‡†æ—¶çš„åŠ¨ä½œ"""
        # è®°å½•å®¡æ‰¹ä¿¡æ¯
        await audit_service.log_clerk_approval(context["topup_id"], context["user_id"])

    async def _on_finance_approve(self, context: Dict):
        """è´¢åŠ¡æ‰¹å‡†æ—¶çš„åŠ¨ä½œ"""
        # é¢„ç•™ä»˜æ¬¾
        await finance_service.reserve_payment(context["topup_id"])

    async def _on_pay(self, context: Dict):
        """ä»˜æ¬¾æ—¶çš„åŠ¨ä½œ"""
        # æ‰§è¡Œä»˜æ¬¾
        await payment_service.execute_payment(
            context["topup_id"],
            context["transaction_id"]
        )

    async def _on_post(self, context: Dict):
        """è®°è´¦æ—¶çš„åŠ¨ä½œ"""
        # æ›´æ–°è´¦æˆ·ä½™é¢
        await account_service.update_balance(context["topup_id"])

        # è®°å½•è´¢åŠ¡æµæ°´
        await ledger_service.create_entry(context["topup_id"])

    async def _on_reject(self, context: Dict):
        """æ‹’ç»æ—¶çš„åŠ¨ä½œ"""
        # å‘é€æ‹’ç»é€šçŸ¥
        await notification_service.notify_rejection(
            context["topup_id"],
            context["reason"]
        )

    async def _on_resubmit(self, context: Dict):
        """é‡æ–°æäº¤æ—¶çš„åŠ¨ä½œ"""
        # æ¸…é™¤ä¹‹å‰çš„å®¡æ‰¹è®°å½•
        await audit_service.clear_approvals(context["topup_id"])
```

### 5.3 æ—¥æŠ¥çŠ¶æ€æœºå®ç°
```python
# models/daily_report_states.py
class DailyReportStatus(Enum):
    DRAFT = "draft"
    PENDING = "pending"
    APPROVED = "approved"
    REJECTED = "rejected"

# services/daily_report_state_machine.py
class DailyReportStateMachine(StateMachine):

    def __init__(self, initial_state: DailyReportStatus = DailyReportStatus.DRAFT):
        super().__init__(initial_state)
        self._setup_transitions()

    def _setup_transitions(self):
        """è®¾ç½®çŠ¶æ€è½¬æ¢è§„åˆ™"""

        # æŠ•æ‰‹æäº¤æ—¥æŠ¥
        self.add_transition(StateTransition(
            from_state=DailyReportStatus.DRAFT,
            to_state=DailyReportStatus.PENDING,
            allowed_roles=["media_buyer", "admin", "manager"],
            validator=self._validate_submission,
            action=self._on_submit
        ))

        # æ•°æ®å‘˜ç¡®è®¤
        self.add_transition(StateTransition(
            from_state=DailyReportStatus.PENDING,
            to_state=DailyReportStatus.APPROVED,
            allowed_roles=["data_clerk", "admin"],
            validator=self._validate_confirmation,
            action=self._on_approve
        ))

        # æ•°æ®å‘˜æ‹’ç»
        self.add_transition(StateTransition(
            from_state=DailyReportStatus.PENDING,
            to_state=DailyReportStatus.REJECTED,
            allowed_roles=["data_clerk", "admin"],
            validator=self._validate_rejection,
            action=self._on_reject
        ))

        # é‡æ–°æäº¤
        self.add_transition(StateTransition(
            from_state=DailyReportStatus.REJECTED,
            to_state=DailyReportStatus.DRAFT,
            allowed_roles=["media_buyer", "admin", "manager"],
            action=self._on_resubmit
        ))

    def _validate_submission(self, context: Dict) -> bool:
        """éªŒè¯æ—¥æŠ¥æäº¤"""
        required_fields = ["date", "spend", "leads_submitted", "ad_account_id"]
        for field in required_fields:
            if field not in context:
                raise ValueError(f"ç¼ºå°‘å¿…å¡«å­—æ®µ: {field}")

        # æ£€æŸ¥æ˜¯å¦é‡å¤æäº¤
        if await self._check_duplicate_submission(context):
            raise ValueError("è¯¥æ—¥æœŸçš„æ—¥æŠ¥å·²å­˜åœ¨")

        return True

    def _validate_confirmation(self, context: Dict) -> bool:
        """éªŒè¯ç¡®è®¤"""
        if "leads_confirmed" not in context:
            raise ValueError("å¿…é¡»ç¡®è®¤ç²‰æ•°")

        return True

    def _validate_rejection(self, context: Dict) -> bool:
        """éªŒè¯æ‹’ç»"""
        if "reason" not in context:
            raise ValueError("æ‹’ç»æ—¶å¿…é¡»æä¾›åŸå› ")

        return True

    async def _on_submit(self, context: Dict):
        """æäº¤æ—¶çš„åŠ¨ä½œ"""
        # è®¡ç®—åˆå§‹æŒ‡æ ‡
        await metrics_service.calculate_initial_metrics(context["report_id"])

        # å‘é€å®¡æ ¸é€šçŸ¥
        await notification_service.notify_data_clerk_daily_report(context["report_id"])

    async def _on_approve(self, context: Dict):
        """æ‰¹å‡†æ—¶çš„åŠ¨ä½œ"""
        # æ›´æ–°æœ€ç»ˆæŒ‡æ ‡
        await metrics_service.calculate_final_metrics(
            context["report_id"],
            context["leads_confirmed"]
        )

        # æ£€æŸ¥å¼‚å¸¸
        await anomaly_detection_service.check_daily_report(context["report_id"])

    async def _on_reject(self, context: Dict):
        """æ‹’ç»æ—¶çš„åŠ¨ä½œ"""
        # å‘é€æ‹’ç»é€šçŸ¥
        await notification_service.notify_daily_report_rejection(
            context["report_id"],
            context["reason"]
        )

    async def _on_resubmit(self, context: Dict):
        """é‡æ–°æäº¤æ—¶çš„åŠ¨ä½œ"""
        # æ¸…é™¤ä¹‹å‰çš„ç¡®è®¤è®°å½•
        await audit_service.clear_daily_report_confirmation(context["report_id"])

    async def _check_duplicate_submission(self, context: Dict) -> bool:
        """æ£€æŸ¥é‡å¤æäº¤"""
        existing = await daily_report_service.get_report_by_date_account(
            context["date"],
            context["ad_account_id"]
        )
        return existing is not None
```

---

## å…­ã€æƒé™æ§åˆ¶ç³»ç»Ÿ

### 6.1 æƒé™æ¨¡å‹è®¾è®¡
```python
# models/permissions.py
from enum import Enum
from typing import Dict, List, Set

class UserRole(Enum):
    ADMIN = "admin"
    MANAGER = "manager"
    DATA_CLERK = "data_clerk"
    FINANCE = "finance"
    MEDIA_BUYER = "media_buyer"

class Permission(Enum):
    # é¡¹ç›®æƒé™
    PROJECT_CREATE = "project:create"
    PROJECT_READ = "project:read"
    PROJECT_UPDATE = "project:update"
    PROJECT_DELETE = "project:delete"

    # è´¦æˆ·æƒé™
    ACCOUNT_CREATE = "account:create"
    ACCOUNT_READ = "account:read"
    ACCOUNT_UPDATE = "account:update"
    ACCOUNT_DELETE = "account:delete"
    ACCOUNT_ASSIGN = "account:assign"

    # æ—¥æŠ¥æƒé™
    DAILY_REPORT_CREATE = "daily_report:create"
    DAILY_REPORT_READ = "daily_report:read"
    DAILY_REPORT_CONFIRM = "daily_report:confirm"
    DAILY_REPORT_UPDATE = "daily_report:update"

    # å……å€¼æƒé™
    TOPUP_CREATE = "topup:create"
    TOPUP_READ = "topup:read"
    TOPUP_CLERK_APPROVE = "topup:clerk_approve"
    TOPUP_FINANCE_APPROVE = "topup:finance_approve"
    TOPUP_EXECUTE = "topup:execute"

    # å¯¹è´¦æƒé™
    RECONCILIATION_CREATE = "reconciliation:create"
    RECONCILIATION_READ = "reconciliation:read"
    RECONCILIATION_UPDATE = "reconciliation:update"

    # ç”¨æˆ·æƒé™
    USER_CREATE = "user:create"
    USER_READ = "user:read"
    USER_UPDATE = "user:update"
    USER_DELETE = "user:delete"

    # ç³»ç»Ÿæƒé™
    SYSTEM_MONITOR = "system:monitor"
    SYSTEM_CONFIG = "system:config"

# æƒé™çŸ©é˜µå®šä¹‰
ROLE_PERMISSIONS: Dict[UserRole, Set[Permission]] = {
    UserRole.ADMIN: {
        # ç®¡ç†å‘˜æ‹¥æœ‰æ‰€æœ‰æƒé™
        Permission.PROJECT_CREATE, Permission.PROJECT_READ, Permission.PROJECT_UPDATE, Permission.PROJECT_DELETE,
        Permission.ACCOUNT_CREATE, Permission.ACCOUNT_READ, Permission.ACCOUNT_UPDATE, Permission.ACCOUNT_DELETE, Permission.ACCOUNT_ASSIGN,
        Permission.DAILY_REPORT_CREATE, Permission.DAILY_REPORT_READ, Permission.DAILY_REPORT_CONFIRM, Permission.DAILY_REPORT_UPDATE,
        Permission.TOPUP_CREATE, Permission.TOPUP_READ, Permission.TOPUP_CLERK_APPROVE, Permission.TOPUP_FINANCE_APPROVE, Permission.TOPUP_EXECUTE,
        Permission.RECONCILIATION_CREATE, Permission.RECONCILIATION_READ, Permission.RECONCILIATION_UPDATE,
        Permission.USER_CREATE, Permission.USER_READ, Permission.USER_UPDATE, Permission.USER_DELETE,
        Permission.SYSTEM_MONITOR, Permission.SYSTEM_CONFIG
    },

    UserRole.MANAGER: {
        Permission.PROJECT_CREATE, Permission.PROJECT_READ, Permission.PROJECT_UPDATE,
        Permission.ACCOUNT_READ, Permission.ACCOUNT_UPDATE, Permission.ACCOUNT_ASSIGN,
        Permission.DAILY_REPORT_READ, Permission.DAILY_REPORT_CONFIRM,
        Permission.TOPUP_READ, Permission.TOPUP_CLERK_APPROVE,
        Permission.RECONCILIATION_READ,
        Permission.USER_READ
    },

    UserRole.DATA_CLERK: {
        Permission.PROJECT_READ,
        Permission.ACCOUNT_READ, Permission.ACCOUNT_UPDATE,
        Permission.DAILY_REPORT_CREATE, Permission.DAILY_REPORT_READ, Permission.DAILY_REPORT_CONFIRM, Permission.DAILY_REPORT_UPDATE,
        Permission.TOPUP_CREATE, Permission.TOPUP_READ, Permission.TOPUP_CLERK_APPROVE,
        Permission.RECONCILIATION_CREATE, Permission.RECONCILIATION_READ, Permission.RECONCILIATION_UPDATE
    },

    UserRole.FINANCE: {
        Permission.PROJECT_READ,
        Permission.ACCOUNT_READ,
        Permission.DAILY_REPORT_READ,
        Permission.TOPUP_READ, Permission.TOPUP_FINANCE_APPROVE, Permission.TOPUP_EXECUTE,
        Permission.RECONCILIATION_CREATE, Permission.RECONCILIATION_READ, Permission.RECONCILIATION_UPDATE
    },

    UserRole.MEDIA_BUYER: {
        Permission.PROJECT_READ,
        Permission.ACCOUNT_READ,  # åªèƒ½è¯»å–åˆ†é…ç»™è‡ªå·±çš„è´¦æˆ·
        Permission.DAILY_REPORT_CREATE, Permission.DAILY_REPORT_READ, Permission.DAILY_REPORT_UPDATE,
        Permission.TOPUP_CREATE, Permission.TOPUP_READ  # åªèƒ½åˆ›å»ºå’ŒæŸ¥çœ‹è‡ªå·±çš„ç”³è¯·
    }
}
```

### 6.2 æƒé™æ£€æŸ¥å™¨
```python
# services/permission_checker.py
from typing import Optional
from sqlalchemy.orm import Session

class PermissionChecker:

    def __init__(self, db: Session):
        self.db = db

    def has_permission(self, user_role: UserRole, permission: Permission) -> bool:
        """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æŒ‡å®šæƒé™"""
        return permission in ROLE_PERMISSIONS.get(user_role, set())

    def can_access_project(self, user: User, project_id: str, action: str) -> bool:
        """æ£€æŸ¥é¡¹ç›®è®¿é—®æƒé™"""
        # ç®¡ç†å‘˜æ‹¥æœ‰æ‰€æœ‰æƒé™
        if user.role == UserRole.ADMIN.value:
            return True

        # è·å–é¡¹ç›®ä¿¡æ¯
        project = self.db.query(Project).filter(Project.id == project_id).first()
        if not project:
            return False

        # é¡¹ç›®ç»ç†æƒé™
        if user.role == UserRole.MANAGER.value and project.manager_id == user.id:
            return True

        # æŠ•æ‰‹æƒé™ - åªèƒ½è®¿é—®åˆ†é…ç»™è‡ªå·±çš„é¡¹ç›®
        if user.role == UserRole.MEDIA_BUYER.value:
            has_assigned_account = self.db.query(AdAccount).filter(
                AdAccount.project_id == project_id,
                AdAccount.assigned_user_id == user.id
            ).first()
            return has_assigned_account is not None

        # æ•°æ®å‘˜å’Œè´¢åŠ¡æƒé™ - å¯ä»¥è®¿é—®æ‰€æœ‰é¡¹ç›®ï¼ˆç”¨äºå®¡æ ¸å’Œå¯¹è´¦ï¼‰
        if user.role in [UserRole.DATA_CLERK.value, UserRole.FINANCE.value]:
            return True

        return False

    def can_access_account(self, user: User, account_id: str, action: str) -> bool:
        """æ£€æŸ¥è´¦æˆ·è®¿é—®æƒé™"""
        # ç®¡ç†å‘˜æ‹¥æœ‰æ‰€æœ‰æƒé™
        if user.role == UserRole.ADMIN.value:
            return True

        # è·å–è´¦æˆ·ä¿¡æ¯
        account = self.db.query(AdAccount).filter(AdAccount.id == account_id).first()
        if not account:
            return False

        # æˆ·ç®¡æƒé™
        if user.role in [UserRole.MANAGER.value, UserRole.DATA_CLERK.value]:
            return True

        # è´¢åŠ¡æƒé™ - åªè¯»
        if user.role == UserRole.FINANCE.value and action in ["read", "list"]:
            return True

        # æŠ•æ‰‹æƒé™ - åªèƒ½è®¿é—®åˆ†é…ç»™è‡ªå·±çš„è´¦æˆ·
        if user.role == UserRole.MEDIA_BUYER.value and account.assigned_user_id == user.id:
            return True

        return False

    def can_manage_topup(self, user: User, topup_id: str, action: str) -> bool:
        """æ£€æŸ¥å……å€¼ç®¡ç†æƒé™"""
        # ç®¡ç†å‘˜æ‹¥æœ‰æ‰€æœ‰æƒé™
        if user.role == UserRole.ADMIN.value:
            return True

        # è·å–å……å€¼ç”³è¯·ä¿¡æ¯
        topup = self.db.query(Topup).filter(Topup.id == topup_id).first()
        if not topup:
            return False

        # åˆ›å»ºæƒé™
        if action == "create":
            return user.role in [
                UserRole.MEDIA_BUYER.value,
                UserRole.DATA_CLERK.value,
                UserRole.MANAGER.value
            ]

        # æ•°æ®å‘˜å®¡æ‰¹æƒé™
        if action == "clerk_approve":
            return user.role in [UserRole.DATA_CLERK.value, UserRole.ADMIN.value]

        # è´¢åŠ¡å®¡æ‰¹æƒé™
        if action == "finance_approve":
            return user.role in [UserRole.FINANCE.value, UserRole.ADMIN.value]

        # æ‰§è¡Œæƒé™
        if action == "execute":
            return user.role in [UserRole.FINANCE.value, UserRole.ADMIN.value]

        # æŠ•æ‰‹åªèƒ½æŸ¥çœ‹è‡ªå·±çš„ç”³è¯·
        if action in ["read", "list"]:
            if user.role == UserRole.MEDIA_BUYER.value:
                return topup.requested_by == user.id
            else:
                return user.role in [
                    UserRole.DATA_CLERK.value,
                    UserRole.FINANCE.value,
                    UserRole.MANAGER.value
                ]

        return False

    def can_confirm_daily_report(self, user: User, report_id: str) -> bool:
        """æ£€æŸ¥æ—¥æŠ¥ç¡®è®¤æƒé™"""
        # ç®¡ç†å‘˜å’Œæ•°æ®å‘˜å¯ä»¥ç¡®è®¤
        if user.role in [UserRole.ADMIN.value, UserRole.DATA_CLERK.value]:
            return True

        return False

    def filter_accessible_projects(self, user: User, query):
        """è¿‡æ»¤ç”¨æˆ·å¯è®¿é—®çš„é¡¹ç›®"""
        if user.role == UserRole.ADMIN.value:
            return query

        if user.role == UserRole.MANAGER.value:
            return query.filter(Project.manager_id == user.id)

        if user.role == UserRole.MEDIA_BUYER.value:
            return query.join(AdAccount).filter(
                AdAccount.assigned_user_id == user.id
            )

        # æ•°æ®å‘˜å’Œè´¢åŠ¡å¯ä»¥è®¿é—®æ‰€æœ‰é¡¹ç›®
        return query

    def filter_accessible_accounts(self, user: User, query):
        """è¿‡æ»¤ç”¨æˆ·å¯è®¿é—®çš„è´¦æˆ·"""
        if user.role == UserRole.ADMIN.value:
            return query

        if user.role in [UserRole.MANAGER.value, UserRole.DATA_CLERK.value]:
            return query

        if user.role == UserRole.FINANCE.value:
            return query  # è´¢åŠ¡å¯ä»¥æŸ¥çœ‹æ‰€æœ‰è´¦æˆ·

        if user.role == UserRole.MEDIA_BUYER.value:
            return query.filter(AdAccount.assigned_user_id == user.id)

        return query.filter(False)  # å…¶ä»–è§’è‰²æ— æƒé™
```

### 6.3 æƒé™è£…é¥°å™¨
```python
# decorators/permission_decorators.py
from functools import wraps
from typing import List, Optional

def require_permissions(permissions: List[Permission]):
    """æƒé™éªŒè¯è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise PermissionError("ç”¨æˆ·æœªè®¤è¯")

            user_role = UserRole(current_user.role)

            # æ£€æŸ¥æƒé™
            for permission in permissions:
                if not permission_checker.has_permission(user_role, permission):
                    raise PermissionError(f"ç¼ºå°‘æƒé™: {permission.value}")

            return await func(*args, **kwargs)
        return wrapper
    return decorator

def require_resource_access(resource_type: str, action: str, resource_id_param: str = None):
    """èµ„æºè®¿é—®æƒé™è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise PermissionError("ç”¨æˆ·æœªè®¤è¯")

            # è·å–èµ„æºID
            resource_id = kwargs.get(resource_id_param)
            if not resource_id:
                raise ValueError(f"ç¼ºå°‘èµ„æºIDå‚æ•°: {resource_id_param}")

            # æ£€æŸ¥èµ„æºè®¿é—®æƒé™
            permission_checker = PermissionChecker(db)

            if resource_type == "project":
                if not permission_checker.can_access_project(current_user, resource_id, action):
                    raise PermissionError("æ— é¡¹ç›®è®¿é—®æƒé™")

            elif resource_type == "account":
                if not permission_checker.can_access_account(current_user, resource_id, action):
                    raise PermissionError("æ— è´¦æˆ·è®¿é—®æƒé™")

            elif resource_type == "topup":
                if not permission_checker.can_manage_topup(current_user, resource_id, action):
                    raise PermissionError("æ— å……å€¼ç®¡ç†æƒé™")

            elif resource_type == "daily_report":
                if action == "confirm" and not permission_checker.can_confirm_daily_report(current_user, resource_id):
                    raise PermissionError("æ— æ—¥æŠ¥ç¡®è®¤æƒé™")

            return await func(*args, **kwargs)
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@router.post("/projects")
@require_permissions([Permission.PROJECT_CREATE])
async def create_project(project: ProjectCreate, current_user: User = Depends(get_current_user)):
    """åˆ›å»ºé¡¹ç›®"""
    pass

@router.get("/projects/{project_id}")
@require_resource_access("project", "read", "project_id")
async def get_project(project_id: str, current_user: User = Depends(get_current_user)):
    """è·å–é¡¹ç›®è¯¦æƒ…"""
    pass

@router.put("/topups/{topup_id}/clerk-approval")
@require_resource_access("topup", "clerk_approve", "topup_id")
async def clerk_approve_topup(topup_id: str, approval: ClerkApproval, current_user: User = Depends(get_current_user)):
    """æ•°æ®å‘˜å®¡æ‰¹å……å€¼"""
    pass
```

### 6.4 åŠ¨æ€æƒé™é…ç½®
```python
# services/dynamic_permission.py
class DynamicPermissionService:

    def __init__(self, db: Session):
        self.db = db

    async def create_custom_role(self, role_name: str, permissions: List[Permission]) -> UserRole:
        """åˆ›å»ºè‡ªå®šä¹‰è§’è‰²"""
        # æ£€æŸ¥è§’è‰²æ˜¯å¦å·²å­˜åœ¨
        existing_role = self.db.query(Role).filter(Role.name == role_name).first()
        if existing_role:
            raise ValueError(f"è§’è‰² {role_name} å·²å­˜åœ¨")

        # åˆ›å»ºè§’è‰²
        new_role = Role(name=role_name, is_custom=True)
        self.db.add(new_role)
        self.db.commit()

        # åˆ†é…æƒé™
        for permission in permissions:
            role_permission = RolePermission(
                role_id=new_role.id,
                permission=permission.value
            )
            self.db.add(role_permission)

        self.db.commit()
        return UserRole(role_name)

    async def assign_role_to_user(self, user_id: str, role: UserRole):
        """ä¸ºç”¨æˆ·åˆ†é…è§’è‰²"""
        user = self.db.query(User).filter(User.id == user_id).first()
        if not user:
            raise ValueError("ç”¨æˆ·ä¸å­˜åœ¨")

        user.role = role.value
        self.db.commit()

    async def get_user_permissions(self, user_id: str) -> Set[Permission]:
        """è·å–ç”¨æˆ·æ‰€æœ‰æƒé™"""
        user = self.db.query(User).filter(User.id == user_id).first()
        if not user:
            return set()

        user_role = UserRole(user.role)

        # åŸºç¡€æƒé™
        base_permissions = ROLE_PERMISSIONS.get(user_role, set())

        # è‡ªå®šä¹‰è§’è‰²æƒé™
        if user.role not in [role.value for role in UserRole]:
            custom_permissions = self.db.query(RolePermission).join(Role).filter(
                Role.name == user.role
            ).all()

            for rp in custom_permissions:
                try:
                    permission = Permission(rp.permission)
                    base_permissions.add(permission)
                except ValueError:
                    continue  # å¿½ç•¥æ— æ•ˆæƒé™

        return base_permissions

    async def check_resource_specific_permission(
        self,
        user_id: str,
        resource_type: str,
        resource_id: str,
        action: str
    ) -> bool:
        """æ£€æŸ¥ç‰¹å®šèµ„æºæƒé™"""
        user = self.db.query(User).filter(User.id == user_id).first()
        if not user:
            return False

        # æ£€æŸ¥èµ„æºç‰¹å®šæƒé™
        resource_permission = self.db.query(ResourcePermission).filter(
            ResourcePermission.user_id == user_id,
            ResourcePermission.resource_type == resource_type,
            ResourcePermission.resource_id == resource_id,
            ResourcePermission.action == action
        ).first()

        if resource_permission:
            return resource_permission.granted

        # æ£€æŸ¥è§’è‰²æƒé™
        return await self._check_role_resource_permission(user, resource_type, resource_id, action)

    async def grant_resource_permission(
        self,
        user_id: str,
        resource_type: str,
        resource_id: str,
        action: str,
        granted_by: str
    ):
        """æˆäºˆç‰¹å®šèµ„æºæƒé™"""
        # æ£€æŸ¥æƒé™æ˜¯å¦å­˜åœ¨
        existing = self.db.query(ResourcePermission).filter(
            ResourcePermission.user_id == user_id,
            ResourcePermission.resource_type == resource_type,
            ResourcePermission.resource_id == resource_id,
            ResourcePermission.action == action
        ).first()

        if existing:
            existing.granted = True
            existing.granted_at = datetime.utcnow()
            existing.granted_by = granted_by
        else:
            new_permission = ResourcePermission(
                user_id=user_id,
                resource_type=resource_type,
                resource_id=resource_id,
                action=action,
                granted=True,
                granted_at=datetime.utcnow(),
                granted_by=granted_by
            )
            self.db.add(new_permission)

        self.db.commit()
```

---

## ä¸ƒã€AIé¢„æµ‹æ¨¡å—

### 7.1 AIé¢„æµ‹å¼•æ“æ¶æ„
```python
# ai/predictor_engine.py
from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Any
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error
import joblib
import logging

logger = logging.getLogger(__name__)

class BasePredictor(ABC):
    """é¢„æµ‹å™¨åŸºç±»"""

    def __init__(self, model_path: str = None):
        self.model = None
        self.scaler = StandardScaler()
        self.model_path = model_path
        self.is_trained = False

    @abstractmethod
    def prepare_features(self, data: Dict) -> np.ndarray:
        """å‡†å¤‡ç‰¹å¾æ•°æ®"""
        pass

    @abstractmethod
    def prepare_target(self, data: Dict) -> np.ndarray:
        """å‡†å¤‡ç›®æ ‡æ•°æ®"""
        pass

    @abstractmethod
    def train(self, training_data: List[Dict]) -> Dict:
        """è®­ç»ƒæ¨¡å‹"""
        pass

    @abstractmethod
    def predict(self, features: Dict) -> Dict:
        """è¿›è¡Œé¢„æµ‹"""
        pass

    def save_model(self):
        """ä¿å­˜æ¨¡å‹"""
        if self.model and self.model_path:
            joblib.dump({
                'model': self.model,
                'scaler': self.scaler,
                'is_trained': self.is_trained
            }, self.model_path)
            logger.info(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {self.model_path}")

    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        if self.model_path:
            try:
                model_data = joblib.load(self.model_path)
                self.model = model_data['model']
                self.scaler = model_data['scaler']
                self.is_trained = model_data['is_trained']
                logger.info(f"æ¨¡å‹å·²ä» {self.model_path} åŠ è½½")
                return True
            except Exception as e:
                logger.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
                return False
        return False
```

### 7.2 è´¦æˆ·å¯¿å‘½é¢„æµ‹å™¨
```python
# ai/account_lifetime_predictor.py
class AccountLifetimePredictor(BasePredictor):
    """è´¦æˆ·å¯¿å‘½é¢„æµ‹å™¨"""

    def __init__(self, model_path: str = "models/account_lifetime.pkl"):
        super().__init__(model_path)
        self.feature_columns = [
            'channel_quality_score',
            'service_fee_rate',
            'account_age_days',
            'daily_spend_avg',
            'daily_spend_std',
            'lead_conversion_rate',
            'account_type_score',
            'country_risk_score',
            'setup_fee_paid',
            'has_violations'
        ]

    def prepare_features(self, account_data: Dict) -> np.ndarray:
        """å‡†å¤‡è´¦æˆ·ç‰¹å¾æ•°æ®"""
        features = []

        # æ¸ é“è´¨é‡åˆ†æ•°
        features.append(account_data.get('channel_quality_score', 5.0))

        # æœåŠ¡è´¹ç‡
        features.append(account_data.get('service_fee_rate', 0.1))

        # è´¦æˆ·å¹´é¾„ï¼ˆå¤©ï¼‰
        if 'created_date' in account_data and account_data['created_date']:
            age_days = (datetime.utcnow() - account_data['created_date']).days
        else:
            age_days = 0
        features.append(age_days)

        # æ—¥å‡æ¶ˆè€—ç»Ÿè®¡
        spend_stats = account_data.get('spend_statistics', {})
        features.append(spend_stats.get('daily_avg', 0))
        features.append(spend_stats.get('daily_std', 0))

        # è½¬åŒ–ç‡
        features.append(account_data.get('lead_conversion_rate', 0))

        # è´¦æˆ·ç±»å‹åˆ†æ•°
        account_type = account_data.get('account_type', 'standard')
        type_scores = {'standard': 1.0, 'premium': 1.5, 'enterprise': 2.0}
        features.append(type_scores.get(account_type, 1.0))

        # å›½å®¶é£é™©åˆ†æ•°
        country_risk = {
            'US': 1.0, 'CA': 1.0, 'GB': 1.0, 'AU': 1.0,
            'DE': 0.9, 'FR': 0.9, 'JP': 0.9,
            'CN': 0.7, 'IN': 0.7, 'BR': 0.7,
            'OTHER': 0.5
        }
        country = account_data.get('country', 'OTHER')
        features.append(country_risk.get(country, 0.5))

        # æ˜¯å¦å·²ä»˜å¼€æˆ·è´¹
        features.append(1.0 if account_data.get('setup_fee_paid', False) else 0.0)

        # æ˜¯å¦æœ‰è¿è§„è®°å½•
        features.append(1.0 if account_data.get('has_violations', False) else 0.0)

        return np.array(features).reshape(1, -1)

    def prepare_target(self, account_data: Dict) -> np.ndarray:
        """å‡†å¤‡ç›®æ ‡æ•°æ®ï¼ˆè´¦æˆ·å¯¿å‘½ï¼‰"""
        if 'lifetime_days' in account_data:
            return np.array([account_data['lifetime_days']])
        return np.array([0])

    def train(self, training_data: List[Dict]) -> Dict:
        """è®­ç»ƒè´¦æˆ·å¯¿å‘½é¢„æµ‹æ¨¡å‹"""
        logger.info(f"å¼€å§‹è®­ç»ƒè´¦æˆ·å¯¿å‘½é¢„æµ‹æ¨¡å‹ï¼Œæ•°æ®é‡: {len(training_data)}")

        # å‡†å¤‡è®­ç»ƒæ•°æ®
        X = []
        y = []

        for data in training_data:
            if 'lifetime_days' in data and data['lifetime_days'] > 0:
                features = self.prepare_features(data).flatten()
                X.append(features)
                y.append(data['lifetime_days'])

        if len(X) < 10:
            raise ValueError("è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œè‡³å°‘éœ€è¦10ä¸ªæ ·æœ¬")

        X = np.array(X)
        y = np.array(y)

        # æ•°æ®æ ‡å‡†åŒ–
        X_scaled = self.scaler.fit_transform(X)

        # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42
        )

        # è®­ç»ƒéšæœºæ£®æ—å›å½’æ¨¡å‹
        self.model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            n_jobs=-1
        )

        self.model.fit(X_train, y_train)

        # è¯„ä¼°æ¨¡å‹
        train_score = self.model.score(X_train, y_train)
        test_score = self.model.score(X_test, y_test)
        y_pred = self.model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)

        self.is_trained = True

        # ä¿å­˜æ¨¡å‹
        self.save_model()

        training_report = {
            'samples_count': len(X),
            'train_score': train_score,
            'test_score': test_score,
            'mse': mse,
            'feature_importance': dict(zip(self.feature_columns, self.model.feature_importances_))
        }

        logger.info(f"æ¨¡å‹è®­ç»ƒå®Œæˆ: {training_report}")
        return training_report

    def predict(self, account_data: Dict) -> Dict:
        """é¢„æµ‹è´¦æˆ·å¯¿å‘½"""
        if not self.is_trained:
            if not self.load_model():
                raise ValueError("æ¨¡å‹æœªè®­ç»ƒä¸”æ— æ³•åŠ è½½")

        try:
            # å‡†å¤‡ç‰¹å¾
            features = self.prepare_features(account_data)
            features_scaled = self.scaler.transform(features)

            # é¢„æµ‹å¯¿å‘½
            predicted_days = self.model.predict(features_scaled)[0]

            # è®¡ç®—ç½®ä¿¡åº¦
            individual_predictions = []
            for estimator in self.model.estimators_:
                pred = estimator.predict(features_scaled)[0]
                individual_predictions.append(pred)

            confidence = 1.0 - (np.std(individual_predictions) / np.mean(individual_predictions))
            confidence = max(0, min(1, confidence))  # é™åˆ¶åœ¨0-1ä¹‹é—´

            # é£é™©ç­‰çº§åˆ†ç±»
            if predicted_days >= 60:
                risk_level = "low"
                risk_score = 0.2
            elif predicted_days >= 30:
                risk_level = "medium"
                risk_score = 0.5
            elif predicted_days >= 14:
                risk_level = "high"
                risk_score = 0.8
            else:
                risk_level = "critical"
                risk_score = 0.9

            # ç”Ÿæˆå»ºè®®
            suggestions = self._generate_suggestions(predicted_days, risk_level, account_data)

            return {
                'predicted_lifetime_days': int(predicted_days),
                'risk_level': risk_level,
                'risk_score': round(risk_score, 3),
                'confidence': round(confidence, 3),
                'suggestions': suggestions,
                'prediction_date': datetime.utcnow().isoformat(),
                'model_version': '1.0'
            }

        except Exception as e:
            logger.error(f"è´¦æˆ·å¯¿å‘½é¢„æµ‹å¤±è´¥: {e}")
            return {
                'error': 'prediction_failed',
                'message': str(e)
            }

    def _generate_suggestions(self, predicted_days: float, risk_level: str, account_data: Dict) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []

        if risk_level == "critical":
            suggestions.append("ç«‹å³æ£€æŸ¥è´¦æˆ·çŠ¶æ€ï¼Œå‡†å¤‡å¤‡ç”¨è´¦æˆ·")
            suggestions.append("å‡å°‘å½“æ—¥æ¶ˆè€—ï¼Œå»¶é•¿è´¦æˆ·å¯¿å‘½")
            suggestions.append("è”ç³»æ¸ é“å•†ç¡®è®¤è´¦æˆ·å¥åº·çŠ¶å†µ")

        elif risk_level == "high":
            suggestions.append("å¯†åˆ‡ç›‘æ§è´¦æˆ·è¡¨ç°å’Œæ¶ˆè€—è¶‹åŠ¿")
            suggestions.append("é¿å…å¤§é¢å……å€¼ï¼Œé‡‡ç”¨å°é¢å¤šæ¬¡å……å€¼ç­–ç•¥")
            suggestions.append("å‡†å¤‡å¤‡ç”¨è´¦æˆ·ä»¥å¤‡ä¸æ—¶ä¹‹éœ€")

        elif risk_level == "medium":
            suggestions.append("ä¿æŒå½“å‰æ¶ˆè€—æ°´å¹³ï¼Œå®šæœŸè¯„ä¼°è´¦æˆ·çŠ¶æ€")
            suggestions.append("ä¼˜åŒ–å¹¿å‘Šç´ æï¼Œæé«˜è½¬åŒ–æ•ˆç‡")

        else:  # low risk
            suggestions.append("è´¦æˆ·çŠ¶æ€è‰¯å¥½ï¼Œå¯æ­£å¸¸æŠ•æ”¾")
            suggestions.append("å¯é€‚å½“å¢åŠ æ¶ˆè€—ä»¥æµ‹è¯•è´¦æˆ·ä¸Šé™")

        # åŸºäºæ¸ é“è´¨é‡çš„å»ºè®®
        channel_quality = account_data.get('channel_quality_score', 5.0)
        if channel_quality < 6.0:
            suggestions.append("è€ƒè™‘æ›´æ¢æ›´é«˜è´¨é‡çš„æ¸ é“å•†")

        # åŸºäºè½¬åŒ–ç‡çš„å»ºè®®
        conversion_rate = account_data.get('lead_conversion_rate', 0)
        if conversion_rate < 0.01:
            suggestions.append("ä¼˜åŒ–å¹¿å‘Šå®šå‘å’Œåˆ›æ„ä»¥æé«˜è½¬åŒ–ç‡")

        return suggestions

# ä½¿ç”¨ç¤ºä¾‹
async def predict_account_lifetime(account_id: str) -> Dict:
    """é¢„æµ‹è´¦æˆ·å¯¿å‘½çš„APIç«¯ç‚¹"""
    # è·å–è´¦æˆ·æ•°æ®
    account = await get_account_with_statistics(account_id)
    if not account:
        raise ValueError("è´¦æˆ·ä¸å­˜åœ¨")

    # åˆ›å»ºé¢„æµ‹å™¨
    predictor = AccountLifetimePredictor()

    # è¿›è¡Œé¢„æµ‹
    prediction = predictor.predict(account.dict())

    # ä¿å­˜é¢„æµ‹ç»“æœ
    await save_prediction_result(account_id, "lifetime", prediction)

    return prediction
```

### 7.3 å¼‚å¸¸æ£€æµ‹å™¨
```python
# ai/anomaly_detector.py
class DailyReportAnomalyDetector(BasePredictor):
    """æ—¥æŠ¥å¼‚å¸¸æ£€æµ‹å™¨"""

    def __init__(self, model_path: str = "models/anomaly_detector.pkl"):
        super().__init__(model_path)
        self.feature_columns = [
            'spend_amount',
            'leads_count',
            'cpl',
            'spend_vs_7day_avg_ratio',
            'leads_vs_7day_avg_ratio',
            'cpl_vs_7day_avg_ratio',
            'day_of_week',
            'is_weekend',
            'account_age_days',
            'historical_volatility'
        ]

    def prepare_features(self, report_data: Dict) -> np.ndarray:
        """å‡†å¤‡æ—¥æŠ¥ç‰¹å¾æ•°æ®"""
        features = []

        # åŸºç¡€æ•°æ®
        features.append(report_data.get('spend', 0))
        features.append(report_data.get('leads_submitted', 0))

        # è®¡ç®—CPL
        spend = report_data.get('spend', 0)
        leads = report_data.get('leads_submitted', 0)
        cpl = spend / leads if leads > 0 else 0
        features.append(cpl)

        # ä¸7å¤©å¹³å‡å€¼çš„æ¯”å€¼
        historical_stats = report_data.get('historical_stats', {})
        features.append(spend / historical_stats.get('spend_7day_avg', 1) if historical_stats.get('spend_7day_avg', 0) > 0 else 1)
        features.append(leads / historical_stats.get('leads_7day_avg', 1) if historical_stats.get('leads_7day_avg', 0) > 0 else 1)
        features.append(cpl / historical_stats.get('cpl_7day_avg', 1) if historical_stats.get('cpl_7day_avg', 0) > 0 else 1)

        # æ—¶é—´ç‰¹å¾
        report_date = report_data.get('date')
        if report_date:
            date_obj = datetime.strptime(report_date, '%Y-%m-%d').date()
            features.append(date_obj.weekday())  # 0=Monday, 6=Sunday
            features.append(1.0 if date_obj.weekday() >= 5 else 0.0)  # æ˜¯å¦å‘¨æœ«
        else:
            features.append(0)
            features.append(0)

        # è´¦æˆ·å¹´é¾„
        account_created = report_data.get('account_created_date')
        if account_created and report_date:
            age_days = (datetime.strptime(report_date, '%Y-%m-%d').date() - account_created.date()).days
            features.append(age_days)
        else:
            features.append(0)

        # å†å²æ³¢åŠ¨æ€§
        features.append(historical_stats.get('spend_volatility', 0))

        return np.array(features).reshape(1, -1)

    def prepare_target(self, data: Dict) -> np.ndarray:
        """å‡†å¤‡ç›®æ ‡æ•°æ®ï¼ˆæ˜¯å¦å¼‚å¸¸ï¼‰"""
        # è¿™é‡Œä½¿ç”¨è§„åˆ™æ ‡æ³¨å¼‚å¸¸ï¼Œå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨äººå·¥æ ‡æ³¨
        is_anomaly = 0

        spend = data.get('spend', 0)
        leads = data.get('leads_submitted', 0)
        cpl = spend / leads if leads > 0 else 0

        historical_stats = data.get('historical_stats', {})

        # æ¶ˆè€—å¼‚å¸¸æ£€æµ‹
        if historical_stats.get('spend_7day_avg', 0) > 0:
            spend_ratio = spend / historical_stats['spend_7day_avg']
            if spend_ratio > 3 or spend_ratio < 0.1:  # æ¶ˆè€—å‰§çƒˆæ³¢åŠ¨
                is_anomaly = 1

        # CPLå¼‚å¸¸æ£€æµ‹
        if historical_stats.get('cpl_7day_avg', 0) > 0:
            cpl_ratio = cpl / historical_stats['cpl_7day_avg']
            if cpl_ratio > 5 or cpl_ratio < 0.2:  # CPLå‰§çƒˆæ³¢åŠ¨
                is_anomaly = 1

        # é›¶æ¶ˆè€—å¼‚å¸¸
        if spend == 0 and historical_stats.get('spend_7day_avg', 0) > 0:
            is_anomaly = 1

        return np.array([is_anomaly])

    def train(self, training_data: List[Dict]) -> Dict:
        """è®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹"""
        logger.info(f"å¼€å§‹è®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹ï¼Œæ•°æ®é‡: {len(training_data)}")

        # å‡†å¤‡è®­ç»ƒæ•°æ®
        X = []
        y = []

        for data in training_data:
            features = self.prepare_features(data).flatten()
            X.append(features)
            target = self.prepare_target(data)
            y.append(target[0])

        if len(X) < 50:
            raise ValueError("å¼‚å¸¸æ£€æµ‹è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œè‡³å°‘éœ€è¦50ä¸ªæ ·æœ¬")

        X = np.array(X)
        y = np.array(y)

        # æ£€æŸ¥å¼‚å¸¸æ ·æœ¬æ¯”ä¾‹
        anomaly_ratio = np.mean(y)
        logger.info(f"å¼‚å¸¸æ ·æœ¬æ¯”ä¾‹: {anomaly_ratio:.2%}")

        # æ•°æ®æ ‡å‡†åŒ–
        X_scaled = self.scaler.fit_transform(X)

        # ä½¿ç”¨Isolation Forestè¿›è¡Œå¼‚å¸¸æ£€æµ‹
        from sklearn.ensemble import IsolationForest

        self.model = IsolationForest(
            contamination=min(max(anomaly_ratio, 0.01), 0.5),  # æ±¡æŸ“ç‡åœ¨1%-50%ä¹‹é—´
            random_state=42,
            n_jobs=-1
        )

        self.model.fit(X_scaled)

        # è¯„ä¼°æ¨¡å‹
        predictions = self.model.predict(X_scaled)
        # Isolation Forestè¿”å›-1è¡¨ç¤ºå¼‚å¸¸ï¼Œ1è¡¨ç¤ºæ­£å¸¸
        binary_predictions = (predictions == -1).astype(int)

        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(y, binary_predictions)

        self.is_trained = True
        self.save_model()

        training_report = {
            'samples_count': len(X),
            'anomaly_ratio': anomaly_ratio,
            'accuracy': accuracy,
            'model_type': 'IsolationForest'
        }

        logger.info(f"å¼‚å¸¸æ£€æµ‹æ¨¡å‹è®­ç»ƒå®Œæˆ: {training_report}")
        return training_report

    def detect_anomalies(self, report_data: Dict) -> Dict:
        """æ£€æµ‹æ—¥æŠ¥å¼‚å¸¸"""
        if not self.is_trained:
            if not self.load_model():
                raise ValueError("æ¨¡å‹æœªè®­ç»ƒä¸”æ— æ³•åŠ è½½")

        try:
            # å‡†å¤‡ç‰¹å¾
            features = self.prepare_features(report_data)
            features_scaled = self.scaler.transform(features)

            # é¢„æµ‹å¼‚å¸¸
            prediction = self.model.predict(features_scaled)[0]
            anomaly_score = self.model.decision_function(features_scaled)[0]

            # è½¬æ¢ä¸ºå¼‚å¸¸æ¦‚ç‡ï¼ˆè¶Šä½è¶Šå¼‚å¸¸ï¼‰
            anomaly_probability = 1.0 / (1.0 + np.exp(anomaly_score))

            is_anomaly = prediction == -1

            # åˆ†æå¼‚å¸¸åŸå› 
            anomaly_reasons = self._analyze_anomaly_reasons(report_data, anomaly_score)

            # ç”Ÿæˆå»ºè®®
            suggestions = self._generate_anomaly_suggestions(report_data, anomaly_reasons)

            return {
                'is_anomaly': is_anomaly,
                'anomaly_score': float(anomaly_score),
                'anomaly_probability': round(anomaly_probability, 4),
                'severity': self._calculate_severity(anomaly_score),
                'reasons': anomaly_reasons,
                'suggestions': suggestions,
                'detection_date': datetime.utcnow().isoformat(),
                'model_version': '1.0'
            }

        except Exception as e:
            logger.error(f"å¼‚å¸¸æ£€æµ‹å¤±è´¥: {e}")
            return {
                'error': 'detection_failed',
                'message': str(e)
            }

    def _analyze_anomaly_reasons(self, report_data: Dict, anomaly_score: float) -> List[str]:
        """åˆ†æå¼‚å¸¸åŸå› """
        reasons = []

        spend = report_data.get('spend', 0)
        leads = report_data.get('leads_submitted', 0)
        cpl = spend / leads if leads > 0 else 0

        historical_stats = report_data.get('historical_stats', {})

        # æ¶ˆè€—åˆ†æ
        if historical_stats.get('spend_7day_avg', 0) > 0:
            spend_ratio = spend / historical_stats['spend_7day_avg']
            if spend_ratio > 2:
                reasons.append(f"æ¶ˆè€—å¼‚å¸¸é«˜ï¼Œä¸º7å¤©å¹³å‡å€¼çš„{spend_ratio:.1f}å€")
            elif spend_ratio < 0.2:
                reasons.append(f"æ¶ˆè€—å¼‚å¸¸ä½ï¼Œä»…ä¸º7å¤©å¹³å‡å€¼çš„{spend_ratio:.1f}å€")

        # ç²‰æ•°åˆ†æ
        if historical_stats.get('leads_7day_avg', 0) > 0:
            leads_ratio = leads / historical_stats['leads_7day_avg']
            if leads_ratio > 2:
                reasons.append(f"ç²‰æ•°å¼‚å¸¸é«˜ï¼Œä¸º7å¤©å¹³å‡å€¼çš„{leads_ratio:.1f}å€")
            elif leads_ratio < 0.2 and leads > 0:
                reasons.append(f"ç²‰æ•°å¼‚å¸¸ä½ï¼Œä»…ä¸º7å¤©å¹³å‡å€¼çš„{leads_ratio:.1f}å€")

        # CPLåˆ†æ
        if historical_stats.get('cpl_7day_avg', 0) > 0:
            cpl_ratio = cpl / historical_stats['cpl_7day_avg']
            if cpl_ratio > 3:
                reasons.append(f"å•ç²‰æˆæœ¬å¼‚å¸¸é«˜ï¼Œä¸º7å¤©å¹³å‡å€¼çš„{cpl_ratio:.1f}å€")
            elif cpl_ratio < 0.3:
                reasons.append(f"å•ç²‰æˆæœ¬å¼‚å¸¸ä½ï¼Œä¸º7å¤©å¹³å‡å€¼çš„{cpl_ratio:.1f}å€")

        # é›¶æ¶ˆè€—åˆ†æ
        if spend == 0 and historical_stats.get('spend_7day_avg', 0) > 50:
            reasons.append("é›¶æ¶ˆè€—ä½†å†å²æœ‰æ­£å¸¸æ¶ˆè€—è®°å½•")

        # æ—¶é—´ç‰¹å¾åˆ†æ
        report_date = report_data.get('date')
        if report_date:
            date_obj = datetime.strptime(report_date, '%Y-%m-%d').date()
            if date_obj.weekday() >= 5:  # å‘¨æœ«
                if spend > historical_stats.get('spend_7day_avg', 0) * 2:
                    reasons.append("å‘¨æœ«æ¶ˆè€—å¼‚å¸¸åé«˜")

        return reasons if reasons else ["æ¨¡å‹æ£€æµ‹åˆ°å¼‚å¸¸æ¨¡å¼ï¼Œä½†å…·ä½“åŸå› ä¸æ˜ç¡®"]

    def _generate_anomaly_suggestions(self, report_data: Dict, reasons: List[str]) -> List[str]:
        """ç”Ÿæˆå¼‚å¸¸å¤„ç†å»ºè®®"""
        suggestions = []

        # åŸºäºå¼‚å¸¸åŸå› ç”Ÿæˆå»ºè®®
        for reason in reasons:
            if "æ¶ˆè€—å¼‚å¸¸é«˜" in reason:
                suggestions.append("æ£€æŸ¥å¹¿å‘Šè®¾ç½®ï¼Œé¿å…é¢„ç®—è¶…æ”¯")
                suggestions.append("ç¡®è®¤æ˜¯å¦ä¸ºæœ‰æ„çš„å¤§é¢æŠ•æ”¾")

            elif "æ¶ˆè€—å¼‚å¸¸ä½" in reason:
                suggestions.append("æ£€æŸ¥è´¦æˆ·çŠ¶æ€å’Œå¹¿å‘ŠæŠ•æ”¾çŠ¶æ€")
                suggestions.append("ç¡®è®¤æ”¯ä»˜æ–¹å¼å’Œè´¦æˆ·ä½™é¢")

            elif "ç²‰æ•°å¼‚å¸¸é«˜" in reason:
                suggestions.append("éªŒè¯ç²‰æ•°æ¥æºçš„å‡†ç¡®æ€§")
                suggestions.append("æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®ç»Ÿè®¡é”™è¯¯")

            elif "ç²‰æ•°å¼‚å¸¸ä½" in reason:
                suggestions.append("ä¼˜åŒ–å¹¿å‘Šå®šå‘å’Œåˆ›æ„")
                suggestions.append("æ£€æŸ¥è½åœ°é¡µå’Œè½¬åŒ–è¿½è¸ª")

            elif "å•ç²‰æˆæœ¬å¼‚å¸¸é«˜" in reason:
                suggestions.append("æš‚åœé«˜æˆæœ¬çš„å¹¿å‘Šç»„")
                suggestions.append("ä¼˜åŒ–å¹¿å‘Šç´ æå’Œç›®æ ‡å—ä¼—")

            elif "é›¶æ¶ˆè€—" in reason:
                suggestions.append("ç«‹å³æ£€æŸ¥è´¦æˆ·æ˜¯å¦è¢«é™åˆ¶")
                suggestions.append("è”ç³»æ¸ é“å•†ç¡®è®¤è´¦æˆ·çŠ¶æ€")

        # é€šç”¨å»ºè®®
        suggestions.append("å¦‚æŒç»­å¼‚å¸¸ï¼Œå»ºè®®åŠæ—¶è”ç³»æŠ€æœ¯æ”¯æŒ")

        return list(set(suggestions))  # å»é‡

    def _calculate_severity(self, anomaly_score: float) -> str:
        """è®¡ç®—å¼‚å¸¸ä¸¥é‡ç¨‹åº¦"""
        if anomaly_score < -0.5:
            return "critical"
        elif anomaly_score < -0.2:
            return "high"
        elif anomaly_score < 0:
            return "medium"
        else:
            return "low"

# AIé¢„æµ‹æœåŠ¡
class AIPredictionService:

    def __init__(self):
        self.lifetime_predictor = AccountLifetimePredictor()
        self.anomaly_detector = DailyReportAnomalyDetector()

    async def predict_account_lifetime(self, account_id: str) -> Dict:
        """é¢„æµ‹è´¦æˆ·å¯¿å‘½"""
        try:
            # è·å–è´¦æˆ·æ•°æ®
            account_data = await self._get_account_data(account_id)

            # è¿›è¡Œé¢„æµ‹
            prediction = self.lifetime_predictor.predict(account_data)

            # è®°å½•é¢„æµ‹æ—¥å¿—
            await self._log_prediction(account_id, "lifetime", prediction)

            return prediction

        except Exception as e:
            logger.error(f"è´¦æˆ·å¯¿å‘½é¢„æµ‹å¤±è´¥: {e}")
            return {
                'error': 'prediction_failed',
                'message': str(e)
            }

    async def detect_daily_report_anomalies(self, report_id: str) -> Dict:
        """æ£€æµ‹æ—¥æŠ¥å¼‚å¸¸"""
        try:
            # è·å–æ—¥æŠ¥æ•°æ®
            report_data = await self._get_daily_report_data(report_id)

            # è¿›è¡Œå¼‚å¸¸æ£€æµ‹
            detection_result = self.anomaly_detector.detect_anomalies(report_data)

            # å¦‚æœæ£€æµ‹åˆ°å¼‚å¸¸ï¼Œä¿å­˜ç»“æœå¹¶é€šçŸ¥
            if detection_result.get('is_anomaly'):
                await self._save_anomaly_result(report_id, detection_result)
                await self._notify_anomaly(report_id, detection_result)

            return detection_result

        except Exception as e:
            logger.error(f"æ—¥æŠ¥å¼‚å¸¸æ£€æµ‹å¤±è´¥: {e}")
            return {
                'error': 'detection_failed',
                'message': str(e)
            }

    async def batch_predict_lifetimes(self, account_ids: List[str]) -> Dict:
        """æ‰¹é‡é¢„æµ‹è´¦æˆ·å¯¿å‘½"""
        results = {}

        for account_id in account_ids:
            try:
                prediction = await self.predict_account_lifetime(account_id)
                results[account_id] = prediction
            except Exception as e:
                results[account_id] = {
                    'error': 'prediction_failed',
                    'message': str(e)
                }

        return {
            'predictions': results,
            'total_accounts': len(account_ids),
            'successful_predictions': len([r for r in results.values() if 'error' not in r]),
            'prediction_date': datetime.utcnow().isoformat()
        }

    async def retrain_models(self) -> Dict:
        """é‡æ–°è®­ç»ƒAIæ¨¡å‹"""
        results = {}

        try:
            # é‡æ–°è®­ç»ƒå¯¿å‘½é¢„æµ‹æ¨¡å‹
            lifetime_training_data = await self._get_lifetime_training_data()
            lifetime_result = self.lifetime_predictor.train(lifetime_training_data)
            results['lifetime_predictor'] = lifetime_result

        except Exception as e:
            results['lifetime_predictor'] = {
                'error': 'training_failed',
                'message': str(e)
            }

        try:
            # é‡æ–°è®­ç»ƒå¼‚å¸¸æ£€æµ‹æ¨¡å‹
            anomaly_training_data = await self._get_anomaly_training_data()
            anomaly_result = self.anomaly_detector.train(anomaly_training_data)
            results['anomaly_detector'] = anomaly_result

        except Exception as e:
            results['anomaly_detector'] = {
                'error': 'training_failed',
                'message': str(e)
            }

        results['retrain_date'] = datetime.utcnow().isoformat()
        return results
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### å¼€å‘å›¢é˜Ÿè”ç³»æ–¹å¼
- **æŠ€æœ¯è´Ÿè´£äºº**: [å¾…å¡«å†™]
- **æ¶æ„å¸ˆ**: [å¾…å¡«å†™]
- **å‰ç«¯è´Ÿè´£äºº**: [å¾…å¡«å†™]
- **åç«¯è´Ÿè´£äºº**: [å¾…å¡«å†™]
- **AIç®—æ³•è´Ÿè´£äºº**: [å¾…å¡«å†™]
- **è¿ç»´è´Ÿè´£äºº**: [å¾…å¡«å†™]

### ç´§æ€¥è”ç³»
- **ç³»ç»Ÿæ•…éšœ**: ç«‹å³è”ç³»æŠ€æœ¯è´Ÿè´£äºº
- **å®‰å…¨äº‹ä»¶**: ç«‹å³è”ç³»å®‰å…¨å›¢é˜Ÿ
- **æ•°æ®é—®é¢˜**: è”ç³»DBAå›¢é˜Ÿ
- **AIæ¨¡å‹é—®é¢˜**: è”ç³»ç®—æ³•å›¢é˜Ÿ

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.2 å®Œæ•´ç‰ˆ
**æœ€åæ›´æ–°**: 2025-11-10
**ç»´æŠ¤äºº**: ç³»ç»Ÿæ¶æ„å›¢é˜Ÿ
**æ–‡æ¡£çŠ¶æ€**: ç”Ÿäº§å°±ç»ª