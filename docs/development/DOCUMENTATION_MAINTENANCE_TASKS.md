# æ–‡æ¡£ç»´æŠ¤ä»»åŠ¡æ¸…å•

## ğŸ“š æ–‡æ¡£ä½“ç³»æ¦‚è§ˆ

### æ–‡æ¡£ç»“æ„å±‚æ¬¡
```
docs/
â”œâ”€â”€ development/           # å¼€å‘æ–‡æ¡£
â”‚   â”œâ”€â”€ æ¥å£å¼€å‘æµç¨‹æ–‡æ¡£
â”‚   â”œâ”€â”€ ä»£ç è´¨é‡æ£€æŸ¥ä»»åŠ¡
â”‚   â”œâ”€â”€ æµ‹è¯•å®æ–½ä»»åŠ¡æ¸…å•
â”‚   â””â”€â”€ éƒ¨ç½²å‘å¸ƒä»»åŠ¡åˆ—è¡¨
â”œâ”€â”€ api/                  # APIæ–‡æ¡£
â”‚   â”œâ”€â”€ v1/              # ç‰ˆæœ¬åŒ–APIæ–‡æ¡£
â”‚   â””â”€â”€ openapi/         # OpenAPIè§„èŒƒ
â”œâ”€â”€ user/                # ç”¨æˆ·æ–‡æ¡£
â”œâ”€â”€ deployment/          # éƒ¨ç½²æ–‡æ¡£
â””â”€â”€ maintenance/         # ç»´æŠ¤æ–‡æ¡£
```

### æ–‡æ¡£ç±»å‹åˆ†ç±»
- **å¼€å‘æ–‡æ¡£**: æŠ€æœ¯è§„èŒƒã€å¼€å‘æŒ‡å—ã€æœ€ä½³å®è·µ
- **APIæ–‡æ¡£**: æ¥å£è§„èŒƒã€ä½¿ç”¨ç¤ºä¾‹ã€é”™è¯¯ç è¯´æ˜
- **ç”¨æˆ·æ–‡æ¡£**: ä½¿ç”¨æ‰‹å†Œã€å¸¸è§é—®é¢˜ã€æ“ä½œæŒ‡å—
- **è¿ç»´æ–‡æ¡£**: éƒ¨ç½²æŒ‡å—ã€ç›‘æ§é…ç½®ã€æ•…éšœå¤„ç†
- **ç»´æŠ¤æ–‡æ¡£**: ç‰ˆæœ¬æ›´æ–°ã€å˜æ›´è®°å½•ã€ç»´æŠ¤æµç¨‹

---

## ğŸ¯ é˜¶æ®µä¸€ï¼šæ–‡æ¡£è§„åˆ’ä¸æ¶æ„

### ä»»åŠ¡1.1ï¼šæ–‡æ¡£æ¶æ„è®¾è®¡
**æ—¶é—´é¢„ä¼°**: 1å¤©
**è´Ÿè´£è§’è‰²**: æŠ€æœ¯å†™ä½œå·¥ç¨‹å¸ˆ + æ¶æ„å¸ˆ

#### æ–‡æ¡£æ¶æ„è¦æ±‚
- [ ] æ–‡æ¡£åˆ†ç±»ä½“ç³»è®¾è®¡
- [ ] å¯¼èˆªç»“æ„è§„åˆ’
- [ ] ç‰ˆæœ¬ç®¡ç†ç­–ç•¥
- [ ] æœç´¢ä¼˜åŒ–æ–¹æ¡ˆ
- [ ] å¤šåª’ä½“æ”¯æŒè§„åˆ’

#### æ–‡æ¡£æ¶æ„é…ç½®
```yaml
# mkdocs.yml
site_name: AIå¹¿å‘Šä»£æŠ•ç³»ç»Ÿæ–‡æ¡£
site_description: æ™ºèƒ½åŒ–å¹¿å‘ŠæŠ•æ”¾ç®¡ç†å¹³å°æŠ€æœ¯æ–‡æ¡£
site_author: å¼€å‘å›¢é˜Ÿ
site_url: https://docs.your-domain.com

# æ–‡æ¡£å¯¼èˆªç»“æ„
nav:
  - é¦–é¡µ: index.md
  - å¿«é€Ÿå¼€å§‹:
    - ç¯å¢ƒæ­å»º: quickstart/setup.md
    - ç¬¬ä¸€ä¸ªé¡¹ç›®: quickstart/first-project.md
    - åŸºç¡€æ¦‚å¿µ: quickstart/concepts.md
  - å¼€å‘æŒ‡å—:
    - æ¥å£å¼€å‘: development/interface-development.md
    - ä»£ç è§„èŒƒ: development/coding-standards.md
    - æµ‹è¯•æŒ‡å—: development/testing-guide.md
    - APIè®¾è®¡: development/api-design.md
  - APIæ–‡æ¡£:
    - æ¦‚è§ˆ: api/overview.md
    - è®¤è¯: api/authentication.md
    - é”™è¯¯ç : api/error-codes.md
    - æ¥å£åˆ—è¡¨: api/endpoints.md
  - éƒ¨ç½²è¿ç»´:
    - éƒ¨ç½²æŒ‡å—: deployment/deployment-guide.md
    - ç›‘æ§é…ç½®: deployment/monitoring.md
    - æ•…éšœå¤„ç†: deployment/troubleshooting.md
  - ç”¨æˆ·æ‰‹å†Œ:
    - é¡¹ç›®ç®¡ç†: user/project-management.md
    - æ•°æ®æŠ¥è¡¨: user/reports.md
    - å¸¸è§é—®é¢˜: user/faq.md

# ä¸»é¢˜é…ç½®
theme:
  name: material
  language: zh
  features:
    - navigation.instant
    - navigation.tracking
    - navigation.tabs
    - navigation.tabs.sticky
    - navigation.sections
    - navigation.expand
    - navigation.indexes
    - search.highlight
    - search.share

# æ’ä»¶é…ç½®
plugins:
  - search:
      lang:
        - zh
        - en
  - minify:
      minify_html: true
  - git-revision-date-localized
  - awesome-pages

# Markdownæ‰©å±•
markdown_extensions:
  - admonition
  - pymdownx.details
  - pymdownx.superfences:
      custom_fences:
        - name: mermaid
          class: mermaid
          format: !!python/name:pymdownx.superfences.fence_code_format
  - pymdownx.highlight:
      anchor_linenums: true
  - pymdownx.inlinehilite
  - pymdownx.snippets
  - pymdownx.tabbed:
      alternate_style: true
  - tables
  - footnotes
```

#### Claudeæç¤ºè¯
```
è¯·è®¾è®¡AIå¹¿å‘Šä»£æŠ•ç³»ç»Ÿçš„æ–‡æ¡£æ¶æ„ï¼š

æ–‡æ¡£ç±»å‹ï¼š
- å¼€å‘æ–‡æ¡£ï¼ˆæŠ€æœ¯è§„èŒƒã€å¼€å‘æŒ‡å—ï¼‰
- APIæ–‡æ¡£ï¼ˆæ¥å£è§„èŒƒã€ä½¿ç”¨ç¤ºä¾‹ï¼‰
- ç”¨æˆ·æ–‡æ¡£ï¼ˆä½¿ç”¨æ‰‹å†Œã€æ“ä½œæŒ‡å—ï¼‰
- è¿ç»´æ–‡æ¡£ï¼ˆéƒ¨ç½²æŒ‡å—ã€æ•…éšœå¤„ç†ï¼‰
- ç»´æŠ¤æ–‡æ¡£ï¼ˆç‰ˆæœ¬æ›´æ–°ã€å˜æ›´è®°å½•ï¼‰

è®¾è®¡è¦æ±‚ï¼š
1. æ¸…æ™°çš„åˆ†ç±»ä½“ç³»
2. ç›´è§‚çš„å¯¼èˆªç»“æ„
3. ç‰ˆæœ¬ç®¡ç†ç­–ç•¥
4. æœç´¢ä¼˜åŒ–æ–¹æ¡ˆ
5. å¤šåª’ä½“å†…å®¹æ”¯æŒ

è¯·ç”Ÿæˆï¼š
1. æ–‡æ¡£æ¶æ„è®¾è®¡æ–¹æ¡ˆ
2. ç›®å½•ç»“æ„è§„åˆ’
3. å¯¼èˆªèœå•é…ç½®
4. æœç´¢ä¼˜åŒ–ç­–ç•¥
5. ç‰ˆæœ¬æ§åˆ¶æ–¹æ¡ˆ
```

### ä»»åŠ¡1.2ï¼šæ–‡æ¡£æ ‡å‡†åˆ¶å®š
**æ—¶é—´é¢„ä¼°**: 1å¤©
**è´Ÿè´£è§’è‰²**: æŠ€æœ¯å†™ä½œå·¥ç¨‹å¸ˆ

#### æ–‡æ¡£æ ‡å‡†è¦æ±‚
- [ ] æ–‡æ¡£æ ¼å¼è§„èŒƒ
- [ ] å†™ä½œé£æ ¼æŒ‡å—
- [ ] æœ¯è¯­è¯æ±‡è¡¨
- [ ] å›¾è¡¨åˆ¶ä½œæ ‡å‡†
- [ ] ç‰ˆæœ¬æ§åˆ¶è§„èŒƒ

#### æ–‡æ¡£å†™ä½œè§„èŒƒ
```markdown
# æ–‡æ¡£å†™ä½œè§„èŒƒ

## 1. æ–‡æ¡£ç»“æ„æ ‡å‡†

### æ ‡é¢˜å±‚çº§
```markdown
# ä¸€çº§æ ‡é¢˜ï¼ˆæ–‡æ¡£æ ‡é¢˜ï¼‰
## äºŒçº§æ ‡é¢˜ï¼ˆç« èŠ‚æ ‡é¢˜ï¼‰
### ä¸‰çº§æ ‡é¢˜ï¼ˆå°èŠ‚æ ‡é¢˜ï¼‰
#### å››çº§æ ‡é¢˜ï¼ˆå­å°èŠ‚ï¼‰
##### äº”çº§æ ‡é¢˜ï¼ˆè¯¦ç»†å†…å®¹ï¼‰
```

### æ–‡æ¡£æ¨¡æ¿
```markdown
# {æ–‡æ¡£æ ‡é¢˜}

## æ¦‚è¿°
> **é€‚ç”¨åœºæ™¯**: {ä½¿ç”¨åœºæ™¯æè¿°}
> **ç›®æ ‡è¯»è€…**: {ç›®æ ‡è¯»è€…ç¾¤ä½“}
> **å‰ç½®æ¡ä»¶**: {é˜…è¯»æœ¬æ–‡æ¡£çš„å‰ç½®æ¡ä»¶}

---

## åŸºç¡€æ¦‚å¿µ
{åŸºæœ¬æ¦‚å¿µè§£é‡Š}

## ä½¿ç”¨æŒ‡å—
{è¯¦ç»†ä½¿ç”¨è¯´æ˜}

## ç¤ºä¾‹ä»£ç 
```python
# ç¤ºä¾‹ä»£ç 
def example_function():
    pass
```

## å¸¸è§é—®é¢˜
{FAQå†…å®¹}

## å‚è€ƒèµ„æ–™
{ç›¸å…³é“¾æ¥å’Œèµ„æº}
```

## 2. å†™ä½œé£æ ¼è§„èŒƒ

### è¯­è¨€è¦æ±‚
- ä½¿ç”¨ç®€æ´æ˜äº†çš„ä¸­æ–‡è¡¨è¾¾
- é¿å…ä½¿ç”¨è¿‡äºæŠ€æœ¯åŒ–çš„æœ¯è¯­
- ä¿æŒæ®µè½ç®€çŸ­ï¼Œé‡ç‚¹çªå‡º
- ä½¿ç”¨ä¸»åŠ¨è¯­æ€ï¼Œé¿å…è¢«åŠ¨è¯­æ€

### æ ¼å¼è¦æ±‚
- ä»£ç å—ä½¿ç”¨è¯­æ³•é«˜äº®
- é‡ç‚¹å†…å®¹ä½¿ç”¨**ç²—ä½“**æˆ–*æ–œä½“*æ ‡æ³¨
- åˆ—è¡¨ä½¿ç”¨æœ‰åºæˆ–æ— åºåˆ—è¡¨
- è¡¨æ ¼è¦æœ‰è¡¨å¤´å’Œå¯¹é½

### æœ¯è¯­è§„èŒƒ
- æŠ€æœ¯æœ¯è¯­è¦ä¿æŒä¸€è‡´æ€§
- é¦–æ¬¡å‡ºç°çš„æœ¯è¯­è¦ç»™å‡ºè§£é‡Š
- ä½¿ç”¨æ ‡å‡†çš„ç¿»è¯‘ï¼Œé¿å…è‡ªåˆ›è¯æ±‡
```

#### Claudeæç¤ºè¯
```
è¯·åˆ¶å®šé¡¹ç›®æ–‡æ¡£æ ‡å‡†ï¼š

æ ‡å‡†ç±»å‹ï¼š
- æ–‡æ¡£æ ¼å¼è§„èŒƒ
- å†™ä½œé£æ ¼æŒ‡å—
- æœ¯è¯­è¯æ±‡è¡¨
- å›¾è¡¨åˆ¶ä½œæ ‡å‡†
- ç‰ˆæœ¬æ§åˆ¶è§„èŒƒ

è¦æ±‚ï¼š
1. ç»Ÿä¸€çš„æ–‡æ¡£æ¨¡æ¿
2. ä¸€è‡´çš„å†™ä½œé£æ ¼
3. æ ‡å‡†çš„æœ¯è¯­ä½¿ç”¨
4. æ¸…æ™°çš„å›¾è¡¨è§„èŒƒ
5. è§„èŒƒçš„ç‰ˆæœ¬ç®¡ç†

è¯·ç”Ÿæˆï¼š
1. æ–‡æ¡£å†™ä½œè§„èŒƒ
2. æ¨¡æ¿æ–‡ä»¶ç¤ºä¾‹
3. æœ¯è¯­è¯æ±‡è¡¨
4. å›¾è¡¨åˆ¶ä½œæŒ‡å—
5. ç‰ˆæœ¬æ§åˆ¶æµç¨‹
```

---

## ğŸ”§ é˜¶æ®µäºŒï¼šæ–‡æ¡£å†…å®¹åˆ›å»º

### ä»»åŠ¡2.1ï¼šAPIæ–‡æ¡£ç”Ÿæˆ
**æ—¶é—´é¢„ä¼°**: 2å¤©
**è´Ÿè´£è§’è‰²**: åç«¯å·¥ç¨‹å¸ˆ + æŠ€æœ¯å†™ä½œå·¥ç¨‹å¸ˆ

#### APIæ–‡æ¡£è¦æ±‚
- [ ] è‡ªåŠ¨ç”ŸæˆOpenAPIè§„èŒƒ
- [ ] æ¥å£è¯¦ç»†ä¿¡æ¯
- [ ] è¯·æ±‚/å“åº”ç¤ºä¾‹
- [ ] é”™è¯¯ç è¯´æ˜
- [ ] è®¤è¯æ–¹å¼è¯´æ˜

#### APIæ–‡æ¡£ç”Ÿæˆè„šæœ¬
```python
# scripts/generate_api_docs.py
import json
from pathlib import Path
from typing import Dict, Any
from datetime import datetime

class APIDocGenerator:
    """APIæ–‡æ¡£ç”Ÿæˆå™¨"""

    def __init__(self, app, output_dir: Path):
        self.app = app
        self.output_dir = output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def generate_openapi_spec(self):
        """ç”ŸæˆOpenAPIè§„èŒƒ"""
        openapi_spec = self.app.openapi()

        # æ·»åŠ é¡¹ç›®ä¿¡æ¯
        openapi_spec["info"].update({
            "description": "AIå¹¿å‘Šä»£æŠ•ç³»ç»ŸAPIæ¥å£æ–‡æ¡£",
            "version": "v1.0.0",
            "contact": {
                "name": "å¼€å‘å›¢é˜Ÿ",
                "email": "dev-team@company.com"
            }
        })

        # ç”ŸæˆJSONæ ¼å¼
        with open(self.output_dir / "openapi.json", "w", encoding="utf-8") as f:
            json.dump(openapi_spec, f, indent=2, ensure_ascii=False)

        return openapi_spec

    def generate_markdown_docs(self, openapi_spec: Dict[str, Any]):
        """ç”ŸæˆMarkdownæ ¼å¼æ–‡æ¡£"""
        # ç”ŸæˆAPIæ¦‚è§ˆ
        self.generate_api_overview(openapi_spec)

        # ç”Ÿæˆè®¤è¯æ–‡æ¡£
        self.generate_auth_docs(openapi_spec)

        # ç”Ÿæˆé”™è¯¯ç æ–‡æ¡£
        self.generate_error_codes_docs(openapi_spec)

        # ç”Ÿæˆæ¥å£è¯¦æƒ…æ–‡æ¡£
        self.generate_endpoint_docs(openapi_spec)

    def generate_api_overview(self, openapi_spec: Dict[str, Any]):
        """ç”ŸæˆAPIæ¦‚è§ˆæ–‡æ¡£"""
        content = f"""# APIæ¥å£æ–‡æ¡£

## æ¦‚è§ˆ

**APIç‰ˆæœ¬**: {openapi_spec['info']['version']}
**åŸºç¡€URL**: https://api.your-domain.com
**æ›´æ–°æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## åŸºæœ¬ä¿¡æ¯

### è®¤è¯æ–¹å¼
æœ¬APIä½¿ç”¨JWT Bearer Tokenè®¤è¯ã€‚åœ¨è¯·æ±‚å¤´ä¸­æ·»åŠ ï¼š
```
Authorization: Bearer <your_token>
```

### å“åº”æ ¼å¼

æ‰€æœ‰APIå“åº”éƒ½éµå¾ªç»Ÿä¸€çš„æ ¼å¼ï¼š

#### æˆåŠŸå“åº”
```json
{{
  "success": true,
  "data": {{ ... }},
  "message": "æ“ä½œæˆåŠŸ",
  "code": "SUCCESS",
  "request_id": "uuid",
  "timestamp": "2025-11-12T10:30:00Z"
}}
```

#### é”™è¯¯å“åº”
```json
{{
  "success": false,
  "error": {{
    "code": "ERROR_CODE",
    "message": "é”™è¯¯æè¿°"
  }},
  "request_id": "uuid",
  "timestamp": "2025-11-12T10:30:00Z"
}}
```

### é€šç”¨é”™è¯¯ç 

| é”™è¯¯ç  | HTTPçŠ¶æ€ç  | æè¿° |
|--------|------------|------|
| SUCCESS | 200 | æ“ä½œæˆåŠŸ |
| VALIDATION_ERROR | 400 | å‚æ•°éªŒè¯å¤±è´¥ |
| UNAUTHORIZED | 401 | æœªæˆæƒè®¿é—® |
| FORBIDDEN | 403 | æƒé™ä¸è¶³ |
| NOT_FOUND | 404 | èµ„æºä¸å­˜åœ¨ |
| INTERNAL_ERROR | 500 | æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ |

## æ¥å£åˆ—è¡¨

{self._generate_endpoint_summary(openapi_spec)}
"""

        with open(self.output_dir / "api-overview.md", "w", encoding="utf-8") as f:
            f.write(content)

    def generate_auth_docs(self, openapi_spec: Dict[str, Any]):
        """ç”Ÿæˆè®¤è¯æ–‡æ¡£"""
        content = """# APIè®¤è¯æŒ‡å—

## è®¤è¯æ¦‚è¿°

AIå¹¿å‘Šä»£æŠ•ç³»ç»ŸAPIä½¿ç”¨JWTï¼ˆJSON Web Tokenï¼‰è¿›è¡Œèº«ä»½è®¤è¯ã€‚

## è·å–Token

### è¯·æ±‚
```bash
POST /api/v1/auth/login
Content-Type: application/json

{
  "email": "user@example.com",
  "password": "your_password"
}
```

### å“åº”
```json
{
  "success": true,
  "data": {
    "access_token": "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9...",
    "refresh_token": "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9...",
    "token_type": "bearer",
    "expires_in": 900
  }
}
```

## ä½¿ç”¨Token

åœ¨APIè¯·æ±‚çš„Headerä¸­æ·»åŠ Authorizationå­—æ®µï¼š

```bash
GET /api/v1/projects
Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9...
```

## Tokenåˆ·æ–°

Access Tokenæœ‰æ•ˆæœŸä¸º15åˆ†é’Ÿï¼Œè¿‡æœŸåéœ€è¦ä½¿ç”¨refresh_tokenåˆ·æ–°ï¼š

```bash
POST /api/v1/auth/refresh
Content-Type: application/json

{
  "refresh_token": "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9..."
}
```

## æƒé™æ§åˆ¶

ç³»ç»Ÿæ”¯æŒä»¥ä¸‹è§’è‰²ï¼š

| è§’è‰² | æƒé™æè¿° |
|------|----------|
| admin | ç³»ç»Ÿç®¡ç†å‘˜ï¼Œæ‹¥æœ‰æ‰€æœ‰æƒé™ |
| finance | è´¢åŠ¡äººå‘˜ï¼Œå¯ç®¡ç†å……å€¼å’Œå¯¹è´¦ |
| data_operator | æ•°æ®æ“ä½œå‘˜ï¼Œå¯ç®¡ç†æ•°æ® |
| account_manager | è´¦æˆ·ç®¡ç†å‘˜ï¼Œå¯ç®¡ç†é¡¹ç›®å’Œè´¦æˆ· |
| media_buyer | æŠ•æ‰‹ï¼Œå¯ç®¡ç†å¹¿å‘ŠæŠ•æ”¾ |

## æ³¨æ„äº‹é¡¹

1. è¯·å¦¥å–„ä¿ç®¡Tokenï¼Œé¿å…æ³„éœ²
2. Tokenè¿‡æœŸåéœ€è¦é‡æ–°è·å–
3. é•¿æ—¶é—´ä¸æ´»åŠ¨ä¼šè‡ªåŠ¨é€€å‡ºç™»å½•
4. å»ºè®®åœ¨å®¢æˆ·ç«¯å®ç°Tokenè‡ªåŠ¨åˆ·æ–°æœºåˆ¶
"""

        with open(self.output_dir / "authentication.md", "w", encoding="utf-8") as f:
            f.write(content)

    def _generate_endpoint_summary(self, openapi_spec: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ¥å£æ‘˜è¦è¡¨æ ¼"""
        summary = []
        summary.append("| æ–¹æ³• | ç«¯ç‚¹ | æè¿° | æƒé™è¦æ±‚ |")
        summary.append("|------|------|------|----------|")

        for path, path_item in openapi_spec.get("paths", {}).items():
            for method, operation in path_item.items():
                if method.upper() in ["GET", "POST", "PUT", "DELETE", "PATCH"]:
                    desc = operation.get("summary", operation.get("description", ""))
                    auth_req = operation.get("security", [])
                    permission = "éœ€è¦è®¤è¯" if auth_req else "å…¬å¼€æ¥å£"

                    summary.append(f"| {method.upper()} | {path} | {desc} | {permission} |")

        return "\n".join(summary)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    from backend.main import app

    generator = APIDocGenerator(app, Path("docs/api"))
    openapi_spec = generator.generate_openapi_spec()
    generator.generate_markdown_docs(openapi_spec)

    print("âœ… APIæ–‡æ¡£ç”Ÿæˆå®Œæˆ")
```

#### Claudeæç¤ºè¯
```
è¯·ç”ŸæˆAPIæ–‡æ¡£ï¼š

APIè¦æ±‚ï¼š
- åŸºäºOpenAPI 3.0è§„èŒƒ
- åŒ…å«å®Œæ•´çš„æ¥å£ä¿¡æ¯
- æä¾›è¯·æ±‚/å“åº”ç¤ºä¾‹
- è¯´æ˜è®¤è¯æ–¹å¼å’Œæƒé™è¦æ±‚
- åŒ…å«é”™è¯¯ç è¯´æ˜

ç”Ÿæˆå†…å®¹ï¼š
1. OpenAPI JSONè§„èŒƒæ–‡ä»¶
2. APIæ¦‚è§ˆæ–‡æ¡£
3. è®¤è¯æŒ‡å—
4. é”™è¯¯ç è¯´æ˜
5. æ¥å£è¯¦ç»†æ–‡æ¡£

è¯·ç¡®ä¿ï¼š
- æ–‡æ¡£æ ¼å¼è§„èŒƒç»Ÿä¸€
- ç¤ºä¾‹ä»£ç å¯æ‰§è¡Œ
- é”™è¯¯è¯´æ˜å‡†ç¡®
- æƒé™è¦æ±‚æ˜ç¡®
```

### ä»»åŠ¡2.2ï¼šç”¨æˆ·æ‰‹å†Œç¼–å†™
**æ—¶é—´é¢„ä¼°**: 3å¤©
**è´Ÿè´£è§’è‰²**: äº§å“ç»ç† + æŠ€æœ¯å†™ä½œå·¥ç¨‹å¸ˆ

#### ç”¨æˆ·æ‰‹å†Œè¦æ±‚
- [ ] åŠŸèƒ½ä½¿ç”¨æŒ‡å—
- [ ] æ“ä½œæµç¨‹è¯´æ˜
- [ ] å¸¸è§é—®é¢˜è§£ç­”
- [ ] æœ€ä½³å®è·µå»ºè®®
- [ ] æ•…éšœæ’é™¤æŒ‡å—

#### ç”¨æˆ·æ‰‹å†Œæ¨¡æ¿
```markdown
# {åŠŸèƒ½æ¨¡å—}ç”¨æˆ·æ‰‹å†Œ

## åŠŸèƒ½æ¦‚è¿°

{åŠŸèƒ½æ¨¡å—çš„åŸºæœ¬ä»‹ç»å’Œä¸»è¦ç”¨é€”}

## ä½¿ç”¨åœºæ™¯

{é€‚ç”¨çš„ä¸šåŠ¡åœºæ™¯å’Œç”¨æˆ·ç¾¤ä½“}

## æ“ä½œæŒ‡å—

### åŸºç¡€æ“ä½œ

{è¯¦ç»†çš„ä½¿ç”¨æ­¥éª¤ï¼Œé…æœ‰æˆªå›¾æˆ–ç¤ºä¾‹}

### é«˜çº§åŠŸèƒ½

{è¿›é˜¶åŠŸèƒ½çš„ä½¿ç”¨æ–¹æ³•}

## å¸¸è§é—®é¢˜

### Q1: {å¸¸è§é—®é¢˜1}
**A**: {è¯¦ç»†è§£ç­”}

### Q2: {å¸¸è§é—®é¢˜2}
**A**: {è¯¦ç»†è§£ç­”}

## æœ€ä½³å®è·µ

{ä½¿ç”¨å»ºè®®å’Œä¼˜åŒ–æŠ€å·§}

## æ³¨æ„äº‹é¡¹

{ä½¿ç”¨é™åˆ¶å’Œæ³¨æ„äº‹é¡¹}
```

#### Claudeæç¤ºè¯
```
è¯·ç¼–å†™{åŠŸèƒ½æ¨¡å—}çš„ç”¨æˆ·æ‰‹å†Œï¼š

åŠŸèƒ½ä¿¡æ¯ï¼š
- åŠŸèƒ½æè¿°ï¼š{åŠŸèƒ½æè¿°}
- ç›®æ ‡ç”¨æˆ·ï¼š{ç›®æ ‡ç”¨æˆ·ç¾¤ä½“}
- ä¸»è¦æ“ä½œï¼š{ä¸»è¦æ“ä½œæµç¨‹}
- å¸¸è§é—®é¢˜ï¼š{å¸¸è§é—®é¢˜åˆ—è¡¨}

æ‰‹å†Œè¦æ±‚ï¼š
1. è¯¦ç»†çš„æ“ä½œæ­¥éª¤
2. æ¸…æ™°çš„æˆªå›¾è¯´æ˜
3. å¸¸è§é—®é¢˜è§£ç­”
4. æœ€ä½³å®è·µå»ºè®®
5. æ³¨æ„äº‹é¡¹æé†’

è¯·ç”Ÿæˆï¼š
1. åŠŸèƒ½æ¦‚è¿°éƒ¨åˆ†
2. æ“ä½œæŒ‡å—éƒ¨åˆ†
3. FAQéƒ¨åˆ†
4. æœ€ä½³å®è·µéƒ¨åˆ†
5. æ³¨æ„äº‹é¡¹éƒ¨åˆ†
```

---

## ğŸ”„ é˜¶æ®µä¸‰ï¼šæ–‡æ¡£ç»´æŠ¤ä¸æ›´æ–°

### ä»»åŠ¡3.1ï¼šæ–‡æ¡£åŒæ­¥ç»´æŠ¤
**æ—¶é—´é¢„ä¼°**: æŒç»­æ‰§è¡Œ
**æ£€æŸ¥é¢‘ç‡**: æ¯æ¬¡ä»£ç æ›´æ–°

#### åŒæ­¥æ£€æŸ¥æ¸…å•
- [ ] APIæ–‡æ¡£ä¸ä»£ç åŒæ­¥
- [ ] é…ç½®æ–‡æ¡£ä¸å®é™…é…ç½®åŒæ­¥
- [ ] éƒ¨ç½²æ–‡æ¡£ä¸å®é™…æµç¨‹åŒæ­¥
- [ ] ç‰ˆæœ¬ä¿¡æ¯åŠæ—¶æ›´æ–°
- [ ] é“¾æ¥æœ‰æ•ˆæ€§æ£€æŸ¥

#### æ–‡æ¡£åŒæ­¥è„šæœ¬
```python
# scripts/sync_docs.py
import ast
import re
import json
from pathlib import Path
from typing import Dict, List, Tuple
import requests

class DocumentationSyncer:
    """æ–‡æ¡£åŒæ­¥å™¨"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.docs_dir = project_root / "docs"
        self.backend_dir = project_root / "backend"

    def check_api_sync(self) -> Dict[str, bool]:
        """æ£€æŸ¥APIæ–‡æ¡£åŒæ­¥çŠ¶æ€"""
        # è·å–å®é™…APIè·¯ç”±
        actual_routes = self._extract_api_routes()

        # æ£€æŸ¥æ–‡æ¡£ä¸­çš„API
        documented_routes = self._extract_documented_routes()

        # æ¯”è¾ƒå·®å¼‚
        missing_in_docs = set(actual_routes) - set(documented_routes)
        missing_in_code = set(documented_routes) - set(actual_routes)

        return {
            "sync_complete": len(missing_in_docs) == 0 and len(missing_in_code) == 0,
            "missing_in_docs": list(missing_in_docs),
            "missing_in_code": list(missing_in_code),
            "total_actual": len(actual_routes),
            "total_documented": len(documented_routes)
        }

    def _extract_api_routes(self) -> List[str]:
        """ä»ä»£ç ä¸­æå–APIè·¯ç”±"""
        routes = []

        # æ‰«æè·¯ç”±æ–‡ä»¶
        for route_file in self.backend_dir.glob("routers/*.py"):
            with open(route_file, "r", encoding="utf-8") as f:
                content = f.read()

            # æå–è·¯ç”±å®šä¹‰
            pattern = r'@router\.(get|post|put|delete|patch)\s*\(\s*["\']([^"\']+)["\']'
            matches = re.findall(pattern, content)

            for method, path in matches:
                routes.append(f"{method.upper()} {path}")

        return sorted(routes)

    def _extract_documented_routes(self) -> List[str]:
        """ä»æ–‡æ¡£ä¸­æå–å·²è®°å½•çš„APIè·¯ç”±"""
        routes = []

        # æ‰«æAPIæ–‡æ¡£
        for doc_file in self.docs_dir.glob("**/*.md"):
            with open(doc_file, "r", encoding="utf-8") as f:
                content = f.read()

            # æå–APIç«¯ç‚¹
            pattern = r'^\|\s*(GET|POST|PUT|DELETE|PATCH)\s*\|\s*([^\|]+)\s*\|'
            matches = re.findall(pattern, content, re.MULTILINE)

            for method, path in matches:
                routes.append(f"{method.upper()} {path.strip()}")

        return sorted(routes)

    def check_link_validity(self) -> List[Tuple[str, str, str]]:
        """æ£€æŸ¥æ–‡æ¡£é“¾æ¥æœ‰æ•ˆæ€§"""
        broken_links = []

        for doc_file in self.docs_dir.rglob("*.md"):
            with open(doc_file, "r", encoding="utf-8") as f:
                content = f.read()

            # æå–Markdowné“¾æ¥
            link_pattern = r'\[([^\]]+)\]\(([^)]+)\)'
            matches = re.findall(link_pattern, content)

            for text, link in matches:
                if link.startswith("http"):
                    # å¤–éƒ¨é“¾æ¥
                    if not self._check_external_link(link):
                        broken_links.append((str(doc_file.relative_to(self.docs_dir)), text, link))
                elif not link.startswith("#"):
                    # å†…éƒ¨é“¾æ¥
                    if not self._check_internal_link(link, doc_file.parent):
                        broken_links.append((str(doc_file.relative_to(self.docs_dir)), text, link))

        return broken_links

    def _check_external_link(self, url: str) -> bool:
        """æ£€æŸ¥å¤–éƒ¨é“¾æ¥æœ‰æ•ˆæ€§"""
        try:
            response = requests.head(url, timeout=10, allow_redirects=True)
            return response.status_code < 400
        except:
            return False

    def _check_internal_link(self, link: str, base_path: Path) -> bool:
        """æ£€æŸ¥å†…éƒ¨é“¾æ¥æœ‰æ•ˆæ€§"""
        target_path = base_path / link
        return target_path.exists()

    def check_config_sync(self) -> Dict[str, bool]:
        """æ£€æŸ¥é…ç½®æ–‡æ¡£åŒæ­¥"""
        config_checks = {}

        # æ£€æŸ¥ç¯å¢ƒå˜é‡æ–‡æ¡£
        env_vars_in_code = self._extract_env_vars()
        env_vars_in_docs = self._extract_documented_env_vars()

        config_checks["env_vars_sync"] = set(env_vars_in_code) <= set(env_vars_in_docs)

        return config_checks

    def _extract_env_vars(self) -> List[str]:
        """ä»ä»£ç ä¸­æå–ç¯å¢ƒå˜é‡"""
        env_vars = set()

        for py_file in self.backend_dir.rglob("*.py"):
            with open(py_file, "r", encoding="utf-8") as f:
                content = f.read()

            # æå–ç¯å¢ƒå˜é‡ä½¿ç”¨
            pattern = r'os\.environ\.get\(["\']([^"\']+)["\']'
            matches = re.findall(pattern, content)
            env_vars.update(matches)

            # æå–pydanticç¯å¢ƒå˜é‡
            pattern = r'\w+\s*:\s*str\s*=\s*Field\([^)]*env=["\']([^"\']+)["\']'
            matches = re.findall(pattern, content)
            env_vars.update(matches)

        return sorted(list(env_vars))

    def _extract_documented_env_vars(self) -> List[str]:
        """ä»æ–‡æ¡£ä¸­æå–ç¯å¢ƒå˜é‡"""
        env_vars = set()

        for doc_file in self.docs_dir.rglob("*.md"):
            with open(doc_file, "r", encoding="utf-8") as f:
                content = f.read()

            # æå–ç¯å¢ƒå˜é‡æ–‡æ¡£
            pattern = r'`([A-Z_]+)`'
            matches = re.findall(pattern, content)
            env_vars.update(matches)

        return sorted(list(env_vars))

    def generate_sync_report(self) -> str:
        """ç”ŸæˆåŒæ­¥æŠ¥å‘Š"""
        api_sync = self.check_api_sync()
        broken_links = self.check_link_validity()
        config_sync = self.check_config_sync()

        report = f"""# æ–‡æ¡£åŒæ­¥æ£€æŸ¥æŠ¥å‘Š

## æ£€æŸ¥æ—¶é—´
{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## APIæ–‡æ¡£åŒæ­¥çŠ¶æ€
- **åŒæ­¥çŠ¶æ€**: {'âœ… æ­£å¸¸' if api_sync['sync_complete'] else 'âŒ å¼‚å¸¸'}
- **å®é™…APIæ•°é‡**: {api_sync['total_actual']}
- **æ–‡æ¡£è®°å½•æ•°é‡**: {api_sync['total_documented']}

{'' if api_sync['sync_complete'] else f"""
### ç¼ºå¤±çš„APIæ–‡æ¡£
{chr(10).join(f'- {route}' for route in api_sync['missing_in_docs'])}

### æ–‡æ¡£ä¸­å¤šä½™çš„API
{chr(10).join(f'- {route}' for route in api_sync['missing_in_code'])}
"""}

## é“¾æ¥æœ‰æ•ˆæ€§æ£€æŸ¥
- **æ€»é“¾æ¥æ•°**: {len(broken_links)}
- **æŸåé“¾æ¥æ•°**: {len(broken_links)}

{'' if not broken_links else f"""
### æŸåé“¾æ¥è¯¦æƒ…
{chr(10).join(f'- **{file}**: [{text}]({link})' for file, text, link in broken_links)}
"""}

## é…ç½®æ–‡æ¡£åŒæ­¥
- **ç¯å¢ƒå˜é‡åŒæ­¥**: {'âœ… æ­£å¸¸' if config_sync.get('env_vars_sync', False) else 'âŒ å¼‚å¸¸'}

## æ”¹è¿›å»ºè®®
1. åŠæ—¶æ›´æ–°APIæ–‡æ¡£ï¼Œç¡®ä¿ä¸ä»£ç åŒæ­¥
2. ä¿®å¤æ‰€æœ‰æŸåçš„æ–‡æ¡£é“¾æ¥
3. å®Œå–„ç¯å¢ƒå˜é‡é…ç½®æ–‡æ¡£
4. å»ºç«‹æ–‡æ¡£æ›´æ–°çš„è‡ªåŠ¨åŒ–æµç¨‹
"""

        return report

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    syncer = DocumentationSyncer(Path("."))
    report = syncer.generate_sync_report()

    with open("docs_sync_report.md", "w", encoding="utf-8") as f:
        f.write(report)

    print("âœ… æ–‡æ¡£åŒæ­¥æŠ¥å‘Šå·²ç”Ÿæˆ")
```

#### Claudeæç¤ºè¯
```
è¯·æ£€æŸ¥æ–‡æ¡£åŒæ­¥çŠ¶æ€ï¼š

æ£€æŸ¥èŒƒå›´ï¼š
- APIæ–‡æ¡£ä¸ä»£ç åŒæ­¥
- é…ç½®æ–‡æ¡£ä¸å®é™…é…ç½®åŒæ­¥
- æ–‡æ¡£é“¾æ¥æœ‰æ•ˆæ€§
- ç‰ˆæœ¬ä¿¡æ¯å‡†ç¡®æ€§

åŒæ­¥è¦æ±‚ï¼š
1. APIæ¥å£å®Œå…¨æ–‡æ¡£åŒ–
2. é…ç½®å‚æ•°è¯¦ç»†è¯´æ˜
3. æ‰€æœ‰é“¾æ¥æœ‰æ•ˆå¯è®¿é—®
4. ç‰ˆæœ¬ä¿¡æ¯åŠæ—¶æ›´æ–°

è¯·ç”Ÿæˆï¼š
1. åŒæ­¥çŠ¶æ€æ£€æŸ¥æŠ¥å‘Š
2. å·®å¼‚é—®é¢˜æ¸…å•
3. ä¿®å¤å»ºè®®æ–¹æ¡ˆ
4. è‡ªåŠ¨åŒ–åŒæ­¥æµç¨‹
```

### ä»»åŠ¡3.2ï¼šç‰ˆæœ¬ç®¡ç†
**æ—¶é—´é¢„ä¼°**: æŒç»­æ‰§è¡Œ
**æ£€æŸ¥é¢‘ç‡**: æ¯æ¬¡ç‰ˆæœ¬å‘å¸ƒ

#### ç‰ˆæœ¬ç®¡ç†æ¸…å•
- [ ] ç‰ˆæœ¬å·è§„èŒƒç®¡ç†
- [ ] å˜æ›´è®°å½•ç»´æŠ¤
- [ ] å†å²ç‰ˆæœ¬å½’æ¡£
- [ ] ç‰ˆæœ¬å…¼å®¹æ€§è¯´æ˜
- [ ] å‡çº§æŒ‡å—ç¼–å†™

#### å˜æ›´è®°å½•æ¨¡æ¿
```markdown
# å˜æ›´è®°å½•

## [v2.1.0] - 2025-11-12

### æ–°å¢
- ğŸ¨ æ–°å¢é¡¹ç›®æˆæœ¬åˆ†æåŠŸèƒ½
- ğŸ”’ å¢å¼ºæƒé™æ§åˆ¶æœºåˆ¶
- ğŸ“Š æ·»åŠ å®æ—¶æ•°æ®ç›‘æ§é¢æ¿

### æ”¹è¿›
- âš¡ ä¼˜åŒ–APIå“åº”é€Ÿåº¦ï¼Œæå‡30%
- ğŸ› ï¸ é‡æ„ç”¨æˆ·ç®¡ç†æ¨¡å—ï¼Œæå‡ç¨³å®šæ€§
- ğŸ“± æ”¹è¿›ç§»åŠ¨ç«¯é€‚é…

### ä¿®å¤
- ğŸ› ä¿®å¤é¡¹ç›®åˆ›å»ºæ—¶çš„æƒé™éªŒè¯é—®é¢˜
- ğŸ”§ è§£å†³æ•°æ®åº“è¿æ¥æ± æ³„æ¼é—®é¢˜
- ğŸ“ ä¿®æ­£æŠ¥è¡¨æ•°æ®è®¡ç®—é”™è¯¯

### å®‰å…¨
- ğŸ”’ æ›´æ–°ä¾èµ–åŒ…ï¼Œä¿®å¤å®‰å…¨æ¼æ´
- ğŸ›¡ï¸ åŠ å¼ºè¾“å…¥éªŒè¯ï¼Œé˜²æ­¢æ³¨å…¥æ”»å‡»
- ğŸ” æ”¹è¿›JWT Tokenå®‰å…¨ç­–ç•¥

### æ–‡æ¡£
- ğŸ“– æ›´æ–°APIæ–‡æ¡£ï¼Œæ·»åŠ æ–°æ¥å£è¯´æ˜
- ğŸ“š å®Œå–„éƒ¨ç½²æŒ‡å—
- â“ å¢åŠ å¸¸è§é—®é¢˜è§£ç­”

---

## [v2.0.0] - 2025-10-15

### é‡å¤§æ›´æ–°
- ğŸš€ å…¨æ–°çš„AIå¼‚å¸¸æ£€æµ‹åŠŸèƒ½
- ğŸ”„ é‡æ„æ•°æ®æ¨¡å‹ï¼Œæå‡æ€§èƒ½
- ğŸ¨ å…¨æ–°çš„ç”¨æˆ·ç•Œé¢è®¾è®¡

[æ›´å¤šå†å²ç‰ˆæœ¬...]
```

#### Claudeæç¤ºè¯
```
è¯·ç»´æŠ¤ç‰ˆæœ¬å˜æ›´è®°å½•ï¼š

ç‰ˆæœ¬ä¿¡æ¯ï¼š
- å½“å‰ç‰ˆæœ¬ï¼šv2.1.0
- å‘å¸ƒæ—¥æœŸï¼š2025-11-12
- å˜æ›´ç±»å‹ï¼š{å˜æ›´ç±»å‹}

å˜æ›´å†…å®¹ï¼š
{å…·ä½“å˜æ›´å†…å®¹}

è®°å½•è¦æ±‚ï¼š
1. æŒ‰ç…§æ ‡å‡†æ ¼å¼è®°å½•
2. åˆ†ç±»æ¸…æ™°ï¼ˆæ–°å¢/æ”¹è¿›/ä¿®å¤/å®‰å…¨ï¼‰
3. è¯¦ç»†çš„å˜æ›´è¯´æ˜
4. å½±å“èŒƒå›´è¯„ä¼°
5. å‡çº§æ³¨æ„äº‹é¡¹

è¯·ç”Ÿæˆï¼š
1. ç‰ˆæœ¬å˜æ›´è®°å½•
2. å‡çº§æŒ‡å—
3. å…¼å®¹æ€§è¯´æ˜
4. å›æ»šæ–¹æ¡ˆ
```

---

## ğŸ“Š é˜¶æ®µå››ï¼šæ–‡æ¡£è´¨é‡ä¸ä¼˜åŒ–

### ä»»åŠ¡4.1ï¼šæ–‡æ¡£è´¨é‡è¯„ä¼°
**æ—¶é—´é¢„ä¼°**: 1å¤©
**æ£€æŸ¥é¢‘ç‡**: æ¯æœˆ

#### è´¨é‡è¯„ä¼°æ¸…å•
- [ ] å†…å®¹å‡†ç¡®æ€§æ£€æŸ¥
- [ ] ç»“æ„å®Œæ•´æ€§éªŒè¯
- [ ] ç”¨æˆ·å‹å¥½æ€§è¯„ä¼°
- [ ] æœç´¢æ•ˆæœä¼˜åŒ–
- [ ] å¯è¯»æ€§æ”¹è¿›

#### æ–‡æ¡£è´¨é‡è¯„ä¼°è„šæœ¬
```python
# scripts/doc_quality_checker.py
import re
from pathlib import Path
from typing import Dict, List, Tuple
from collections import Counter

class DocumentationQualityChecker:
    """æ–‡æ¡£è´¨é‡æ£€æŸ¥å™¨"""

    def __init__(self, docs_dir: Path):
        self.docs_dir = docs_dir

    def check_document_quality(self) -> Dict[str, any]:
        """æ£€æŸ¥æ–‡æ¡£è´¨é‡"""
        doc_files = list(self.docs_dir.rglob("*.md"))

        quality_metrics = {
            "total_documents": len(doc_files),
            "content_analysis": self._analyze_content(doc_files),
            "structure_analysis": self._analyze_structure(doc_files),
            "readability_analysis": self._analyze_readability(doc_files),
            "search_optimization": self._check_search_optimization(doc_files)
        }

        return quality_metrics

    def _analyze_content(self, doc_files: List[Path]) -> Dict[str, any]:
        """åˆ†ææ–‡æ¡£å†…å®¹è´¨é‡"""
        total_words = 0
        total_code_blocks = 0
        total_images = 0
        total_links = 0

        for doc_file in doc_files:
            with open(doc_file, "r", encoding="utf-8") as f:
                content = f.read()

            # ç»Ÿè®¡å­—æ•°
            words = len(re.findall(r'\w+', content))
            total_words += words

            # ç»Ÿè®¡ä»£ç å—
            code_blocks = len(re.findall(r'```', content)) // 2
            total_code_blocks += code_blocks

            # ç»Ÿè®¡å›¾ç‰‡
            images = len(re.findall(r'!\[.*?\]\(.*?\)', content))
            total_images += images

            # ç»Ÿè®¡é“¾æ¥
            links = len(re.findall(r'\[.*?\]\(.*?\)', content))
            total_links += links

        return {
            "total_words": total_words,
            "avg_words_per_doc": total_words / len(doc_files) if doc_files else 0,
            "total_code_blocks": total_code_blocks,
            "total_images": total_images,
            "total_links": total_links,
            "content_density": total_words / (total_code_blocks + 1)  # å†…å®¹ä¸ä»£ç çš„æ¯”ä¾‹
        }

    def _analyze_structure(self, doc_files: List[Path]) -> Dict[str, any]:
        """åˆ†ææ–‡æ¡£ç»“æ„"""
        structure_metrics = {
            "has_table_of_contents": 0,
            "has_sections": 0,
            "avg_section_depth": 0,
            "has_code_examples": 0,
            "has_faqs": 0
        }

        total_sections = 0
        total_depth = 0

        for doc_file in doc_files:
            with open(doc_file, "r", encoding="utf-8") as f:
                content = f.read()

            # æ£€æŸ¥ç›®å½•
            if re.search(r'(## ç›®å½•|## ç›®å½•|## TOC)', content, re.IGNORECASE):
                structure_metrics["has_table_of_contents"] += 1

            # æ£€æŸ¥ç« èŠ‚
            sections = re.findall(r'^#{1,6}\s+', content, re.MULTILINE)
            if sections:
                structure_metrics["has_sections"] += 1
                total_sections += len(sections)

                # è®¡ç®—å¹³å‡æ·±åº¦
                depths = [len(section.split()[0]) - 1 for section in sections]
                total_depth += sum(depths)

            # æ£€æŸ¥ä»£ç ç¤ºä¾‹
            if '```' in content:
                structure_metrics["has_code_examples"] += 1

            # æ£€æŸ¥FAQ
            if re.search(r'(## å¸¸è§é—®é¢˜|## FAQ|## Q&A)', content, re.IGNORECASE):
                structure_metrics["has_faqs"] += 1

        structure_metrics["avg_section_depth"] = total_depth / total_sections if total_sections > 0 else 0

        return structure_metrics

    def _analyze_readability(self, doc_files: List[Path]) -> Dict[str, any]:
        """åˆ†æå¯è¯»æ€§"""
        readability_metrics = {
            "avg_sentence_length": 0,
            "avg_paragraph_length": 0,
            "heading_consistency": 0,
            "terminology_consistency": self._check_terminology_consistency(doc_files)
        }

        total_sentences = 0
        total_sentence_words = 0
        total_paragraphs = 0
        total_paragraph_words = 0

        for doc_file in doc_files:
            with open(doc_file, "r", encoding="utf-8") as f:
                content = f.read()

            # ç§»é™¤ä»£ç å—
            content = re.sub(r'```.*?```', '', content, flags=re.DOTALL)

            # åˆ†æå¥å­
            sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', content)
            for sentence in sentences:
                if sentence.strip():
                    words = len(re.findall(r'\w+', sentence))
                    if words > 0:
                        total_sentences += 1
                        total_sentence_words += words

            # åˆ†ææ®µè½
            paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
            for paragraph in paragraphs:
                if not paragraph.startswith('#'):  # æ’é™¤æ ‡é¢˜
                    words = len(re.findall(r'\w+', paragraph))
                    if words > 0:
                        total_paragraphs += 1
                        total_paragraph_words += words

        readability_metrics["avg_sentence_length"] = total_sentence_words / total_sentences if total_sentences > 0 else 0
        readability_metrics["avg_paragraph_length"] = total_paragraph_words / total_paragraphs if total_paragraphs > 0 else 0

        return readability_metrics

    def _check_terminology_consistency(self, doc_files: List[Path]) -> Dict[str, any]:
        """æ£€æŸ¥æœ¯è¯­ä¸€è‡´æ€§"""
        term_counter = Counter()

        for doc_file in doc_files:
            with open(doc_file, "r", encoding="utf-8") as f:
                content = f.read()

            # æå–æŠ€æœ¯æœ¯è¯­
            technical_terms = re.findall(r'\b[A-Z][a-zA-Z]+\b', content)
            term_counter.update(technical_terms)

        # æ‰¾å‡ºå¯èƒ½çš„å˜ä½“
        inconsistent_terms = []
        common_terms = term_counter.most_common(20)

        for term, count in common_terms:
            if count > 1:
                # æ£€æŸ¥æ˜¯å¦æœ‰å¤§å°å†™å˜ä½“
                variants = [t for t in term_counter.keys() if t.lower() == term.lower() and t != term]
                if variants:
                    inconsistent_terms.append((term, variants))

        return {
            "total_unique_terms": len(term_counter),
            "most_common_terms": common_terms[:10],
            "inconsistent_terms": inconsistent_terms
        }

    def _check_search_optimization(self, doc_files: List[Path]) -> Dict[str, any]:
        """æ£€æŸ¥æœç´¢ä¼˜åŒ–"""
        optimization_metrics = {
            "documents_with_keywords": 0,
            "avg_keywords_per_doc": 0,
            "documents_with_meta": 0,
            "heading_optimization": 0
        }

        total_keywords = 0

        for doc_file in doc_files:
            with open(doc_file, "r", encoding="utf-8") as f:
                content = f.read()

            # æ£€æŸ¥å…³é”®è¯
            keywords = re.findall(r'(keywords|æ ‡ç­¾):\s*(.+)', content, re.IGNORECASE)
            if keywords:
                optimization_metrics["documents_with_keywords"] += 1
                total_keywords += len(keywords[0][1].split(',')) if keywords[0][1] else 0

            # æ£€æŸ¥å…ƒæ•°æ®
            if re.search(r'(description|æè¿°):', content, re.IGNORECASE):
                optimization_metrics["documents_with_meta"] += 1

            # æ£€æŸ¥æ ‡é¢˜ä¼˜åŒ–
            headings = re.findall(r'^#{1,6}\s+(.+)$', content, re.MULTILINE)
            if headings:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®è¯
                optimized_headings = sum(1 for h in headings if len(h.split()) <= 10)  # ç®€æ´çš„æ ‡é¢˜
                optimization_metrics["heading_optimization"] += optimized_headings

        optimization_metrics["avg_keywords_per_doc"] = total_keywords / len(doc_files) if doc_files else 0

        return optimization_metrics

    def generate_quality_report(self) -> str:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        quality_data = self.check_document_quality()

        report = f"""# æ–‡æ¡£è´¨é‡è¯„ä¼°æŠ¥å‘Š

## è¯„ä¼°æ—¶é—´
{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ€»ä½“æ¦‚å†µ
- **æ–‡æ¡£æ€»æ•°**: {quality_data['total_documents']}
- **å†…å®¹è´¨é‡è¯„åˆ†**: {self._calculate_content_score(quality_data['content_analysis'])}/10
- **ç»“æ„è´¨é‡è¯„åˆ†**: {self._calculate_structure_score(quality_data['structure_analysis'])}/10
- **å¯è¯»æ€§è¯„åˆ†**: {self._calculate_readability_score(quality_data['readability_analysis'])}/10

## å†…å®¹åˆ†æ
- **æ€»å­—æ•°**: {quality_data['content_analysis']['total_words']:,}
- **å¹³å‡æ¯æ–‡æ¡£å­—æ•°**: {quality_data['content_analysis']['avg_words_per_doc']:.0f}
- **ä»£ç å—æ•°é‡**: {quality_data['content_analysis']['total_code_blocks']}
- **å›¾ç‰‡æ•°é‡**: {quality_data['content_analysis']['total_images']}
- **é“¾æ¥æ•°é‡**: {quality_data['content_analysis']['total_links']}

## ç»“æ„åˆ†æ
- **æœ‰ç›®å½•çš„æ–‡æ¡£**: {quality_data['structure_analysis']['has_table_of_contents']}/{quality_data['total_documents']}
- **æœ‰ç« èŠ‚çš„æ–‡æ¡£**: {quality_data['structure_analysis']['has_sections']}/{quality_data['total_documents']}
- **å¹³å‡ç« èŠ‚æ·±åº¦**: {quality_data['structure_analysis']['avg_section_depth']:.1f}
- **æœ‰ä»£ç ç¤ºä¾‹çš„æ–‡æ¡£**: {quality_data['structure_analysis']['has_code_examples']}/{quality_data['total_documents']}

## å¯è¯»æ€§åˆ†æ
- **å¹³å‡å¥å­é•¿åº¦**: {quality_data['readability_analysis']['avg_sentence_length']:.1f} è¯
- **å¹³å‡æ®µè½é•¿åº¦**: {quality_data['readability_analysis']['avg_paragraph_length']:.1f} è¯
- **æœ¯è¯­ä¸€è‡´æ€§**: {'âœ… è‰¯å¥½' if not quality_data['readability_analysis']['terminology_consistency']['inconsistent_terms'] else 'âš ï¸ éœ€æ”¹è¿›'}

## æœç´¢ä¼˜åŒ–
- **æœ‰å…³é”®è¯çš„æ–‡æ¡£**: {quality_data['search_optimization']['documents_with_keywords']}/{quality_data['total_documents']}
- **å¹³å‡å…³é”®è¯æ•°**: {quality_data['search_optimization']['avg_keywords_per_doc']:.1f}

## æ”¹è¿›å»ºè®®
{self._generate_improvement_suggestions(quality_data)}
"""

        return report

    def _calculate_content_score(self, content_data: Dict[str, any]) -> float:
        """è®¡ç®—å†…å®¹è´¨é‡è¯„åˆ†"""
        score = 0

        # å­—æ•°è¯„åˆ†
        if content_data["avg_words_per_doc"] >= 500:
            score += 3
        elif content_data["avg_words_per_doc"] >= 300:
            score += 2
        else:
            score += 1

        # ä»£ç ç¤ºä¾‹è¯„åˆ†
        if content_data["total_code_blocks"] > 50:
            score += 3
        elif content_data["total_code_blocks"] > 20:
            score += 2
        else:
            score += 1

        # åª’ä½“å†…å®¹è¯„åˆ†
        if content_data["total_images"] > 20:
            score += 2
        elif content_data["total_images"] > 10:
            score += 1

        # é“¾æ¥è´¨é‡è¯„åˆ†
        if content_data["total_links"] > 100:
            score += 2
        elif content_data["total_links"] > 50:
            score += 1

        return min(score, 10)

    def _generate_improvement_suggestions(self, quality_data: Dict[str, any]) -> str:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []

        # å†…å®¹æ”¹è¿›å»ºè®®
        if quality_data['content_analysis']['avg_words_per_doc'] < 300:
            suggestions.append("1. å¢åŠ æ–‡æ¡£å†…å®¹æ·±åº¦ï¼Œæ¯ç¯‡æ–‡æ¡£è‡³å°‘300å­—")

        if quality_data['structure_analysis']['has_table_of_contents'] < quality_data['total_documents'] * 0.8:
            suggestions.append("2. ä¸ºé•¿æ–‡æ¡£æ·»åŠ ç›®å½•ï¼Œæé«˜å¯¼èˆªæ€§")

        if quality_data['search_optimization']['documents_with_keywords'] < quality_data['total_documents'] * 0.5:
            suggestions.append("3. ä¸ºæ–‡æ¡£æ·»åŠ å…³é”®è¯æ ‡ç­¾ï¼Œä¼˜åŒ–æœç´¢æ•ˆæœ")

        readability = quality_data['readability_analysis']
        if readability['avg_sentence_length'] > 25:
            suggestions.append("4. ç¼©çŸ­å¥å­é•¿åº¦ï¼Œæé«˜å¯è¯»æ€§")

        if readability['avg_paragraph_length'] > 100:
            suggestions.append("5. åˆ†å‰²é•¿æ®µè½ï¼Œæå‡é˜…è¯»ä½“éªŒ")

        return "\n".join(suggestions) if suggestions else "æ–‡æ¡£è´¨é‡è‰¯å¥½ï¼Œç»§ç»­ä¿æŒ"

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    checker = DocumentationQualityChecker(Path("docs"))
    report = checker.generate_quality_report()

    with open("docs_quality_report.md", "w", encoding="utf-8") as f:
        f.write(report)

    print("âœ… æ–‡æ¡£è´¨é‡æŠ¥å‘Šå·²ç”Ÿæˆ")
```

#### Claudeæç¤ºè¯
```
è¯·è¯„ä¼°æ–‡æ¡£è´¨é‡ï¼š

è¯„ä¼°ç»´åº¦ï¼š
- å†…å®¹è´¨é‡ï¼ˆå®Œæ•´æ€§ã€å‡†ç¡®æ€§ã€æ·±åº¦ï¼‰
- ç»“æ„è´¨é‡ï¼ˆç»„ç»‡æ€§ã€å¯¼èˆªæ€§ã€ä¸€è‡´æ€§ï¼‰
- å¯è¯»æ€§ï¼ˆè¯­è¨€è¡¨è¾¾ã€æœ¯è¯­ä½¿ç”¨ï¼‰
- æœç´¢ä¼˜åŒ–ï¼ˆå…³é”®è¯ã€å…ƒæ•°æ®ï¼‰

è¯„ä¼°è¦æ±‚ï¼š
1. é‡åŒ–è´¨é‡æŒ‡æ ‡
2. è¯†åˆ«æ”¹è¿›ç©ºé—´
3. æä¾›ä¼˜åŒ–å»ºè®®
4. åˆ¶å®šæå‡è®¡åˆ’

è¯·ç”Ÿæˆï¼š
1. è´¨é‡è¯„ä¼°æŠ¥å‘Š
2. é—®é¢˜åˆ†ææ¸…å•
3. æ”¹è¿›å»ºè®®æ–¹æ¡ˆ
4. è´¨é‡æå‡è®¡åˆ’
```

---

## ğŸš€ é˜¶æ®µäº”ï¼šè‡ªåŠ¨åŒ–ä¸å·¥å…·

### ä»»åŠ¡5.1ï¼šæ–‡æ¡£è‡ªåŠ¨åŒ–å·¥å…·
**æ—¶é—´é¢„ä¼°**: 2å¤©
**è´Ÿè´£è§’è‰²**: å¼€å‘å·¥ç¨‹å¸ˆ

#### è‡ªåŠ¨åŒ–å·¥å…·æ¸…å•
- [ ] æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆå·¥å…·
- [ ] æ–‡æ¡£åŒæ­¥æ£€æŸ¥å·¥å…·
- [ ] æ–‡æ¡£è´¨é‡æ£€æŸ¥å·¥å…·
- [ ] æ–‡æ¡£å‘å¸ƒè‡ªåŠ¨åŒ–
- [ ] æ–‡æ¡£ç›‘æ§å‘Šè­¦

#### CI/CDæ–‡æ¡£æµæ°´çº¿
```yaml
# .github/workflows/docs.yml
name: Documentation Pipeline

on:
  push:
    branches: [main, develop]
    paths:
      - "docs/**"
      - "backend/**"
  pull_request:
    branches: [main]
    paths:
      - "docs/**"

jobs:
  build-docs:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install -r requirements-docs.txt

    - name: Generate API documentation
      run: |
        python scripts/generate_api_docs.py

    - name: Check documentation sync
      run: |
        python scripts/sync_docs.py

    - name: Check documentation quality
      run: |
        python scripts/doc_quality_checker.py

    - name: Build documentation site
      run: |
        mkdocs build

    - name: Deploy to GitHub Pages
      if: github.ref == 'refs/heads/main'
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./site

    - name: Notify documentation updates
      if: github.ref == 'refs/heads/main'
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        text: "ğŸ“š æ–‡æ¡£å·²æ›´æ–°: https://your-domain.com/docs/"
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
```

#### Claudeæç¤ºè¯
```
è¯·å¼€å‘æ–‡æ¡£è‡ªåŠ¨åŒ–å·¥å…·ï¼š

å·¥å…·ç±»å‹ï¼š
- æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ
- æ–‡æ¡£åŒæ­¥æ£€æŸ¥
- æ–‡æ¡£è´¨é‡è¯„ä¼°
- æ–‡æ¡£å‘å¸ƒéƒ¨ç½²
- æ–‡æ¡£ç›‘æ§å‘Šè­¦

åŠŸèƒ½è¦æ±‚ï¼š
1. è‡ªåŠ¨æå–APIä¿¡æ¯ç”Ÿæˆæ–‡æ¡£
2. æ£€æŸ¥æ–‡æ¡£ä¸ä»£ç åŒæ­¥çŠ¶æ€
3. è¯„ä¼°æ–‡æ¡£è´¨é‡å¹¶ç”ŸæˆæŠ¥å‘Š
4. è‡ªåŠ¨éƒ¨ç½²åˆ°æ–‡æ¡£ç«™ç‚¹
5. ç›‘æ§æ–‡æ¡£å˜æ›´å¹¶å‘é€é€šçŸ¥

è¯·å¼€å‘ï¼š
1. æ–‡æ¡£ç”Ÿæˆè„šæœ¬
2. åŒæ­¥æ£€æŸ¥å·¥å…·
3. è´¨é‡è¯„ä¼°å·¥å…·
4. è‡ªåŠ¨åŒ–æµæ°´çº¿
5. ç›‘æ§å‘Šè­¦ç³»ç»Ÿ
```

### ä»»åŠ¡5.2ï¼šç”¨æˆ·åé¦ˆæ”¶é›†
**æ—¶é—´é¢„ä¼°**: 1å¤©
**è´Ÿè´£è§’è‰²**: äº§å“ç»ç†

#### åé¦ˆæ”¶é›†æœºåˆ¶
- [ ] æ–‡æ¡£è¯„åˆ†ç³»ç»Ÿ
- [ ] æ„è§åé¦ˆè¡¨å•
- [ ] ç”¨æˆ·è°ƒç ”é—®å·
- [ ] ä½¿ç”¨æƒ…å†µåˆ†æ
- [ ] åé¦ˆå¤„ç†æµç¨‹

#### åé¦ˆæ”¶é›†å·¥å…·
```html
<!-- docs/feedback.html -->
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ–‡æ¡£åé¦ˆ</title>
    <style>
        .feedback-form {
            max-width: 600px;
            margin: 20px auto;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 8px;
        }
        .rating {
            margin: 10px 0;
        }
        .rating button {
            background: none;
            border: none;
            font-size: 24px;
            cursor: pointer;
            margin: 0 5px;
        }
        .rating button:hover {
            color: gold;
        }
    </style>
</head>
<body>
    <div class="feedback-form">
        <h2>æ–‡æ¡£åé¦ˆ</h2>
        <form id="feedbackForm">
            <div class="rating">
                <label>æ–‡æ¡£è¯„åˆ†ï¼š</label>
                <button type="button" onclick="setRating(1)">â­</button>
                <button type="button" onclick="setRating(2)">â­</button>
                <button type="button" onclick="setRating(3)">â­</button>
                <button type="button" onclick="setRating(4)">â­</button>
                <button type="button" onclick="setRating(5)">â­</button>
                <input type="hidden" id="rating" name="rating" value="0">
            </div>

            <div>
                <label for="page">å½“å‰é¡µé¢ï¼š</label>
                <input type="text" id="page" name="page" readonly>
            </div>

            <div>
                <label for="category">åé¦ˆç±»å‹ï¼š</label>
                <select id="category" name="category">
                    <option value="content">å†…å®¹é—®é¢˜</option>
                    <option value="format">æ ¼å¼é—®é¢˜</option>
                    <option value="suggestion">æ”¹è¿›å»ºè®®</option>
                    <option value="other">å…¶ä»–</option>
                </select>
            </div>

            <div>
                <label for="feedback">è¯¦ç»†åé¦ˆï¼š</label>
                <textarea id="feedback" name="feedback" rows="5" cols="50"></textarea>
            </div>

            <div>
                <label for="email">è”ç³»é‚®ç®±ï¼ˆå¯é€‰ï¼‰ï¼š</label>
                <input type="email" id="email" name="email">
            </div>

            <button type="submit">æäº¤åé¦ˆ</button>
        </form>

        <div id="result"></div>
    </div>

    <script>
        // è‡ªåŠ¨è·å–å½“å‰é¡µé¢
        document.getElementById('page').value = document.referrer || window.location.href;

        function setRating(rating) {
            document.getElementById('rating').value = rating;

            // æ›´æ–°æ˜Ÿæ˜Ÿæ˜¾ç¤º
            const stars = document.querySelectorAll('.rating button');
            stars.forEach((star, index) => {
                if (index < rating) {
                    star.style.color = 'gold';
                } else {
                    star.style.color = '#ccc';
                }
            });
        }

        document.getElementById('feedbackForm').addEventListener('submit', async function(e) {
            e.preventDefault();

            const formData = new FormData(this);
            const data = Object.fromEntries(formData);

            try {
                const response = await fetch('/api/feedback', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify(data)
                });

                if (response.ok) {
                    document.getElementById('result').innerHTML =
                        '<p style="color: green;">âœ… æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼</p>';
                    this.reset();
                } else {
                    throw new Error('æäº¤å¤±è´¥');
                }
            } catch (error) {
                document.getElementById('result').innerHTML =
                    '<p style="color: red;">âŒ æäº¤å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•</p>';
            }
        });
    </script>
</body>
</html>
```

#### Claudeæç¤ºè¯
```
è¯·è®¾è®¡æ–‡æ¡£åé¦ˆæ”¶é›†ç³»ç»Ÿï¼š

æ”¶é›†éœ€æ±‚ï¼š
- æ–‡æ¡£è¯„åˆ†åŠŸèƒ½
- åé¦ˆåˆ†ç±»æ”¶é›†
- ç”¨æˆ·è”ç³»ä¿¡æ¯
- è‡ªåŠ¨é¡µé¢è¯†åˆ«
- åé¦ˆç»Ÿè®¡åˆ†æ

åŠŸèƒ½è¦æ±‚ï¼š
1. ç®€å•æ˜“ç”¨çš„åé¦ˆè¡¨å•
2. è‡ªåŠ¨è¯†åˆ«ç”¨æˆ·å½“å‰é¡µé¢
3. æ”¯æŒå¤šç§åé¦ˆç±»å‹
4. åé¦ˆæ•°æ®ç»Ÿè®¡åˆ†æ
5. åé¦ˆå¤„ç†æµç¨‹ç®¡ç†

è¯·è®¾è®¡ï¼š
1. åé¦ˆæ”¶é›†ç•Œé¢
2. æ•°æ®å­˜å‚¨æ–¹æ¡ˆ
3. ç»Ÿè®¡åˆ†æåŠŸèƒ½
4. åé¦ˆå¤„ç†æµç¨‹
5. ç”¨æˆ·ä½“éªŒä¼˜åŒ–
```

---

## ğŸ“‹ æ–‡æ¡£ç»´æŠ¤æ£€æŸ¥æ¸…å•

### æ—¥å¸¸ç»´æŠ¤
- [ ] APIæ–‡æ¡£ä¸ä»£ç åŒæ­¥æ£€æŸ¥
- [ ] é“¾æ¥æœ‰æ•ˆæ€§éªŒè¯
- [ ] ç”¨æˆ·åé¦ˆåŠæ—¶å¤„ç†
- [ ] ç‰ˆæœ¬ä¿¡æ¯æ›´æ–°
- [ ] æœç´¢æ•ˆæœç›‘æ§

### å‘¨æœŸç»´æŠ¤
- [ ] æ–‡æ¡£è´¨é‡è¯„ä¼°
- [ ] æœ¯è¯­ä¸€è‡´æ€§æ£€æŸ¥
- [ ] ç”¨æˆ·ä½¿ç”¨åˆ†æ
- [ ] æ–‡æ¡£ç»“æ„ä¼˜åŒ–
- [ ] å†…å®¹æ›´æ–°è¡¥å……

### ç‰ˆæœ¬å‘å¸ƒç»´æŠ¤
- [ ] å˜æ›´è®°å½•æ›´æ–°
- [ ] ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥
- [ ] å‡çº§æŒ‡å—ç¼–å†™
- [ ] å†å²ç‰ˆæœ¬å½’æ¡£
- [ ] å‘å¸ƒé€šçŸ¥å‘å¸ƒ

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-11-12
**é€‚ç”¨èŒƒå›´**: æ‰€æœ‰æ–‡æ¡£ç»´æŠ¤å·¥ä½œ
**ç»´æŠ¤è´£ä»»äºº**: æŠ€æœ¯å†™ä½œå›¢é˜Ÿ