#!/usr/bin/env python
"""
æ–‡æ¡£æ•´ç†è„šæœ¬
ç”¨äºæ•´ç†å’Œå½’æ¡£è¿‡æ—¶çš„æ–‡æ¡£
"""

import os
import shutil
from pathlib import Path
from datetime import datetime

# æ–‡æ¡£ç›®å½•
DOCS_DIR = Path(__file__).parent
ARCHIVE_DIR = DOCS_DIR / "archive"

# éœ€è¦ç§»åŠ¨åˆ°å½’æ¡£çš„æ–‡æ¡£åˆ—è¡¨
TO_ARCHIVE = [
    # æ ¹ç›®å½•ä¸‹çš„ä¸´æ—¶æ–‡æ¡£
    ("DATABASE_FIX_VALIDATION_REPORT.md", "æ•°æ®åº“ä¿®å¤æŠ¥å‘Š - å·²å®Œæˆ"),
    ("database_init.sql", "æ•°æ®åº“åˆå§‹åŒ–SQL - å·²ç§»åŠ¨åˆ°scripts"),
    ("sample_queries.sql", "ç¤ºä¾‹æŸ¥è¯¢ - å·²ç§»åŠ¨"),
    ("explore_database.py", "æ•°æ®åº“æ¢ç´¢è„šæœ¬ - å·²ç§»åŠ¨"),
    ("final_supabase_demo.py", "Supabaseæ¼”ç¤º - å·²å®Œæˆ"),
    ("ai_ad_system_database.py", "æ—§ç‰ˆæ•°æ®åº“è„šæœ¬ - å·²æ›´æ–°"),
]

# éœ€è¦æ›´æ–°çš„æ–‡æ¡£ï¼ˆæ›´æ–°å†…å®¹ï¼‰
TO_UPDATE = [
    "README.md",  # éœ€è¦æ›´æ–°æŒ‡å‘æ–°çš„æ–‡æ¡£ç´¢å¼•
]

# é‡å¤çš„æ–‡æ¡£ï¼ˆä¿ç•™æœ€æ–°çš„ï¼‰
DUPLICATES = {
    "DATA_SCHEMA.md": ["DATA_SCHEMA_v2_3.md"],  # v2_3æ˜¯æœ€æ–°ç‰ˆæœ¬
}

def archive_document(file_path, reason):
    """å½’æ¡£æ–‡æ¡£"""
    source = DOCS_DIR / file_path
    if source.exists():
        # åˆ›å»ºå½’æ¡£å­ç›®å½•
        archive_subdir = ARCHIVE_DIR / datetime.now().strftime("%Y-%m")
        archive_subdir.mkdir(parents=True, exist_ok=True)

        # ç§»åŠ¨æ–‡ä»¶
        dest = archive_subdir / source.name
        shutil.move(source, dest)

        # åˆ›å»ºè¯´æ˜æ–‡ä»¶
        readme = archive_subdir / f"{source.name}.README"
        with open(readme, 'w', encoding='utf-8') as f:
            f.write(f"# {source.name}\n\n")
            f.write(f"**å½’æ¡£åŸå› **: {reason}\n")
            f.write(f"**å½’æ¡£æ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d')}\n")

        print(f"âœ“ å·²å½’æ¡£: {file_path} -> {archive_subdir}")
    else:
        print(f"âš  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

def create_readme():
    """åˆ›å»ºå½’æ¡£ç›®å½•çš„README"""
    readme = ARCHIVE_DIR / "README.md"
    if not readme.exists():
        with open(readme, 'w', encoding='utf-8') as f:
            f.write("# æ–‡æ¡£å½’æ¡£\n\n")
            f.write("æ­¤ç›®å½•åŒ…å«é¡¹ç›®çš„æ—§ç‰ˆæœ¬æ–‡æ¡£å’Œå·²å½’æ¡£çš„æ–‡ä»¶ã€‚\n\n")
            f.write("## ç›®å½•ç»“æ„\n\n")
            f.write("- æŒ‰å¹´æœˆç»„ç»‡çš„å­ç›®å½•ï¼ˆå¦‚ 2025-01ï¼‰\n")
            f.write("- æ¯ä¸ªæ–‡ä»¶éƒ½æœ‰å¯¹åº”çš„ .README è¯´æ˜å½’æ¡£åŸå› \n\n")
            f.write("## æ³¨æ„äº‹é¡¹\n\n")
            f.write("- å½’æ¡£æ–‡æ¡£ä»…ä¾›å‚è€ƒ\n")
            f.write("- å¦‚éœ€æœ€æ–°ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ä¸»æ–‡æ¡£ç›®å½•\n")

def main():
    print("="*50)
    print("æ–‡æ¡£æ•´ç†å·¥å…·")
    print("="*50)

    # åˆ›å»ºå½’æ¡£ç›®å½•
    ARCHIVE_DIR.mkdir(exist_ok=True)

    # 1. å½’æ¡£è¿‡æ—¶æ–‡æ¡£
    print("\n[1] å½’æ¡£è¿‡æ—¶æ–‡æ¡£...")
    for file_path, reason in TO_ARCHIVE:
        archive_document(file_path, reason)

    # 2. åˆ›å»ºå½’æ¡£README
    print("\n[2] åˆ›å»ºå½’æ¡£è¯´æ˜...")
    create_readme()

    # 3. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    print("\n[3] æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
    temp_patterns = [
        "*.tmp",
        "*.log",
        "*~",
        ".DS_Store",
        "Thumbs.db"
    ]

    for pattern in temp_patterns:
        for file in DOCS_DIR.glob(pattern):
            if file.is_file():
                file.unlink()
                print(f"  - åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {file.name}")

    # 4. ç»Ÿè®¡æ–‡æ¡£
    print("\n[4] æ–‡æ¡£ç»Ÿè®¡...")
    doc_count = len(list(DOCS_DIR.glob("**/*.md")))
    print(f"  - Markdownæ–‡æ¡£: {doc_count} ä¸ª")
    print(f"  - å½’æ¡£æ–‡æ¡£: {len(list(ARCHIVE_DIR.glob("**/*")))} ä¸ª")

    print("\n" + "="*50)
    print("æ–‡æ¡£æ•´ç†å®Œæˆï¼")
    print("="*50)

    # 5. æä¾›ä¸‹ä¸€æ­¥å»ºè®®
    print("\nå»ºè®®åç»­æ“ä½œï¼š")
    print("1. æŸ¥çœ‹ docs/DOCUMENTATION_INDEX.md äº†è§£æ–‡æ¡£ç»“æ„")
    print("2. æ›´æ–°éœ€è¦ç»´æŠ¤çš„æ–‡æ¡£ï¼ˆæ ‡è®°ä¸ºğŸ“ å¾…æ›´æ–°ï¼‰")
    print("3. åˆ é™¤ä¸å†éœ€è¦çš„ä»£ç æ–‡ä»¶ï¼ˆå¦‚å„ç§Pythonè„šæœ¬ï¼‰")

if __name__ == "__main__":
    main()