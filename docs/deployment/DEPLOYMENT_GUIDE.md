# éƒ¨ç½²æŒ‡å—

> **æ–‡æ¡£ç›®çš„**: ä¸ºAIå¹¿å‘Šä»£æŠ•ç³»ç»Ÿæä¾›å®Œæ•´çš„éƒ¨ç½²é…ç½®å’Œè¿ç»´æŒ‡å—
> **ç›®æ ‡è¯»è€…**: DevOpså·¥ç¨‹å¸ˆã€ç³»ç»Ÿç®¡ç†å‘˜ã€å¼€å‘å›¢é˜Ÿ
> **æ›´æ–°æ—¥æœŸ**: 2025-11-11
> **ç‰ˆæœ¬**: v1.0

---

## ğŸ“‹ ç›®å½•

1. [éƒ¨ç½²æ¶æ„æ¦‚è§ˆ](#1-éƒ¨ç½²æ¶æ„æ¦‚è§ˆ)
2. [ç¯å¢ƒé…ç½®](#2-ç¯å¢ƒé…ç½®)
3. [Dockerå®¹å™¨åŒ–](#3-dockerå®¹å™¨åŒ–)
4. [æ•°æ®åº“éƒ¨ç½²](#4-æ•°æ®åº“éƒ¨ç½²)
5. [CI/CDæµç¨‹](#5-cicdæµç¨‹)
6. [ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²](#6-ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²)
7. [ç›‘æ§å’Œæ—¥å¿—](#7-ç›‘æ§å’Œæ—¥å¿—)
8. [å¤‡ä»½å’Œæ¢å¤](#8-å¤‡ä»½å’Œæ¢å¤)
9. [å®‰å…¨é…ç½®](#9-å®‰å…¨é…ç½®)
10. [æ•…éšœæ’æŸ¥](#10-æ•…éšœæ’æŸ¥)

---

## 1. éƒ¨ç½²æ¶æ„æ¦‚è§ˆ

### 1.1 æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        è´Ÿè½½å‡è¡¡å±‚                            â”‚
â”‚                   Nginx Reverse Proxy                       â”‚
â”‚                   SSL Termination                           â”‚
â”‚                   Rate Limiting                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       åº”ç”¨æœåŠ¡å±‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚  Frontend   â”‚              â”‚   Backend    â”‚               â”‚
â”‚  â”‚ Next.js App â”‚              â”‚ FastAPI App  â”‚               â”‚
â”‚  â”‚  Port:3000  â”‚              â”‚  Port:8000   â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       æ•°æ®æœåŠ¡å±‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ PostgreSQL  â”‚              â”‚    Redis     â”‚               â”‚
â”‚  â”‚ Supabase    â”‚              â”‚    Cache     â”‚               â”‚
â”‚  â”‚  Port:5432  â”‚              â”‚  Port:6379   â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 éƒ¨ç½²ç¯å¢ƒ

| ç¯å¢ƒ | ç”¨é€” | æœåŠ¡å™¨é…ç½® | æ•°æ®åº“è§„æ¨¡ | ç›‘æ§çº§åˆ« |
|------|------|------------|------------|----------|
| **å¼€å‘ç¯å¢ƒ** | æ—¥å¸¸å¼€å‘å’ŒåŠŸèƒ½æµ‹è¯• | 2C4G | å°è§„æ¨¡ | åŸºç¡€ç›‘æ§ |
| **æµ‹è¯•ç¯å¢ƒ** | é›†æˆæµ‹è¯•å’ŒQAéªŒè¯ | 4C8G | ä¸­ç­‰è§„æ¨¡ | å®Œæ•´ç›‘æ§ |
| **é¢„ç”Ÿäº§ç¯å¢ƒ** | ç”Ÿäº§å‰æœ€ç»ˆéªŒè¯ | 8C16G | æ¥è¿‘ç”Ÿäº§ | ç”Ÿäº§çº§ç›‘æ§ |
| **ç”Ÿäº§ç¯å¢ƒ** | æ­£å¼ä¸šåŠ¡è¿è¡Œ | 16C32G+ | å¤§è§„æ¨¡ | é«˜çº§ç›‘æ§ |

### 1.3 æŠ€æœ¯æ ˆ

- **å®¹å™¨åŒ–**: Docker + Docker Compose
- **åå‘ä»£ç†**: Nginx
- **åº”ç”¨æœåŠ¡å™¨**: Uvicorn (FastAPI)
- **æ•°æ®åº“**: PostgreSQL (Supabase)
- **ç¼“å­˜**: Redis
- **CI/CD**: GitHub Actions
- **ç›‘æ§**: Prometheus + Grafana
- **æ—¥å¿—**: ELK Stack

---

## 2. ç¯å¢ƒé…ç½®

### 2.1 æœåŠ¡å™¨è¦æ±‚

#### æœ€ä½é…ç½®
- **CPU**: 4æ ¸å¿ƒ
- **å†…å­˜**: 8GB RAM
- **å­˜å‚¨**: 100GB SSD
- **ç½‘ç»œ**: 100Mbpså¸¦å®½

#### æ¨èé…ç½®
- **CPU**: 8æ ¸å¿ƒ
- **å†…å­˜**: 16GB RAM
- **å­˜å‚¨**: 200GB SSD
- **ç½‘ç»œ**: 1Gbpså¸¦å®½

#### ç”Ÿäº§é…ç½®
- **CPU**: 16æ ¸å¿ƒ+
- **å†…å­˜**: 32GB+ RAM
- **å­˜å‚¨**: 500GB+ SSD
- **ç½‘ç»œ**: 10Gbpså¸¦å®½

### 2.2 æ“ä½œç³»ç»Ÿå‡†å¤‡

```bash
# Ubuntu 20.04+ ç³»ç»Ÿæ›´æ–°
sudo apt-get update && sudo apt-get upgrade -y

# å®‰è£…åŸºç¡€å·¥å…·
sudo apt-get install -y curl wget git vim htop

# é…ç½®æ—¶åŒº
sudo timedatectl set-timezone Asia/Shanghai

# é…ç½®ä¸»æœºå
sudo hostnamectl set-hostname ai-ad-spend-prod
```

### 2.3 Docker å®‰è£…

```bash
# å®‰è£… Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# å¯åŠ¨ Docker æœåŠ¡
sudo systemctl start docker
sudo systemctl enable docker

# å®‰è£… Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# éªŒè¯å®‰è£…
docker --version
docker-compose --version
```

### 2.4 é˜²ç«å¢™é…ç½®

```bash
# é…ç½® UFW é˜²ç«å¢™
sudo ufw enable
sudo ufw default deny incoming
sudo ufw default allow outgoing

# å¼€æ”¾å¿…è¦ç«¯å£
sudo ufw allow 22/tcp    # SSH
sudo ufw allow 80/tcp    # HTTP
sudo ufw allow 443/tcp   # HTTPS
sudo ufw allow from 127.0.0.1  # æœ¬åœ°è®¿é—®

# æŸ¥çœ‹é˜²ç«å¢™çŠ¶æ€
sudo ufw status verbose
```

---

## 3. Dockerå®¹å™¨åŒ–

### 3.1 é¡¹ç›®ç»“æ„

```
ai-ad-spend/
â”œâ”€â”€ docker-compose.yml          # ç”Ÿäº§ç¯å¢ƒé…ç½®
â”œâ”€â”€ docker-compose.dev.yml      # å¼€å‘ç¯å¢ƒé…ç½®
â”œâ”€â”€ docker-compose.prod.yml     # ç”Ÿäº§ç¯å¢ƒè¦†ç›–é…ç½®
â”œâ”€â”€ Dockerfile                  # åç«¯åº”ç”¨å®¹å™¨
â”œâ”€â”€ Dockerfile.frontend         # å‰ç«¯åº”ç”¨å®¹å™¨
â”œâ”€â”€ nginx/
â”‚   â”œâ”€â”€ nginx.conf              # Nginx é…ç½®
â”‚   â”œâ”€â”€ ssl/                    # SSL è¯ä¹¦ç›®å½•
â”‚   â””â”€â”€ conf.d/
â”‚       â””â”€â”€ app.conf            # åº”ç”¨é…ç½®
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ deploy.sh               # éƒ¨ç½²è„šæœ¬
â”‚   â”œâ”€â”€ backup.sh               # å¤‡ä»½è„šæœ¬
â”‚   â””â”€â”€ restore.sh              # æ¢å¤è„šæœ¬
â””â”€â”€ monitoring/
    â”œâ”€â”€ prometheus.yml          # Prometheus é…ç½®
    â”œâ”€â”€ grafana/
    â”‚   â””â”€â”€ dashboards/         # Grafana ä»ªè¡¨ç›˜
    â””â”€â”€ alertmanager.yml        # å‘Šè­¦é…ç½®
```

### 3.2 åç«¯ Dockerfile

```dockerfile
# backend/Dockerfile
FROM python:3.11-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
COPY requirements-prod.txt .

# å®‰è£… Python ä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºé root ç”¨æˆ·
RUN useradd --create-home --shell /bin/bash app
RUN chown -R app:app /app
USER app

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 3.3 å‰ç«¯ Dockerfile

```dockerfile
# frontend/Dockerfile
FROM node:20-alpine AS builder

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY package*.json ./

# å®‰è£…ä¾èµ–
RUN npm ci --only=production

# å¤åˆ¶æºä»£ç 
COPY . .

# æ„å»ºåº”ç”¨
RUN npm run build

# ç”Ÿäº§é˜¶æ®µ
FROM nginx:alpine

# å¤åˆ¶æ„å»ºç»“æœ
COPY --from=builder /app/.next /app/.next
COPY --from=builder /app/node_modules /app/node_modules
COPY --from=builder /app/package.json /app/
COPY --from=builder /app/public /app/public

# å¤åˆ¶ Next.js é…ç½®
COPY --from=builder /app/next.config.js ./

# å¤åˆ¶ Nginx é…ç½®
COPY nginx.conf /etc/nginx/nginx.conf

# æš´éœ²ç«¯å£
EXPOSE 3000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:3000 || exit 1

# å¯åŠ¨ Nginx
CMD ["nginx", "-g", "daemon off;"]
```

### 3.4 Docker Compose é…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  # åç«¯æœåŠ¡
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    restart: unless-stopped
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - JWT_SECRET=${JWT_SECRET}
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
    env_file:
      - .env.prod
    depends_on:
      - postgres
      - redis
    networks:
      - app-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.backend.rule=Host(`api.yourdomain.com`)"
      - "traefik.http.routers.backend.tls=true"

  # å‰ç«¯æœåŠ¡
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    restart: unless-stopped
    environment:
      - NEXT_PUBLIC_API_BASE_URL=https://api.yourdomain.com
      - NEXT_PUBLIC_SUPABASE_URL=${SUPABASE_URL}
      - NEXT_PUBLIC_SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
    networks:
      - app-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.frontend.rule=Host(`yourdomain.com`)"
      - "traefik.http.routers.frontend.tls=true"

  # Nginx åå‘ä»£ç†
  nginx:
    image: nginx:alpine
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - ./nginx/conf.d:/etc/nginx/conf.d
    depends_on:
      - backend
      - frontend
    networks:
      - app-network

  # PostgreSQL æ•°æ®åº“
  postgres:
    image: postgres:15
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    networks:
      - app-network

  # Redis ç¼“å­˜
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    networks:
      - app-network

  # ç›‘æ§æœåŠ¡
  prometheus:
    image: prom/prometheus:latest
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - app-network

  grafana:
    image: grafana/grafana:latest
    restart: unless-stopped
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
    networks:
      - app-network

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:

networks:
  app-network:
    driver: bridge
```

---

## 4. æ•°æ®åº“éƒ¨ç½²

### 4.1 PostgreSQL é…ç½®

```yaml
# docker-compose.prod.yml (è¦†ç›–é…ç½®)
version: '3.8'

services:
  postgres:
    image: postgres:15
    restart: unless-stopped
    environment:
      - POSTGRES_DB=ai_ad_spend_prod
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
      - ./postgresql/postgresql.conf:/etc/postgresql/postgresql.conf
      - ./postgresql/pg_hba.conf:/etc/postgresql/pg_hba.conf
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4'
    networks:
      - app-network
```

### 4.2 æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬

```sql
-- scripts/init-db.sql
-- åˆ›å»ºæ•°æ®åº“å’Œç”¨æˆ·
CREATE DATABASE ai_ad_spend_prod;
CREATE USER app_user WITH ENCRYPTED PASSWORD '${DB_PASSWORD}';

-- æˆæƒ
GRANT ALL PRIVILEGES ON DATABASE ai_ad_spend_prod TO app_user;
GRANT ALL PRIVILEGES ON SCHEMA public TO app_user;

-- è®¾ç½®é»˜è®¤æƒé™
ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON TABLES TO app_user;
ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON SEQUENCES TO app_user;

-- è¿æ¥åˆ°åº”ç”¨æ•°æ®åº“
\c ai_ad_spend_prod;

-- åˆ›å»ºæ‰©å±•
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pg_stat_statements";
CREATE EXTENSION IF NOT EXISTS "pg_trgm";

-- é€€å‡º
\c postgres;

-- æ–­å¼€è¿æ¥
\q
```

### 4.3 æ•°æ®åº“è¿ç§»

```bash
#!/bin/bash
# scripts/migrate-db.sh

set -e

echo "å¼€å§‹æ•°æ®åº“è¿ç§»..."

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
docker-compose exec postgres pg_isready -U postgres

# è¿è¡Œ Alembic è¿ç§»
docker-compose exec backend alembic upgrade head

# éªŒè¯è¿ç§»ç»“æœ
docker-compose exec backend alembic current

echo "æ•°æ®åº“è¿ç§»å®Œæˆ!"
```

---

## 5. CI/CDæµç¨‹

### 5.1 GitHub Actions å·¥ä½œæµ

```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        cd backend
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Run tests
      run: |
        cd backend
        pytest --cov=app tests/
        coverage xml

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./backend/coverage.xml

  build-and-deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v4

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: true
        tags: |
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}

    - name: Deploy to production
      uses: appleboy/ssh-action@v1.0.0
      with:
        host: ${{ secrets.PROD_HOST }}
        username: ${{ secrets.PROD_USER }}
        key: ${{ secrets.PROD_SSH_KEY }}
        script: |
          cd /opt/ai-ad-spend
          git pull origin main
          docker-compose pull
          docker-compose up -d
          docker system prune -f
```

### 5.2 éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# scripts/deploy.sh

set -e

# é…ç½®å˜é‡
DEPLOY_DIR="/opt/ai-ad-spend"
BACKUP_DIR="/opt/backups"
LOG_FILE="/var/log/deploy.log"

# æ—¥å¿—å‡½æ•°
log() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a "$LOG_FILE"
}

# é”™è¯¯å¤„ç†
error_exit() {
    log "ERROR: $1"
    exit 1
}

# æ£€æŸ¥æƒé™
check_permissions() {
    if [[ $EUID -ne 0 ]]; then
        error_exit "æ­¤è„šæœ¬éœ€è¦ root æƒé™è¿è¡Œ"
    fi
}

# å¤‡ä»½æ•°æ®åº“
backup_database() {
    log "å¼€å§‹å¤‡ä»½æ•°æ®åº“..."

    BACKUP_FILE="$BACKUP_DIR/db_backup_$(date +%Y%m%d_%H%M%S).sql"

    docker-compose exec postgres pg_dump -U postgres ai_ad_spend_prod > "$BACKUP_FILE"

    # å‹ç¼©å¤‡ä»½æ–‡ä»¶
    gzip "$BACKUP_FILE"

    log "æ•°æ®åº“å¤‡ä»½å®Œæˆ: ${BACKUP_FILE}.gz"
}

# æ›´æ–°ä»£ç 
update_code() {
    log "æ›´æ–°åº”ç”¨ä»£ç ..."

    cd "$DEPLOY_DIR"
    git fetch origin
    git reset --hard origin/main

    log "ä»£ç æ›´æ–°å®Œæˆ"
}

# æ„å»ºå’Œéƒ¨ç½²
deploy_application() {
    log "å¼€å§‹éƒ¨ç½²åº”ç”¨..."

    cd "$DEPLOY_DIR"

    # åœæ­¢æœåŠ¡
    docker-compose down

    # æ‹‰å–æœ€æ–°é•œåƒ
    docker-compose pull

    # å¯åŠ¨æœåŠ¡
    docker-compose up -d

    # ç­‰å¾…æœåŠ¡å¯åŠ¨
    sleep 30

    log "åº”ç”¨éƒ¨ç½²å®Œæˆ"
}

# å¥åº·æ£€æŸ¥
health_check() {
    log "è¿›è¡Œå¥åº·æ£€æŸ¥..."

    # æ£€æŸ¥åç«¯æœåŠ¡
    for i in {1..10}; do
        if curl -f http://localhost:8000/health > /dev/null 2>&1; then
            log "åç«¯æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡"
            break
        fi

        if [[ $i -eq 10 ]]; then
            error_exit "åç«¯æœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥"
        fi

        sleep 10
    done

    # æ£€æŸ¥å‰ç«¯æœåŠ¡
    if curl -f http://localhost:3000 > /dev/null 2>&1; then
        log "å‰ç«¯æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡"
    else
        error_exit "å‰ç«¯æœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥"
    fi

    log "å¥åº·æ£€æŸ¥å®Œæˆ"
}

# æ¸…ç†æ—§é•œåƒ
cleanup() {
    log "æ¸…ç†æ—§é•œåƒ..."

    docker image prune -f

    # ä¿ç•™æœ€è¿‘5ä¸ªç‰ˆæœ¬çš„é•œåƒ
    docker images --format "table {{.Repository}}\t{{.Tag}}\t{{.ID}}" | \
        grep ai-ad-spend | \
        tail -n +6 | \
        awk '{print $3}' | \
        xargs -r docker rmi -f

    log "æ¸…ç†å®Œæˆ"
}

# ä¸»å‡½æ•°
main() {
    log "å¼€å§‹éƒ¨ç½²æµç¨‹..."

    check_permissions
    backup_database
    update_code
    deploy_application
    health_check
    cleanup

    log "éƒ¨ç½²æµç¨‹å®Œæˆ!"
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
```

---

## 6. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### 6.1 æœåŠ¡å™¨åˆå§‹åŒ–

```bash
#!/bin/bash
# scripts/init-server.sh

set -e

# æ›´æ–°ç³»ç»Ÿ
sudo apt-get update && sudo apt-get upgrade -y

# å®‰è£…åŸºç¡€è½¯ä»¶
sudo apt-get install -y \
    curl \
    wget \
    git \
    vim \
    htop \
    unzip \
    software-properties-common \
    apt-transport-https \
    ca-certificates \
    gnupg \
    lsb-release

# å®‰è£… Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER

# å®‰è£… Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# é…ç½®é˜²ç«å¢™
sudo ufw enable
sudo ufw allow 22/tcp
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp

# åˆ›å»ºåº”ç”¨ç›®å½•
sudo mkdir -p /opt/ai-ad-spend
sudo mkdir -p /opt/backups
sudo mkdir -p /var/log/ai-ad-spend

# è®¾ç½®æƒé™
sudo chown -R $USER:$USER /opt/ai-ad-spend
sudo chown -R $USER:$USER /opt/backups
sudo chown -R $USER:$USER /var/log/ai-ad-spend

echo "æœåŠ¡å™¨åˆå§‹åŒ–å®Œæˆ!"
```

### 6.2 SSL è¯ä¹¦é…ç½®

```bash
#!/bin/bash
# scripts/setup-ssl.sh

DOMAIN="yourdomain.com"

# å®‰è£… Certbot
sudo apt-get install -y certbot python3-certbot-nginx

# è·å– SSL è¯ä¹¦
sudo certbot --nginx \
    --non-interactive \
    --agree-tos \
    --email admin@yourdomain.com \
    -d $DOMAIN \
    -d www.$DOMAIN

# è®¾ç½®è‡ªåŠ¨ç»­æœŸ
echo "0 12 * * * /usr/bin/certbot renew --quiet" | sudo crontab -

# å¤åˆ¶è¯ä¹¦åˆ°åº”ç”¨ç›®å½•
sudo mkdir -p /opt/ai-ad-spend/nginx/ssl
sudo cp /etc/letsencrypt/live/$DOMAIN/fullchain.pem /opt/ai-ad-spend/nginx/ssl/
sudo cp /etc/letsencrypt/live/$DOMAIN/privkey.pem /opt/ai-ad-spend/nginx/ssl/
sudo chown -R $USER:$USER /opt/ai-ad-spend/nginx/ssl

echo "SSL è¯ä¹¦é…ç½®å®Œæˆ!"
```

### 6.3 Nginx é…ç½®

```nginx
# nginx/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # æ—¥å¿—æ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    # åŸºæœ¬é…ç½®
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 50M;

    # Gzip å‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/javascript
        application/xml+rss
        application/json;

    # å®‰å…¨å¤´
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

    # åŒ…å«ç«™ç‚¹é…ç½®
    include /etc/nginx/conf.d/*.conf;
}
```

```nginx
# nginx/conf.d/app.conf
upstream backend {
    server backend:8000;
}

upstream frontend {
    server frontend:3000;
}

# HTTP é‡å®šå‘åˆ° HTTPS
server {
    listen 80;
    server_name yourdomain.com www.yourdomain.com;
    return 301 https://$server_name$request_uri;
}

# HTTPS ä¸»ç«™ç‚¹
server {
    listen 443 ssl http2;
    server_name yourdomain.com www.yourdomain.com;

    # SSL é…ç½®
    ssl_certificate /etc/nginx/ssl/fullchain.pem;
    ssl_certificate_key /etc/nginx/ssl/privkey.pem;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;

    # å‰ç«¯åº”ç”¨
    location / {
        proxy_pass http://frontend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # API è¯·æ±‚
    location /api/ {
        proxy_pass http://backend/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # å¢åŠ è¶…æ—¶æ—¶é—´
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }

    # å¥åº·æ£€æŸ¥
    location /health {
        proxy_pass http://backend/health;
        access_log off;
    }

    # é™æ€æ–‡ä»¶ç¼“å­˜
    location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
```

---

## 7. ç›‘æ§å’Œæ—¥å¿—

### 7.1 Prometheus é…ç½®

```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'backend'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: '/metrics'
    scrape_interval: 15s

  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx:9113']

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
```

### 7.2 å‘Šè­¦è§„åˆ™

```yaml
# monitoring/alert_rules.yml
groups:
  - name: application_alerts
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "é«˜é”™è¯¯ç‡å‘Šè­¦"
          description: "é”™è¯¯ç‡è¶…è¿‡ 10%"

      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "é«˜å“åº”æ—¶é—´å‘Šè­¦"
          description: "95% è¯·æ±‚å“åº”æ—¶é—´è¶…è¿‡ 1 ç§’"

      - alert: DatabaseDown
        expr: up{job="postgres"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "æ•°æ®åº“æœåŠ¡å®•æœº"
          description: "PostgreSQL æ•°æ®åº“æ— æ³•è®¿é—®"

      - alert: HighDatabaseConnections
        expr: pg_stat_activity_count > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "æ•°æ®åº“è¿æ¥æ•°è¿‡é«˜"
          description: "æ•°æ®åº“æ´»è·ƒè¿æ¥æ•°è¶…è¿‡ 80"

      - alert: DiskSpaceUsage
        expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "ç£ç›˜ç©ºé—´ä½¿ç”¨ç‡è¿‡é«˜"
          description: "ç£ç›˜ä½¿ç”¨ç‡è¶…è¿‡ 80%"
```

---

## 8. å¤‡ä»½å’Œæ¢å¤

### 8.1 è‡ªåŠ¨å¤‡ä»½è„šæœ¬

```bash
#!/bin/bash
# scripts/backup.sh

set -e

# é…ç½®å˜é‡
BACKUP_DIR="/opt/backups"
RETENTION_DAYS=30
DATE=$(date +%Y%m%d_%H%M%S)

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p "$BACKUP_DIR"/{database,config,logs}

# æ•°æ®åº“å¤‡ä»½
backup_database() {
    echo "å¼€å§‹æ•°æ®åº“å¤‡ä»½..."

    BACKUP_FILE="$BACKUP_DIR/database/db_backup_$DATE.sql"

    # å¤‡ä»½æ•°æ®åº“
    docker-compose exec postgres pg_dump -U postgres ai_ad_spend_prod > "$BACKUP_FILE"

    # å‹ç¼©å¤‡ä»½æ–‡ä»¶
    gzip "$BACKUP_FILE"

    echo "æ•°æ®åº“å¤‡ä»½å®Œæˆ: ${BACKUP_FILE}.gz"
}

# é…ç½®æ–‡ä»¶å¤‡ä»½
backup_config() {
    echo "å¼€å§‹é…ç½®æ–‡ä»¶å¤‡ä»½..."

    CONFIG_BACKUP_DIR="$BACKUP_DIR/config/config_$DATE"
    mkdir -p "$CONFIG_BACKUP_DIR"

    # å¤åˆ¶é…ç½®æ–‡ä»¶
    cp -r /opt/ai-ad-spend/.env* "$CONFIG_BACKUP_DIR/"
    cp -r /opt/ai-ad-spend/nginx "$CONFIG_BACKUP_DIR/"
    cp -r /opt/ai-ad-spend/monitoring "$CONFIG_BACKUP_DIR/"

    # åˆ›å»ºå‹ç¼©åŒ…
    tar -czf "$CONFIG_BACKUP_DIR.tar.gz" -C "$BACKUP_DIR/config" "config_$DATE"
    rm -rf "$CONFIG_BACKUP_DIR"

    echo "é…ç½®æ–‡ä»¶å¤‡ä»½å®Œæˆ: ${CONFIG_BACKUP_DIR}.tar.gz"
}

# æ—¥å¿—å¤‡ä»½
backup_logs() {
    echo "å¼€å§‹æ—¥å¿—å¤‡ä»½..."

    LOG_BACKUP_FILE="$BACKUP_DIR/logs/logs_$DATE.tar.gz"

    # æ‰“åŒ…æ—¥å¿—æ–‡ä»¶
    tar -czf "$LOG_BACKUP_FILE" -C /var/log ai-ad-spend

    echo "æ—¥å¿—å¤‡ä»½å®Œæˆ: $LOG_BACKUP_FILE"
}

# æ¸…ç†æ—§å¤‡ä»½
cleanup_old_backups() {
    echo "æ¸…ç† $RETENTION_DAYS å¤©å‰çš„å¤‡ä»½..."

    # æ¸…ç†æ•°æ®åº“å¤‡ä»½
    find "$BACKUP_DIR/database" -name "*.gz" -mtime +$RETENTION_DAYS -delete

    # æ¸…ç†é…ç½®å¤‡ä»½
    find "$BACKUP_DIR/config" -name "*.tar.gz" -mtime +$RETENTION_DAYS -delete

    # æ¸…ç†æ—¥å¿—å¤‡ä»½
    find "$BACKUP_DIR/logs" -name "*.tar.gz" -mtime +$RETENTION_DAYS -delete

    echo "æ—§å¤‡ä»½æ¸…ç†å®Œæˆ"
}

# ä¸»å‡½æ•°
main() {
    echo "å¼€å§‹å¤‡ä»½æµç¨‹..."

    backup_database
    backup_config
    backup_logs
    cleanup_old_backups

    echo "å¤‡ä»½æµç¨‹å®Œæˆ!"
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
```

### 8.2 æ¢å¤è„šæœ¬

```bash
#!/bin/bash
# scripts/restore.sh

set -e

# é…ç½®å˜é‡
BACKUP_DIR="/opt/backups"

# æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
show_help() {
    echo "ç”¨æ³•: $0 [é€‰é¡¹]"
    echo "é€‰é¡¹:"
    echo "  -d, --database FILE  æ¢å¤æ•°æ®åº“"
    echo "  -c, --config FILE    æ¢å¤é…ç½®"
    echo "  -l, --logs FILE      æ¢å¤æ—¥å¿—"
    echo "  -a, --all DATE       æ¢å¤æ‰€æœ‰å¤‡ä»½ (æ ¼å¼: YYYYMMDD_HHMMSS)"
    echo "  -h, --help           æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"
}

# æ¢å¤æ•°æ®åº“
restore_database() {
    local backup_file=$1

    echo "å¼€å§‹æ¢å¤æ•°æ®åº“: $backup_file"

    # åœæ­¢åº”ç”¨æœåŠ¡
    docker-compose stop backend

    # æ¢å¤æ•°æ®åº“
    if [[ $backup_file == *.gz ]]; then
        gunzip -c "$backup_file" | docker-compose exec -T postgres psql -U postgres ai_ad_spend_prod
    else
        docker-compose exec -T postgres psql -U postgres ai_ad_spend_prod < "$backup_file"
    fi

    # é‡å¯åº”ç”¨æœåŠ¡
    docker-compose start backend

    echo "æ•°æ®åº“æ¢å¤å®Œæˆ"
}

# æ¢å¤é…ç½®æ–‡ä»¶
restore_config() {
    local backup_file=$1

    echo "å¼€å§‹æ¢å¤é…ç½®: $backup_file"

    # è§£å‹é…ç½®æ–‡ä»¶
    tar -xzf "$backup_file" -C /opt/ai-ad-spend/

    # é‡å¯æœåŠ¡ä»¥åº”ç”¨æ–°é…ç½®
    docker-compose restart nginx

    echo "é…ç½®æ–‡ä»¶æ¢å¤å®Œæˆ"
}

# æ¢å¤æ‰€æœ‰å¤‡ä»½
restore_all() {
    local date=$1

    echo "å¼€å§‹æ¢å¤æ‰€æœ‰å¤‡ä»½: $date"

    # æŸ¥æ‰¾å¤‡ä»½æ–‡ä»¶
    DB_BACKUP=$(find "$BACKUP_DIR/database" -name "db_backup_$date.sql.gz" | head -n 1)
    CONFIG_BACKUP=$(find "$BACKUP_DIR/config" -name "config_$date.tar.gz" | head -n 1)
    LOGS_BACKUP=$(find "$BACKUP_DIR/logs" -name "logs_$date.tar.gz" | head -n 1)

    # æ¢å¤å„ä¸ªç»„ä»¶
    if [[ -n "$DB_BACKUP" ]]; then
        restore_database "$DB_BACKUP"
    fi

    if [[ -n "$CONFIG_BACKUP" ]]; then
        restore_config "$CONFIG_BACKUP"
    fi

    if [[ -n "$LOGS_BACKUP" ]]; then
        tar -xzf "$LOGS_BACKUP" -C /var/log/
    fi

    echo "æ‰€æœ‰å¤‡ä»½æ¢å¤å®Œæˆ"
}

# å‚æ•°è§£æ
case "$1" in
    -d|--database)
        restore_database "$2"
        ;;
    -c|--config)
        restore_config "$2"
        ;;
    -l|--logs)
        tar -xzf "$2" -C /var/log/
        echo "æ—¥å¿—æ¢å¤å®Œæˆ"
        ;;
    -a|--all)
        restore_all "$2"
        ;;
    -h|--help)
        show_help
        ;;
    *)
        show_help
        exit 1
        ;;
esac
```

---

## 9. å®‰å…¨é…ç½®

### 9.1 å®‰å…¨åŠ å›º

```bash
#!/bin/bash
# scripts/security-hardening.sh

# ç¦ç”¨ root SSH ç™»å½•
sudo sed -i 's/PermitRootLogin yes/PermitRootLogin no/' /etc/ssh/sshd_config

# æ›´æ”¹ SSH ç«¯å£
sudo sed -i 's/#Port 22/Port 2222/' /etc/ssh/sshd_config

# é‡å¯ SSH æœåŠ¡
sudo systemctl restart sshd

# é…ç½® fail2ban
sudo apt-get install -y fail2ban

# åˆ›å»º fail2ban é…ç½®
sudo tee /etc/fail2ban/jail.local > /dev/null <<EOF
[DEFAULT]
bantime = 3600
findtime = 600
maxretry = 3

[sshd]
enabled = true
port = 2222
logpath = /var/log/auth.log

[nginx-http-auth]
enabled = true
filter = nginx-http-auth
logpath = /var/log/nginx/error.log

[nginx-limit-req]
enabled = true
filter = nginx-limit-req
logpath = /var/log/nginx/error.log
EOF

# å¯åŠ¨ fail2ban
sudo systemctl enable fail2ban
sudo systemctl start fail2ban

# è®¾ç½®è‡ªåŠ¨å®‰å…¨æ›´æ–°
sudo apt-get install -y unattended-upgrades
sudo dpkg-reconfigure -plow unattended-upgrades

echo "å®‰å…¨åŠ å›ºå®Œæˆ"
```

### 9.2 ç¯å¢ƒå˜é‡å®‰å…¨ç®¡ç†

```bash
#!/bin/bash
# scripts/setup-secrets.sh

# åˆ›å»º secrets ç›®å½•
mkdir -p /opt/ai-ad-spend/secrets
chmod 700 /opt/ai-ad-spend/secrets

# ç”Ÿæˆéšæœºå¯†é’¥
generate_secret() {
    openssl rand -hex 32
}

# ç”Ÿæˆç¯å¢ƒå˜é‡æ–‡ä»¶
cat > /opt/ai-ad-spend/.env.prod <<EOF
# åº”ç”¨é…ç½®
APP_NAME=AIå¹¿å‘Šä»£æŠ•ç³»ç»Ÿ
APP_VERSION=2.0.0
DEBUG=false
ENVIRONMENT=production

# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://postgres:$(generate_secret)@postgres:5432/ai_ad_spend_prod
POSTGRES_PASSWORD=$(generate_secret)

# Supabase é…ç½®
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your-anon-key
SUPABASE_SERVICE_KEY=your-service-key

# Redis é…ç½®
REDIS_URL=redis://:$(generate_secret)@redis:6379/0
REDIS_PASSWORD=$(generate_secret)

# JWT é…ç½®
JWT_SECRET=$(generate_secret)
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=15
REFRESH_TOKEN_EXPIRE_DAYS=7

# CORS é…ç½®
ALLOWED_ORIGINS=https://yourdomain.com

# å¤–éƒ¨ API é…ç½®
FACEBOOK_API_VERSION=v18.0
FACEBOOK_APP_ID=your-app-id
FACEBOOK_APP_SECRET=your-app-secret

# ç›‘æ§é…ç½®
SENTRY_DSN=your-sentry-dsn
GRAFANA_PASSWORD=$(generate_secret)
EOF

# è®¾ç½®æ–‡ä»¶æƒé™
chmod 600 /opt/ai-ad-spend/.env.prod

echo "ç¯å¢ƒå˜é‡é…ç½®å®Œæˆ"
```

---

## 10. æ•…éšœæ’æŸ¥

### 10.1 å¸¸è§é—®é¢˜è¯Šæ–­

```bash
#!/bin/bash
# scripts/diagnose.sh

echo "=== AIå¹¿å‘Šä»£æŠ•ç³»ç»Ÿè¯Šæ–­å·¥å…· ==="
echo ""

# æ£€æŸ¥ç³»ç»Ÿèµ„æº
echo "1. ç³»ç»Ÿèµ„æºæ£€æŸ¥:"
echo "CPU ä½¿ç”¨ç‡:"
top -bn1 | grep "Cpu(s)" | awk '{print $2}' | awk -F'%' '{print $1}'

echo "å†…å­˜ä½¿ç”¨ç‡:"
free | grep Mem | awk '{printf("%.2f%%\n", $3/$2 * 100.0)}'

echo "ç£ç›˜ä½¿ç”¨ç‡:"
df -h | grep -vE '^Filesystem|tmpfs|cdrom' | awk '{print $5 " " $1}'

# æ£€æŸ¥ Docker æœåŠ¡
echo ""
echo "2. Docker æœåŠ¡æ£€æŸ¥:"
docker-compose ps

# æ£€æŸ¥ç«¯å£å ç”¨
echo ""
echo "3. ç«¯å£å ç”¨æ£€æŸ¥:"
for port in 80 443 8000 3000 5432 6379; do
    if netstat -tln | grep -q ":$port "; then
        echo "ç«¯å£ $port: å·²å ç”¨"
    else
        echo "ç«¯å£ $port: æœªå ç”¨"
    fi
done

# æ£€æŸ¥æ—¥å¿—é”™è¯¯
echo ""
echo "4. åº”ç”¨æ—¥å¿—é”™è¯¯æ£€æŸ¥:"
docker-compose logs --tail=50 backend | grep -i error || echo "æ— é”™è¯¯æ—¥å¿—"

docker-compose logs --tail=50 frontend | grep -i error || echo "æ— é”™è¯¯æ—¥å¿—"

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
echo ""
echo "5. æ•°æ®åº“è¿æ¥æ£€æŸ¥:"
docker-compose exec postgres pg_isready -U postgres && echo "æ•°æ®åº“è¿æ¥æ­£å¸¸" || echo "æ•°æ®åº“è¿æ¥å¼‚å¸¸"

# æ£€æŸ¥ Redis è¿æ¥
echo ""
echo "6. Redis è¿æ¥æ£€æŸ¥:"
docker-compose exec redis redis-cli ping | grep -q PONG && echo "Redis è¿æ¥æ­£å¸¸" || echo "Redis è¿æ¥å¼‚å¸¸"

echo ""
echo "=== è¯Šæ–­å®Œæˆ ==="
```

### 10.2 åº”æ€¥æ¢å¤æµç¨‹

```bash
#!/bin/bash
# scripts/emergency-recovery.sh

echo "=== åº”æ€¥æ¢å¤æµç¨‹ ==="

# åœæ­¢æ‰€æœ‰æœåŠ¡
echo "1. åœæ­¢æ‰€æœ‰æœåŠ¡..."
docker-compose down

# æ¸…ç†å®¹å™¨
echo "2. æ¸…ç†å®¹å™¨..."
docker system prune -f

# é‡æ–°æ‹‰å–é•œåƒ
echo "3. é‡æ–°æ‹‰å–é•œåƒ..."
docker-compose pull

# å¯åŠ¨åŸºç¡€æœåŠ¡
echo "4. å¯åŠ¨åŸºç¡€æœåŠ¡..."
docker-compose up -d postgres redis

# ç­‰å¾…æ•°æ®åº“å¯åŠ¨
echo "5. ç­‰å¾…æ•°æ®åº“å¯åŠ¨..."
sleep 30

# æ¢å¤æ•°æ®åº“ (ä½¿ç”¨æœ€æ–°å¤‡ä»½)
LATEST_BACKUP=$(ls -t /opt/backups/database/*.gz | head -n 1)
if [[ -n "$LATEST_BACKUP" ]]; then
    echo "6. æ¢å¤æ•°æ®åº“: $LATEST_BACKUP"
    gunzip -c "$LATEST_BACKUP" | docker-compose exec -T postgres psql -U postgres ai_ad_spend_prod
fi

# å¯åŠ¨åº”ç”¨æœåŠ¡
echo "7. å¯åŠ¨åº”ç”¨æœåŠ¡..."
docker-compose up -d

# å¥åº·æ£€æŸ¥
echo "8. è¿›è¡Œå¥åº·æ£€æŸ¥..."
sleep 30

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
if curl -f http://localhost:8000/health > /dev/null 2>&1; then
    echo "âœ… åç«¯æœåŠ¡æ­£å¸¸"
else
    echo "âŒ åç«¯æœåŠ¡å¼‚å¸¸"
fi

if curl -f http://localhost:3000 > /dev/null 2>&1; then
    echo "âœ… å‰ç«¯æœåŠ¡æ­£å¸¸"
else
    echo "âŒ å‰ç«¯æœåŠ¡å¼‚å¸¸"
fi

echo "=== åº”æ€¥æ¢å¤å®Œæˆ ==="
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### ç´§æ€¥è”ç³»æ–¹å¼
- **24/7 æ•…éšœçƒ­çº¿**: +86-xxx-xxxx-xxxx
- **æŠ€æœ¯è´Ÿè´£äºº**: +86-xxx-xxxx-xxxx
- **DevOps å·¥ç¨‹å¸ˆ**: devops@company.com

### åœ¨çº¿èµ„æº
- **ç›‘æ§é¢æ¿**: https://monitor.yourdomain.com
- **æ—¥å¿—ç³»ç»Ÿ**: https://logs.yourdomain.com
- **æ–‡æ¡£ä¸­å¿ƒ**: https://docs.company.com/ai-ad-spend

### å¤‡ä»½éªŒè¯
- **æ¯æ—¥å¤‡ä»½**: 02:00 AM è‡ªåŠ¨æ‰§è¡Œ
- **å¤‡ä»½éªŒè¯**: æ¯å‘¨æ—¥å‡Œæ™¨æ‰§è¡Œ
- **å¼‚åœ°å¤‡ä»½**: æ¯æœˆåŒæ­¥åˆ°äº‘å­˜å‚¨

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-11-11
**ä¸‹æ¬¡å®¡æŸ¥**: éƒ¨ç½²æ¶æ„é‡å¤§å˜æ›´æ—¶
**ç»´æŠ¤è´£ä»»äºº**: DevOpså›¢é˜Ÿè´Ÿè´£äºº